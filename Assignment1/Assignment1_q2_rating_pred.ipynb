{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline() # Skip Header\n",
    "    for l in f:\n",
    "        yield l.strip(). split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookData = []\n",
    "for user, book, rating in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    bookData.append([user, book, int(rating)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['u79354815', 'b14275065', 4],\n",
       " ['u56917948', 'b82152306', 5],\n",
       " ['u97915914', 'b44882292', 5],\n",
       " ['u49688858', 'b79927466', 5],\n",
       " ['u08384938', 'b05683889', 2],\n",
       " ['u13530776', 'b86375465', 4],\n",
       " ['u46307273', 'b92838791', 5],\n",
       " ['u18524450', 'b35165110', 2],\n",
       " ['u69700998', 'b17128180', 5],\n",
       " ['u43359569', 'b34596567', 5]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookData[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks (Read prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Although we have built a validation set, it only consists of positive samples.\n",
    "For this task we also need examples of user/item pairs that weren’t read. For each entry (user,book) in the validation set, sample a negative entry by randomly choosing a book that user hasn’t read. Evaluate the performance (accuracy) of the baseline model on the validation set you have built.\n",
    "\n",
    "Ans: <br>\n",
    "Accurarcy of validation set: 0.7484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "190000\n",
      "190000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Separate traing and validation set\n",
    "print(len(bookData))\n",
    "numTrainSet = 190000\n",
    "bookDataTrain = bookData[:numTrainSet]\n",
    "bookDataYTrain =  [1] * len(bookDataTrain)\n",
    "bookDataValidPos = bookData[numTrainSet:]\n",
    "bookDataYValidPos = [1] * len(bookDataValidPos)\n",
    "print(len(bookDataTrain))\n",
    "print(len(bookDataYTrain))\n",
    "print(len(bookDataValidPos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7170"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookUniqueIds = set()\n",
    "for user, book, rating in bookData:\n",
    "    bookUniqueIds.add(book)\n",
    "bookUniqueIdsList = list(bookUniqueIds)\n",
    "#bookUniqueIdsList\n",
    "len(bookUniqueIdsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookReadByUserIds = {}\n",
    "for user, book, rating in bookData:\n",
    "    if user in bookReadByUserIds:\n",
    "        bookReadByUserIds[user].add(book)\n",
    "    else:\n",
    "        bookReadByUserIds[user] = set()\n",
    "        bookReadByUserIds[user].add(book)\n",
    "#bookReadByUserIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNegativeEntries():\n",
    "    bookDataValidNeg = []\n",
    "    bookDataYValidNeg = [0] * len(bookDataValidPos)\n",
    "    for user, book, rating in bookDataValidPos:\n",
    "        #while True:\n",
    "            #unreadBookId = random.choice(bookUniqueIdsList)\n",
    "        # For consistent validation set\n",
    "        for unreadBookId in bookUniqueIdsList:\n",
    "            if unreadBookId not in bookReadByUserIds[user]:\n",
    "                bookDataValidNeg.append([user, unreadBookId, \"-1\"])\n",
    "                break\n",
    "    return bookDataValidNeg, bookDataYValidNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "bookDataValidNeg, bookDataYValidNeg = getNegativeEntries()\n",
    "bookDataValid = bookDataValidPos + bookDataValidNeg\n",
    "bookDataYValid = bookDataYValidPos + bookDataYValidNeg\n",
    "print(len(bookDataValid))\n",
    "print(len(bookDataYValid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutValidationSet(nameTag):\n",
    "    timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    fileName = \"validation_set_\" + timestr + \"_validMSE_\" + nameTag + \".txt\"\n",
    "    outFile = open(fileName, 'w')\n",
    "    \n",
    "    # Write out current validation set\n",
    "    for data, y in zip(bookDataValid, bookDataYValid):\n",
    "        outFile.write(data[0] + '-' + data[1] + \",\" + str(y) + \"\\n\")\n",
    "\n",
    "    outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBaselinePred(Xdata, threshold):\n",
    "    ### Would-read baseline: just rank which books are popular and which are not, and return '1' if a book is among the top-ranked\n",
    "    bookCount = defaultdict(int)\n",
    "    totalRead = 0\n",
    "    \n",
    "    for user, book, _ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "        bookCount[book] += 1\n",
    "        totalRead += 1\n",
    "        \n",
    "    mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "    \n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for bkc, bkId in mostPopular:\n",
    "        count += bkc\n",
    "        return1.add(bkId)\n",
    "        if count > totalRead/threshold: break\n",
    "            \n",
    "    # Make prediction\n",
    "    prediction = []\n",
    "    for uId, bId, rating in Xdata:\n",
    "        if bId in return1:\n",
    "            prediction.append(1)\n",
    "        else:\n",
    "            prediction.append(0)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAcc(pred, golden):\n",
    "    correctPredictions = [p==y for p, y in zip(pred, golden)]\n",
    "    return sum(correctPredictions) / len(golden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTPR(pred, golden):\n",
    "    TP = sum([(p and l) for (p,l) in zip(pred, golden)])\n",
    "    FN = sum([(not p and l) for (p,l) in zip(pred, golden)])\n",
    "    return TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTNR(pred, golden):\n",
    "    FP = sum([(p and not l) for (p,l) in zip(pred, golden)])\n",
    "    TN = sum([(not p and not l) for (p,l) in zip(pred, golden)])\n",
    "    return TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(pred, golden):\n",
    "    TNR = getTNR(pred, golden)\n",
    "    TPR = getTPR(pred, golden)\n",
    "    acc = getAcc(pred, golden)\n",
    "    return (acc, TPR, TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "20000\n",
      "0.7484\n"
     ]
    }
   ],
   "source": [
    "predBookDataYValid = getBaselinePred(bookDataValid, 2.0)\n",
    "print(len(predBookDataYValid))\n",
    "print(len(bookDataYValid))\n",
    "\n",
    "# Accurarcy\n",
    "predBookDataValidMSE = getAcc(predBookDataYValid, bookDataYValid)\n",
    "print(predBookDataValidMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutValidationSet(str(predBookDataValidMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The existing ‘read prediction’ baseline just returns True if the item in question is ‘popular,’ using a threshold of the 50th percentile of popularity (totalRead/2).\n",
    "Assuming that the ‘non-read’ test examples are a random sample of user-book pairs, this threshold may not be the best one. See if you can find a better threshold and report its performance on your validatin set.\n",
    "\n",
    "Ans: <br>\n",
    "Threshold = 1.250000, i.e. 80th percentile of popularity <br>\n",
    "Accurarcy on validation set: 0.899000 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion: t=1.000000, acc=0.500000, TPR=1.000000, TNR=0.000000\n",
      "Validataion: t=1.050000, acc=0.478050, TPR=0.954800, TNR=0.001300\n",
      "Validataion: t=1.100000, acc=0.454450, TPR=0.907600, TNR=0.001300\n",
      "Validataion: t=1.150000, acc=0.433650, TPR=0.866000, TNR=0.001300\n",
      "Validataion: t=1.200000, acc=0.416400, TPR=0.831500, TNR=0.001300\n",
      "Validataion: t=1.250000, acc=0.899000, TPR=0.798000, TNR=1.000000\n",
      "Validataion: t=1.300000, acc=0.881850, TPR=0.763700, TNR=1.000000\n",
      "Validataion: t=1.350000, acc=0.866700, TPR=0.733400, TNR=1.000000\n",
      "Validataion: t=1.400000, acc=0.853350, TPR=0.706700, TNR=1.000000\n",
      "Validataion: t=1.450000, acc=0.841500, TPR=0.683000, TNR=1.000000\n",
      "Validataion: t=1.500000, acc=0.829650, TPR=0.659300, TNR=1.000000\n",
      "Validataion: t=1.550000, acc=0.818400, TPR=0.636800, TNR=1.000000\n",
      "Validataion: t=1.600000, acc=0.808550, TPR=0.617100, TNR=1.000000\n",
      "Validataion: t=1.650000, acc=0.798950, TPR=0.597900, TNR=1.000000\n",
      "Validataion: t=1.700000, acc=0.790300, TPR=0.580600, TNR=1.000000\n",
      "Validataion: t=1.750000, acc=0.782900, TPR=0.565800, TNR=1.000000\n",
      "Validataion: t=1.800000, acc=0.775400, TPR=0.550800, TNR=1.000000\n",
      "Validataion: t=1.850000, acc=0.767550, TPR=0.535100, TNR=1.000000\n",
      "Validataion: t=1.900000, acc=0.761150, TPR=0.522300, TNR=1.000000\n",
      "Validataion: t=1.950000, acc=0.753950, TPR=0.507900, TNR=1.000000\n",
      "Validataion: t=2.000000, acc=0.748400, TPR=0.496800, TNR=1.000000\n",
      "Validataion: t=2.050000, acc=0.742450, TPR=0.484900, TNR=1.000000\n",
      "Validataion: t=2.100000, acc=0.736100, TPR=0.472200, TNR=1.000000\n",
      "Validataion: t=2.150000, acc=0.730100, TPR=0.460200, TNR=1.000000\n",
      "Validataion: t=2.200000, acc=0.724200, TPR=0.448400, TNR=1.000000\n",
      "Validataion: t=2.250000, acc=0.720400, TPR=0.440800, TNR=1.000000\n",
      "Validataion: t=2.300000, acc=0.716100, TPR=0.432200, TNR=1.000000\n",
      "Validataion: t=2.350000, acc=0.711450, TPR=0.422900, TNR=1.000000\n",
      "Validataion: t=2.400000, acc=0.706750, TPR=0.413500, TNR=1.000000\n",
      "Validataion: t=2.450000, acc=0.702800, TPR=0.405600, TNR=1.000000\n",
      "Validataion: t=2.500000, acc=0.699050, TPR=0.398100, TNR=1.000000\n",
      "Validataion: t=2.550000, acc=0.695450, TPR=0.390900, TNR=1.000000\n",
      "Validataion: t=2.600000, acc=0.691200, TPR=0.382400, TNR=1.000000\n",
      "Validataion: t=2.650000, acc=0.687300, TPR=0.374600, TNR=1.000000\n",
      "Validataion: t=2.700000, acc=0.683650, TPR=0.367300, TNR=1.000000\n",
      "Validataion: t=2.750000, acc=0.680600, TPR=0.361200, TNR=1.000000\n",
      "Validataion: t=2.800000, acc=0.677000, TPR=0.354000, TNR=1.000000\n",
      "Validataion: t=2.850000, acc=0.674550, TPR=0.349100, TNR=1.000000\n",
      "Validataion: t=2.900000, acc=0.671150, TPR=0.342300, TNR=1.000000\n",
      "Validataion: t=2.950000, acc=0.668200, TPR=0.336400, TNR=1.000000\n"
     ]
    }
   ],
   "source": [
    "for thres in np.arange(1, 3, 0.05):\n",
    "    #predBookDataYTrain = getBaselinePred(bookDataTrain, thres)\n",
    "    # Accurarcy for training set\n",
    "    #correctPredictions = [p==y for p, y in zip(predBookDataYTrain, bookDataYTrain)]\n",
    "    #print(\"Training: t=%f, acc=%f\" % (thres, sum(correctPredictions) / len(bookDataYTrain)) )\n",
    "    \n",
    "    predBookDataYValid = getBaselinePred(bookDataValid, thres)\n",
    "    # Accurarcy for validation set\n",
    "    acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "    print(\"Validataion: t=%f, acc=%f, TPR=%f, TNR=%f\" % (thres, acc, TPR, TNR) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutBaselinePred(threshold):\n",
    "    ### Would-read baseline: just rank which books are popular and which are not, and return '1' if a book is among the top-ranked\n",
    "    bookCount = defaultdict(int)\n",
    "    totalRead = 0\n",
    "    \n",
    "    for user, book, _ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "        bookCount[book] += 1\n",
    "        totalRead += 1\n",
    "    \n",
    "    mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "    \n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for bkc, bkId in mostPopular:\n",
    "        count += bkc\n",
    "        return1.add(bkId)\n",
    "        if count > totalRead/threshold: break\n",
    "    \n",
    "    predOutFile = open(\"predictions_Read.txt\", 'w')\n",
    "    for l in open(\"pairs_Read.txt\", 'r'):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predOutFile.write(l)\n",
    "            continue\n",
    "        uId, bId = l.strip().split('-')\n",
    "        if bId in return1:\n",
    "            predOutFile.write(uId + '-' + bId + \",1\\n\")\n",
    "        else:\n",
    "            predOutFile.write(uId + '-' + bId + \",0\\n\")\n",
    "    predOutFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutBaselinePred(1.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. A stronger baseline than the one provided might make use of the Jaccard similarity (or another similarity metric). Given a pair (u, b) in the validation set, consider all training items b′ that user u has read.\n",
    "For each, compute the Jaccard similarity between b and b′, i.e., users (in the training set) who have read ′\n",
    "b and users who have read b . Predict as ‘read’ if the maximum of these Jaccard similarities exceeds a threshold (you may choose the threshold that works best). Report the performance on your validation set (1 mark).\n",
    "\n",
    "Ans: <br>\n",
    "Choose the threshold with the best accurarcy on validation set: threshold = 0.010000<br>\n",
    "Accurarcy on the validation set: 0.689850 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['u79354815', 'b14275065', 4],\n",
       " ['u56917948', 'b82152306', 5],\n",
       " ['u97915914', 'b44882292', 5],\n",
       " ['u49688858', 'b79927466', 5],\n",
       " ['u08384938', 'b05683889', 2],\n",
       " ['u13530776', 'b86375465', 4],\n",
       " ['u46307273', 'b92838791', 5],\n",
       " ['u18524450', 'b35165110', 2],\n",
       " ['u69700998', 'b17128180', 5],\n",
       " ['u43359569', 'b34596567', 5]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookDataTrain[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in bookDataTrain:\n",
    "    usersPerItem[d[1]].add(d[0])\n",
    "    itemsPerUser[d[0]].add(d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairSimilarity(u, b):\n",
    "    similarities = []\n",
    "    users = usersPerItem[b]\n",
    "    candidateItems = itemsPerUser[u]\n",
    "    for b2 in candidateItems:\n",
    "        if b2 == b: continue\n",
    "        sim = Jaccard(users, usersPerItem[b2])\n",
    "        similarities.append((sim,b2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJaccardPred(Xdata, threshold):      \n",
    "    # Make prediction\n",
    "    prediction = []\n",
    "    for uId, bId, rating in Xdata:\n",
    "        #print(\"Query: userId: %s, bookId: %s\" % (uId, bId))\n",
    "        #print(itemsPerUser[uId])\n",
    "        sim = pairSimilarity(uId, bId)\n",
    "        #print(sim[0][0])\n",
    "        \n",
    "        if sim and sim[0][0] > threshold:\n",
    "            prediction.append(1)\n",
    "        else:\n",
    "            prediction.append(0)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion: t=0.000000, acc=0.665700, TPR=0.920400, TNR=0.411000\n",
      "Validataion: t=0.001000, acc=0.665700, TPR=0.920400, TNR=0.411000\n",
      "Validataion: t=0.002000, acc=0.665700, TPR=0.920400, TNR=0.411000\n",
      "Validataion: t=0.003000, acc=0.671850, TPR=0.919100, TNR=0.424600\n",
      "Validataion: t=0.004000, acc=0.670100, TPR=0.915600, TNR=0.424600\n",
      "Validataion: t=0.005000, acc=0.672850, TPR=0.908800, TNR=0.436900\n",
      "Validataion: t=0.006000, acc=0.677800, TPR=0.898900, TNR=0.456700\n",
      "Validataion: t=0.007000, acc=0.682100, TPR=0.885500, TNR=0.478700\n",
      "Validataion: t=0.008000, acc=0.686800, TPR=0.869300, TNR=0.504300\n",
      "Validataion: t=0.009000, acc=0.689350, TPR=0.848700, TNR=0.530000\n",
      "Validataion: t=0.010000, acc=0.689850, TPR=0.819700, TNR=0.560000\n",
      "Validataion: t=0.011000, acc=0.681400, TPR=0.788900, TNR=0.573900\n",
      "Validataion: t=0.012000, acc=0.679250, TPR=0.756100, TNR=0.602400\n",
      "Validataion: t=0.013000, acc=0.667650, TPR=0.713700, TNR=0.621600\n",
      "Validataion: t=0.014000, acc=0.654550, TPR=0.674100, TNR=0.635000\n",
      "Validataion: t=0.015000, acc=0.639950, TPR=0.627500, TNR=0.652400\n",
      "Validataion: t=0.016000, acc=0.631200, TPR=0.583500, TNR=0.678900\n",
      "Validataion: t=0.017000, acc=0.617300, TPR=0.539200, TNR=0.695400\n",
      "Validataion: t=0.018000, acc=0.604650, TPR=0.496700, TNR=0.712600\n",
      "Validataion: t=0.019000, acc=0.591600, TPR=0.452600, TNR=0.730600\n",
      "Validataion: t=0.020000, acc=0.580350, TPR=0.407600, TNR=0.753100\n",
      "Validataion: t=0.021000, acc=0.567900, TPR=0.370000, TNR=0.765800\n",
      "Validataion: t=0.022000, acc=0.554250, TPR=0.335200, TNR=0.773300\n",
      "Validataion: t=0.023000, acc=0.552200, TPR=0.304400, TNR=0.800000\n",
      "Validataion: t=0.024000, acc=0.543850, TPR=0.272200, TNR=0.815500\n",
      "Validataion: t=0.025000, acc=0.541250, TPR=0.241200, TNR=0.841300\n",
      "Validataion: t=0.026000, acc=0.531850, TPR=0.218900, TNR=0.844800\n",
      "Validataion: t=0.027000, acc=0.524350, TPR=0.202000, TNR=0.846700\n",
      "Validataion: t=0.028000, acc=0.520700, TPR=0.176800, TNR=0.864600\n",
      "Validataion: t=0.029000, acc=0.517750, TPR=0.159500, TNR=0.876000\n"
     ]
    }
   ],
   "source": [
    "for thres in np.arange(0, 0.03, 0.001):\n",
    "    predBookDataYValid = getJaccardPred(bookDataValid, thres)\n",
    "    # Accurarcy for validation set\n",
    "    acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "    print(\"Validataion: t=%f, acc=%f, TPR=%f, TNR=%f\" % (thres, acc, TPR, TNR) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutJaccardPred(threshold):  \n",
    "    predOutFile = open(\"predictions_Read.txt\", 'w')\n",
    "    bookDataTest = []\n",
    "    \n",
    "    # Read Testing set\n",
    "    for l in open(\"pairs_Read.txt\", 'r'):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predOutFile.write(l)\n",
    "            continue\n",
    "        uId, bId = l.strip().split('-')\n",
    "        bookDataTest.append([uId, bId, -1])\n",
    "    \n",
    "    # Predict by Jaccard\n",
    "    bookDataYTest = getJaccardPred(bookDataTest, threshold)\n",
    "    \n",
    "    # Write out prediction result\n",
    "    for data, y in zip(bookDataTest, bookDataYTest):\n",
    "        predOutFile.write(data[0] + '-' + data[1] + \",\" + str(y) + \"\\n\")\n",
    "\n",
    "    predOutFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutJaccardPred(0.011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutJaccardPred(0.008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutJaccardPred(0.013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Improve the above predictor by incorporating both a Jaccard-based threshold and a popularity based threshold. Report the performance on your validation set.\n",
    "\n",
    "Ans: <br>\n",
    "The proposed methods: to mix the results from various of threshold of the two predictors by AND or OR.<br>\n",
    "Mix1 (OR):<br>\n",
    "Accurarcy: 0.86185<br>\n",
    "TPR: 0.8591<br>\n",
    "TNR: 0.8646<br>\n",
    "Threshold of Jaccard prediction: 0.028<br>\n",
    "Threshold of Baseline prediction: 1.25 (80th percentile of popularity)<br>\n",
    "\n",
    "Mix2 (AND):<br>\n",
    "Accurarcy: 0.88385<br>\n",
    "TPR: 0.7677<br>\n",
    "TNR: 1.0<br>\n",
    "Threshold of Jaccard prediction: 0.002<br>\n",
    "Threshold of Baseline prediction: 1.25 (80th percentile of popularity)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:10<00:00, 16.67s/it]\n"
     ]
    }
   ],
   "source": [
    "mix1Result = []\n",
    "mix2Result = []\n",
    "\n",
    "for thresJac in tqdm(np.arange(0, 0.03, 0.002)):\n",
    "    jacPredBookDataYValid = getJaccardPred(bookDataValid, thresJac)\n",
    "\n",
    "    for thresBase in np.arange(1, 3, 0.05):\n",
    "        basePredBookDataYValid = getBaselinePred(bookDataValid, thresBase)\n",
    "        \n",
    "        mix1PredBookDataYValid = []\n",
    "        mix2PredBookDataYValid = []\n",
    "\n",
    "        for jacPred, basePred in zip(jacPredBookDataYValid, basePredBookDataYValid):\n",
    "            if jacPred == basePred:\n",
    "                mix1PredBookDataYValid.append(jacPred)\n",
    "                mix2PredBookDataYValid.append(jacPred)\n",
    "            elif jacPred > basePred:\n",
    "                mix1PredBookDataYValid.append(jacPred)\n",
    "                mix2PredBookDataYValid.append(basePred)\n",
    "            elif basePred > jacPred:\n",
    "                mix1PredBookDataYValid.append(basePred)\n",
    "                mix2PredBookDataYValid.append(jacPred)\n",
    "\n",
    "        acc, TPR, TNR = getMetrics(mix1PredBookDataYValid, bookDataYValid)\n",
    "        #print(\"Validataion Mix1: tJaccard=%f, tBaseline=%f, acc=%f, TPR=%f, TNR=%f\" % (thresJac, thresBase, acc, TPR, TNR) )\n",
    "        mix1Result.append((acc,TPR,TNR,thresJac,thresBase))\n",
    "        \n",
    "        acc, TPR, TNR = getMetrics(mix2PredBookDataYValid, bookDataYValid)\n",
    "        #print(\"Validataion Mix2: tJaccard=%f, tBaseline=%f, acc=%f, TPR=%f, TNR=%f\" % (thresJac, thresBase, acc, TPR, TNR) )\n",
    "        mix2Result.append((acc,TPR,TNR,thresJac,thresBase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix1Result.sort(reverse=True)\n",
    "mix2Result.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.86185, 0.8591, 0.8646, 0.028, 1.2500000000000002),\n",
       " (0.85555, 0.8663, 0.8448, 0.026000000000000002, 1.2500000000000002),\n",
       " (0.85005, 0.8355, 0.8646, 0.028, 1.3000000000000003),\n",
       " (0.84465, 0.8445, 0.8448, 0.026000000000000002, 1.3000000000000003),\n",
       " (0.8442, 0.8729, 0.8155, 0.024, 1.2500000000000002),\n",
       " (0.83865, 0.8127, 0.8646, 0.028, 1.3500000000000003),\n",
       " (0.8346, 0.8244, 0.8448, 0.026000000000000002, 1.3500000000000003),\n",
       " (0.8338, 0.8521, 0.8155, 0.024, 1.3000000000000003),\n",
       " (0.82975, 0.7949, 0.8646, 0.028, 1.4000000000000004),\n",
       " (0.82665, 0.88, 0.7733, 0.022, 1.2500000000000002),\n",
       " (0.82635, 0.8079, 0.8448, 0.026000000000000002, 1.4000000000000004),\n",
       " (0.82445, 0.8334, 0.8155, 0.024, 1.3500000000000003),\n",
       " (0.821, 0.7774, 0.8646, 0.028, 1.4500000000000004),\n",
       " (0.8198, 0.8865, 0.7531, 0.02, 1.2500000000000002),\n",
       " (0.8184, 0.792, 0.8448, 0.026000000000000002, 1.4500000000000004),\n",
       " (0.8174, 0.8615, 0.7733, 0.022, 1.3000000000000003),\n",
       " (0.81685, 0.8182, 0.8155, 0.024, 1.4000000000000004),\n",
       " (0.8117, 0.7588, 0.8646, 0.028, 1.5000000000000004),\n",
       " (0.81155, 0.87, 0.7531, 0.02, 1.3000000000000003),\n",
       " (0.8098, 0.7748, 0.8448, 0.026000000000000002, 1.5000000000000004),\n",
       " (0.8095, 0.8035, 0.8155, 0.024, 1.4500000000000004),\n",
       " (0.8092, 0.8451, 0.7733, 0.022, 1.3500000000000003),\n",
       " (0.80425, 0.8554, 0.7531, 0.02, 1.3500000000000003),\n",
       " (0.8038, 0.895, 0.7126, 0.018000000000000002, 1.2500000000000002),\n",
       " (0.80295, 0.7413, 0.8646, 0.028, 1.5500000000000005),\n",
       " (0.80245, 0.8316, 0.7733, 0.022, 1.4000000000000004),\n",
       " (0.8023, 0.7598, 0.8448, 0.026000000000000002, 1.5500000000000005),\n",
       " (0.8015, 0.7875, 0.8155, 0.024, 1.5000000000000004),\n",
       " (0.79815, 0.8432, 0.7531, 0.02, 1.4000000000000004),\n",
       " (0.79625, 0.8799, 0.7126, 0.018000000000000002, 1.3000000000000003)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix1Result[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.88385, 0.7677, 1.0, 0.002, 1.2500000000000002),\n",
       " (0.88385, 0.7677, 1.0, 0.0, 1.2500000000000002),\n",
       " (0.8823, 0.7646, 1.0, 0.004, 1.2500000000000002),\n",
       " (0.877, 0.754, 1.0, 0.006, 1.2500000000000002),\n",
       " (0.86925, 0.7385, 1.0, 0.002, 1.3000000000000003),\n",
       " (0.86925, 0.7385, 1.0, 0.0, 1.3000000000000003),\n",
       " (0.86785, 0.7357, 1.0, 0.004, 1.3000000000000003),\n",
       " (0.86605, 0.7321, 1.0, 0.008, 1.2500000000000002),\n",
       " (0.86295, 0.7259, 1.0, 0.006, 1.3000000000000003),\n",
       " (0.8558, 0.7116, 1.0, 0.002, 1.3500000000000003),\n",
       " (0.8558, 0.7116, 1.0, 0.0, 1.3500000000000003),\n",
       " (0.85465, 0.7093, 1.0, 0.004, 1.3500000000000003),\n",
       " (0.85255, 0.7051, 1.0, 0.008, 1.3000000000000003),\n",
       " (0.8501, 0.7002, 1.0, 0.006, 1.3500000000000003),\n",
       " (0.84635, 0.6927, 1.0, 0.01, 1.2500000000000002),\n",
       " (0.84385, 0.6877, 1.0, 0.002, 1.4000000000000004),\n",
       " (0.84385, 0.6877, 1.0, 0.0, 1.4000000000000004),\n",
       " (0.8428, 0.6856, 1.0, 0.004, 1.4000000000000004),\n",
       " (0.8403, 0.6806, 1.0, 0.008, 1.3500000000000003),\n",
       " (0.8387, 0.6774, 1.0, 0.006, 1.4000000000000004),\n",
       " (0.83365, 0.6673, 1.0, 0.01, 1.3000000000000003),\n",
       " (0.83285, 0.6657, 1.0, 0.002, 1.4500000000000004),\n",
       " (0.83285, 0.6657, 1.0, 0.0, 1.4500000000000004),\n",
       " (0.83195, 0.6639, 1.0, 0.004, 1.4500000000000004),\n",
       " (0.82925, 0.6585, 1.0, 0.008, 1.4000000000000004),\n",
       " (0.828, 0.656, 1.0, 0.006, 1.4500000000000004),\n",
       " (0.8222, 0.6444, 1.0, 0.01, 1.3500000000000003),\n",
       " (0.82185, 0.6437, 1.0, 0.002, 1.5000000000000004),\n",
       " (0.82185, 0.6437, 1.0, 0.0, 1.5000000000000004),\n",
       " (0.82105, 0.6421, 1.0, 0.004, 1.5000000000000004)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix2Result[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutMixture1Pred(thresJac, thresBase):  \n",
    "    predOutMix1File = open(\"predictions_Read_mix1.txt\", 'w')\n",
    "    bookDataTest = []\n",
    "    \n",
    "    # Read Testing set\n",
    "    for l in open(\"pairs_Read.txt\", 'r'):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predOutMix1File.write(l)\n",
    "            continue\n",
    "        uId, bId = l.strip().split('-')\n",
    "        bookDataTest.append([uId, bId, -1])\n",
    "    \n",
    "    # Predict by Jaccard\n",
    "    jacPredBookDataYValid = getJaccardPred(bookDataTest, thresJac)\n",
    "    basePredBookDataYValid = getBaselinePred(bookDataTest, thresBase)\n",
    "    mix1PredBookDataYValid = []\n",
    "    \n",
    "    for jacPred, basePred in zip(jacPredBookDataYValid, basePredBookDataYValid):\n",
    "        if jacPred == basePred:\n",
    "            mix1PredBookDataYValid.append(jacPred)\n",
    "        elif jacPred > basePred:\n",
    "            mix1PredBookDataYValid.append(jacPred)\n",
    "        elif basePred > jacPred:\n",
    "            mix1PredBookDataYValid.append(basePred)\n",
    "                \n",
    "    # Write out prediction result for mix1 model\n",
    "    for data, y in zip(bookDataTest, mix1PredBookDataYValid):\n",
    "        predOutMix1File.write(data[0] + '-' + data[1] + \",\" + str(y) + \"\\n\")\n",
    "\n",
    "    predOutMix1File.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutMixture2Pred(thresJac, thresBase):  \n",
    "    predOutMix2File = open(\"predictions_Read_mix2.txt\", 'w')\n",
    "    bookDataTest = []\n",
    "    \n",
    "    # Read Testing set\n",
    "    for l in open(\"pairs_Read.txt\", 'r'):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predOutMix2File.write(l)\n",
    "            continue\n",
    "        uId, bId = l.strip().split('-')\n",
    "        bookDataTest.append([uId, bId, -1])\n",
    "    \n",
    "    # Predict by Jaccard\n",
    "    jacPredBookDataYValid = getJaccardPred(bookDataTest, thresJac)\n",
    "    basePredBookDataYValid = getBaselinePred(bookDataTest, thresBase)\n",
    "    mix2PredBookDataYValid = []\n",
    "    \n",
    "    for jacPred, basePred in zip(jacPredBookDataYValid, basePredBookDataYValid):\n",
    "        if jacPred == basePred:\n",
    "            mix2PredBookDataYValid.append(jacPred)\n",
    "        elif jacPred > basePred:\n",
    "            mix2PredBookDataYValid.append(basePred)\n",
    "        elif basePred > jacPred:\n",
    "            mix2PredBookDataYValid.append(jacPred)\n",
    "\n",
    "    # Write out prediction result for mix2 model\n",
    "    for data, y in zip(bookDataTest, mix2PredBookDataYValid):\n",
    "        predOutMix2File.write(data[0] + '-' + data[1] + \",\" + str(y) + \"\\n\")\n",
    "\n",
    "    predOutMix2File.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutMixture2Pred(0.002, 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutMixture1Pred(0.028, 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. To run our model on the test set, we’ll have to use the files ‘pairs Read.txt’ to find the reviewerID/itemID pairs about which we have to make predictions.\n",
    "Using that data, run the above model and upload your solution to Kaggle. Tell us your Kaggle user name (1 mark). If you’ve already uploaded a better solution to Kaggle, that’s fine too!\n",
    "\n",
    "Ans: <br>\n",
    "Display Name: JamesTcl <br>\n",
    "User Name: k2973363 <br>\n",
    "Email Address: til002@eng.ucsd.edu <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (CSE 258 only) Tasks (Rating prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start by building our training/validation sets much as we did for the first task. This time building a validation set is more straightforward: you can simply use part of the data for validation, and do not need to randomly sample non-read users/books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rating baseline: compute averages for each user, or return the global average if we've never seen the user before\n",
    "\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "\n",
    "for user,book,r in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    r = int(r)\n",
    "    allRatings.append(r)\n",
    "    userRatings[user].append(r)\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "for u in userRatings:\n",
    "    userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "\n",
    "predictions = open(\"predictions_Rating.txt\", 'w')\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split('-')\n",
    "    \n",
    "    if u in userAverage:\n",
    "        predictions.write(u + '-' + b + ',' + str(userAverage[u]) + '\\n')\n",
    "    else:\n",
    "        predictions.write(u + '-' + b + ',' + str(globalAverage) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Fit a predictor of the form by fitting the mean and the two bias terms as described in the lecture notes.\n",
    "Use a regularization parameter of λ = 1. Report the MSE on the validation set.\n",
    "\n",
    "Ans: <br>\n",
    "Separate 70% of data as training set, and the rest of 30% of data as validation set. <br>\n",
    "MSE on the validation set: 1.4613473974773903 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199800\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# Shuffle First?\n",
    "numTraining = int(len(bookData) * 0.999)\n",
    "bookDataTrain = bookData[:numTraining]\n",
    "bookDataValid = bookData[numTraining:]\n",
    "print(len(bookDataTrain))\n",
    "print(len(bookDataValid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "\n",
    "for userId,bookId,r in bookDataTrain:\n",
    "    reviewsPerUser[userId].append(r)\n",
    "    reviewsPerItem[bookId].append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(bookDataTrain)\n",
    "nUsers = len(reviewsPerUser)\n",
    "nItems = len(reviewsPerItem)\n",
    "users = list(reviewsPerUser.keys())\n",
    "items = list(reviewsPerItem.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.896746746746747"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingMean = sum([d[2] for d in bookDataTrain]) / len(bookDataTrain)\n",
    "ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.896746746746747"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = ratingMean\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, item):\n",
    "    userBias = 0\n",
    "    itemBias = 0\n",
    "    if user in userBiases:\n",
    "        userBias = userBiases[user]\n",
    "    if item in itemBiases:\n",
    "        itemBias = itemBiases[item]\n",
    "        \n",
    "    return alpha + userBias + itemBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1:nUsers+1]))\n",
    "    itemBiases = dict(zip(items, theta[1+nUsers:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    \n",
    "    # MSE cost Term\n",
    "    predictions = [prediction(uId, bId) for uId, bId, r in bookDataTrain]\n",
    "    cost = MSE(predictions, labels)\n",
    "    # print(\"MSE = \" + str(cost))\n",
    "    \n",
    "    # Regulariztion Terms\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, labels, lambU, lambB):\n",
    "    unpack(theta)\n",
    "    \n",
    "    # MSE cost Term\n",
    "    predictions = [prediction(uId, bId) for uId, bId, r in bookDataTrain]\n",
    "    cost = MSE(predictions, labels)\n",
    "    # print(\"MSE = \" + str(cost))\n",
    "    \n",
    "    # Regulariztion Terms\n",
    "    for u in userBiases:\n",
    "        cost += lambU*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lambB*itemBiases[i]**2\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(bookDataTrain)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    \n",
    "    for uId, bId, r in bookDataTrain:\n",
    "        pred = prediction(uId, bId)\n",
    "        diff = pred - r\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[uId] += 2/N*diff\n",
    "        dItemBiases[bId] += 2/N*diff\n",
    "    for uId in userBiases:\n",
    "        dUserBiases[uId] += 2*lamb*userBiases[uId]\n",
    "    for bId in itemBiases:\n",
    "        dItemBiases[bId] += 2*lamb*itemBiases[bId]\n",
    "\n",
    "    dtheta = [dalpha] + [dUserBiases[uId] for uId in users] + [dItemBiases[bId] for bId in items]\n",
    "\n",
    "    return np.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(theta, labels, lambU, lambB):\n",
    "    unpack(theta)\n",
    "    N = len(bookDataTrain)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    \n",
    "    for uId, bId, r in bookDataTrain:\n",
    "        pred = prediction(uId, bId)\n",
    "        diff = pred - r\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[uId] += 2/N*diff\n",
    "        dItemBiases[bId] += 2/N*diff\n",
    "    for uId in userBiases:\n",
    "        dUserBiases[uId] += 2*lambU*userBiases[uId]\n",
    "    for bId in itemBiases:\n",
    "        dItemBiases[bId] += 2*lambB*itemBiases[bId]\n",
    "\n",
    "    dtheta = [dalpha] + [dUserBiases[uId] for uId in users] + [dItemBiases[bId] for bId in items]\n",
    "\n",
    "    return np.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "alwaysPredictMean = [ratingMean for d in bookDataTrain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [r for uId,bId,r in bookDataTrain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4743637907149336"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(alwaysPredictMean, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-c93734bd30dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnUsers\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnItems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderivative\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.000001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[1;32m--> 199\u001b[1;33m                            **opts)\n\u001b[0m\u001b[0;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[0;32m    201\u001b[0m          \u001b[1;34m'task'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-107-ba7626166cfe>\u001b[0m in \u001b[0;36mcost\u001b[1;34m(theta, labels, lambU, lambB)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# MSE cost Term\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbId\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0muId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbookDataTrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m# print(\"MSE = \" + str(cost))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-96-2dfcf7663b38>\u001b[0m in \u001b[0;36mMSE\u001b[1;34m(predictions, labels)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdifferences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdifferences\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdifferences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-96-2dfcf7663b38>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdifferences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdifferences\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdifferences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0]*(nUsers+nItems), derivative, args = (labels, 0.000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [prediction(uId, bId) for uId, bId, r in bookDataValid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsValid = [r for uId,bId,r in bookDataValid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-da59264453df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# lambda = 0.001, MSE=1.3215213938145665\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelsValid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-2dfcf7663b38>\u001b[0m in \u001b[0;36mMSE\u001b[1;34m(predictions, labels)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdifferences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdifferences\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdifferences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# lambda = 0.001, MSE=1.3215213938145665\n",
    "MSE(predictions, labelsValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutTestSetPred(0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Report the user and book IDs that have the largest and smallest values of β\n",
    "\n",
    "Ans: <br>\n",
    "user ID with largest values of β: u92864068<br>\n",
    "user ID with smallest values of β: u11591742<br>\n",
    "book ID with largest values of β: b76915592<br>\n",
    "book ID with smallest values of β: b80820222<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "userBiasesList = [(bias, uId) for uId, bias in userBiases.items()]\n",
    "userBiasesList.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0004446173289278906, 'u92864068')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userBiasesList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0014061416249505658, 'u11591742')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userBiasesList[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemBiasesList = [(bias, bId) for bId, bias in itemBiases.items()]\n",
    "itemBiasesList.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0007608030421973806, 'b76915592')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemBiasesList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0002643354810743335, 'b80820222')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemBiasesList[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Find a better value of λ using your validation set. Report the value you chose, its MSE, and upload your solution to Kaggle by running it on the test data\n",
    "\n",
    "Ans: <br>\n",
    "Choose the λ with lowest MSE on the validation set, where λ = 0.0000100000<br>\n",
    "MSE on the validation set: 1.123269<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutTestSetPred(lambdaVal):\n",
    "    fileName = \"predictions_Rating_\" + str(lambdaVal) + \".txt\"\n",
    "    predictions = open(fileName, 'w')\n",
    "    for l in open(\"pairs_Rating.txt\"):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        uId,bId = l.strip().split('-')\n",
    "        predictions.write(uId + '-' + bId + ',' + str(prediction(uId, bId)) + '\\n')\n",
    "\n",
    "    predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0.0000000100, MSE of validation set = 1.090233\n",
      "Lambda: 0.0000001000, MSE of validation set = 1.090632\n",
      "Lambda: 0.0000010000, MSE of validation set = 1.084642\n",
      "Lambda: 0.0000100000, MSE of validation set = 1.055671\n",
      "Lambda: 0.0001000000, MSE of validation set = 1.123791\n",
      "Lambda: 0.0010000000, MSE of validation set = 1.409054\n",
      "Lambda: 0.0100000000, MSE of validation set = 1.511142\n",
      "Lambda: 0.1000000000, MSE of validation set = 1.524507\n",
      "Lambda: 1.0000000000, MSE of validation set = 1.525889\n",
      "Lambda: 10.0000000000, MSE of validation set = 1.526028\n"
     ]
    }
   ],
   "source": [
    "lambdaExpList = range(-8,2)\n",
    "for exp in lambdaExpList:\n",
    "    # Train the model\n",
    "    l = pow(10,exp)\n",
    "    scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0]*(nUsers+nItems), derivative, args = (labels, l))\n",
    "    \n",
    "    # Predict from the model\n",
    "    predictions = [prediction(uId, bId) for uId, bId, r in bookDataValid]\n",
    "    labelsValid = [r for uId,bId,r in bookDataValid]\n",
    "    mse = MSE(predictions, labelsValid)\n",
    "    print(\"Lambda: %.10f, MSE of validation set = %f\" % (l, mse))\n",
    "    writeOutTestSetPred(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda User: 0.0000000100, LambdaBook: 0.0000000100, MSE of validation set = 1.090195\n",
      "Lambda User: 0.0000000100, LambdaBook: 0.0000001000, MSE of validation set = 1.089946\n",
      "Lambda User: 0.0000000100, LambdaBook: 0.0000010000, MSE of validation set = 1.088485\n",
      "Lambda User: 0.0000000100, LambdaBook: 0.0000100000, MSE of validation set = 1.077746\n",
      "Lambda User: 0.0000000100, LambdaBook: 0.0001000000, MSE of validation set = 1.051554\n",
      "Lambda User: 0.0000000100, LambdaBook: 0.0010000000, MSE of validation set = 1.069833\n",
      "Lambda User: 0.0000000100, LambdaBook: 0.0100000000, MSE of validation set = 1.090463\n",
      "Lambda User: 0.0000000100, LambdaBook: 0.1000000000, MSE of validation set = 1.093897\n",
      "Lambda User: 0.0000000100, LambdaBook: 1.0000000000, MSE of validation set = 1.094456\n",
      "Lambda User: 0.0000000100, LambdaBook: 10.0000000000, MSE of validation set = 1.094563\n",
      "Lambda User: 0.0000000100, LambdaBook: 100.0000000000, MSE of validation set = 1.097615\n",
      "Lambda User: 0.0000001000, LambdaBook: 0.0000000100, MSE of validation set = 1.089664\n",
      "Lambda User: 0.0000001000, LambdaBook: 0.0000001000, MSE of validation set = 1.089777\n",
      "Lambda User: 0.0000001000, LambdaBook: 0.0000010000, MSE of validation set = 1.088324\n",
      "Lambda User: 0.0000001000, LambdaBook: 0.0000100000, MSE of validation set = 1.077776\n",
      "Lambda User: 0.0000001000, LambdaBook: 0.0001000000, MSE of validation set = 1.051035\n",
      "Lambda User: 0.0000001000, LambdaBook: 0.0010000000, MSE of validation set = 1.069222\n",
      "Lambda User: 0.0000001000, LambdaBook: 0.0100000000, MSE of validation set = 1.089867\n",
      "Lambda User: 0.0000001000, LambdaBook: 0.1000000000, MSE of validation set = 1.093433\n",
      "Lambda User: 0.0000001000, LambdaBook: 1.0000000000, MSE of validation set = 1.093943\n",
      "Lambda User: 0.0000001000, LambdaBook: 10.0000000000, MSE of validation set = 1.094042\n",
      "Lambda User: 0.0000001000, LambdaBook: 100.0000000000, MSE of validation set = 1.095426\n",
      "Lambda User: 0.0000010000, LambdaBook: 0.0000000100, MSE of validation set = 1.086167\n",
      "Lambda User: 0.0000010000, LambdaBook: 0.0000001000, MSE of validation set = 1.085993\n",
      "Lambda User: 0.0000010000, LambdaBook: 0.0000010000, MSE of validation set = 1.084616\n",
      "Lambda User: 0.0000010000, LambdaBook: 0.0000100000, MSE of validation set = 1.073848\n",
      "Lambda User: 0.0000010000, LambdaBook: 0.0001000000, MSE of validation set = 1.047392\n",
      "Lambda User: 0.0000010000, LambdaBook: 0.0010000000, MSE of validation set = 1.065454\n",
      "Lambda User: 0.0000010000, LambdaBook: 0.0100000000, MSE of validation set = 1.085925\n",
      "Lambda User: 0.0000010000, LambdaBook: 0.1000000000, MSE of validation set = 1.089306\n",
      "Lambda User: 0.0000010000, LambdaBook: 1.0000000000, MSE of validation set = 1.089523\n",
      "Lambda User: 0.0000010000, LambdaBook: 10.0000000000, MSE of validation set = 1.090509\n",
      "Lambda User: 0.0000010000, LambdaBook: 100.0000000000, MSE of validation set = 1.092079\n",
      "Lambda User: 0.0000100000, LambdaBook: 0.0000000100, MSE of validation set = 1.068276\n",
      "Lambda User: 0.0000100000, LambdaBook: 0.0000001000, MSE of validation set = 1.068017\n",
      "Lambda User: 0.0000100000, LambdaBook: 0.0000010000, MSE of validation set = 1.066514\n",
      "Lambda User: 0.0000100000, LambdaBook: 0.0000100000, MSE of validation set = 1.055741\n",
      "Lambda User: 0.0000100000, LambdaBook: 0.0001000000, MSE of validation set = 1.027632\n",
      "Lambda User: 0.0000100000, LambdaBook: 0.0010000000, MSE of validation set = 1.043471\n",
      "Lambda User: 0.0000100000, LambdaBook: 0.0100000000, MSE of validation set = 1.063180\n",
      "Lambda User: 0.0000100000, LambdaBook: 0.1000000000, MSE of validation set = 1.066494\n",
      "Lambda User: 0.0000100000, LambdaBook: 1.0000000000, MSE of validation set = 1.066923\n",
      "Lambda User: 0.0000100000, LambdaBook: 10.0000000000, MSE of validation set = 1.066876\n",
      "Lambda User: 0.0000100000, LambdaBook: 100.0000000000, MSE of validation set = 1.072042\n",
      "Lambda User: 0.0001000000, LambdaBook: 0.0000000100, MSE of validation set = 1.181826\n",
      "Lambda User: 0.0001000000, LambdaBook: 0.0000001000, MSE of validation set = 1.181829\n",
      "Lambda User: 0.0001000000, LambdaBook: 0.0000010000, MSE of validation set = 1.179974\n",
      "Lambda User: 0.0001000000, LambdaBook: 0.0000100000, MSE of validation set = 1.165931\n",
      "Lambda User: 0.0001000000, LambdaBook: 0.0001000000, MSE of validation set = 1.123795\n",
      "Lambda User: 0.0001000000, LambdaBook: 0.0010000000, MSE of validation set = 1.126204\n",
      "Lambda User: 0.0001000000, LambdaBook: 0.0100000000, MSE of validation set = 1.142910\n",
      "Lambda User: 0.0001000000, LambdaBook: 0.1000000000, MSE of validation set = 1.146049\n",
      "Lambda User: 0.0001000000, LambdaBook: 1.0000000000, MSE of validation set = 1.146609\n",
      "Lambda User: 0.0001000000, LambdaBook: 10.0000000000, MSE of validation set = 1.147136\n",
      "Lambda User: 0.0001000000, LambdaBook: 100.0000000000, MSE of validation set = 1.146873\n",
      "Lambda User: 0.0010000000, LambdaBook: 0.0000000100, MSE of validation set = 1.482049\n",
      "Lambda User: 0.0010000000, LambdaBook: 0.0000001000, MSE of validation set = 1.482100\n",
      "Lambda User: 0.0010000000, LambdaBook: 0.0000010000, MSE of validation set = 1.479613\n",
      "Lambda User: 0.0010000000, LambdaBook: 0.0000100000, MSE of validation set = 1.463282\n",
      "Lambda User: 0.0010000000, LambdaBook: 0.0001000000, MSE of validation set = 1.412139\n",
      "Lambda User: 0.0010000000, LambdaBook: 0.0010000000, MSE of validation set = 1.409054\n",
      "Lambda User: 0.0010000000, LambdaBook: 0.0100000000, MSE of validation set = 1.425561\n",
      "Lambda User: 0.0010000000, LambdaBook: 0.1000000000, MSE of validation set = 1.428568\n",
      "Lambda User: 0.0010000000, LambdaBook: 1.0000000000, MSE of validation set = 1.428848\n",
      "Lambda User: 0.0010000000, LambdaBook: 10.0000000000, MSE of validation set = 1.428930\n",
      "Lambda User: 0.0010000000, LambdaBook: 100.0000000000, MSE of validation set = 1.428944\n",
      "Lambda User: 0.0100000000, LambdaBook: 0.0000000100, MSE of validation set = 1.566460\n",
      "Lambda User: 0.0100000000, LambdaBook: 0.0000001000, MSE of validation set = 1.566547\n",
      "Lambda User: 0.0100000000, LambdaBook: 0.0000010000, MSE of validation set = 1.564219\n",
      "Lambda User: 0.0100000000, LambdaBook: 0.0000100000, MSE of validation set = 1.547703\n",
      "Lambda User: 0.0100000000, LambdaBook: 0.0001000000, MSE of validation set = 1.496183\n",
      "Lambda User: 0.0100000000, LambdaBook: 0.0010000000, MSE of validation set = 1.493992\n",
      "Lambda User: 0.0100000000, LambdaBook: 0.0100000000, MSE of validation set = 1.511142\n",
      "Lambda User: 0.0100000000, LambdaBook: 0.1000000000, MSE of validation set = 1.514242\n",
      "Lambda User: 0.0100000000, LambdaBook: 1.0000000000, MSE of validation set = 1.514576\n",
      "Lambda User: 0.0100000000, LambdaBook: 10.0000000000, MSE of validation set = 1.514609\n",
      "Lambda User: 0.0100000000, LambdaBook: 100.0000000000, MSE of validation set = 1.514664\n",
      "Lambda User: 0.1000000000, LambdaBook: 0.0000000100, MSE of validation set = 1.576960\n",
      "Lambda User: 0.1000000000, LambdaBook: 0.0000001000, MSE of validation set = 1.576469\n",
      "Lambda User: 0.1000000000, LambdaBook: 0.0000010000, MSE of validation set = 1.574522\n",
      "Lambda User: 0.1000000000, LambdaBook: 0.0000100000, MSE of validation set = 1.557896\n",
      "Lambda User: 0.1000000000, LambdaBook: 0.0001000000, MSE of validation set = 1.506176\n",
      "Lambda User: 0.1000000000, LambdaBook: 0.0010000000, MSE of validation set = 1.504150\n",
      "Lambda User: 0.1000000000, LambdaBook: 0.0100000000, MSE of validation set = 1.521392\n",
      "Lambda User: 0.1000000000, LambdaBook: 0.1000000000, MSE of validation set = 1.524507\n",
      "Lambda User: 0.1000000000, LambdaBook: 1.0000000000, MSE of validation set = 1.524842\n",
      "Lambda User: 0.1000000000, LambdaBook: 10.0000000000, MSE of validation set = 1.524878\n",
      "Lambda User: 0.1000000000, LambdaBook: 100.0000000000, MSE of validation set = 1.524880\n",
      "Lambda User: 1.0000000000, LambdaBook: 0.0000000100, MSE of validation set = 1.577756\n",
      "Lambda User: 1.0000000000, LambdaBook: 0.0000001000, MSE of validation set = 1.577587\n",
      "Lambda User: 1.0000000000, LambdaBook: 0.0000010000, MSE of validation set = 1.575223\n",
      "Lambda User: 1.0000000000, LambdaBook: 0.0000100000, MSE of validation set = 1.558399\n",
      "Lambda User: 1.0000000000, LambdaBook: 0.0001000000, MSE of validation set = 1.507197\n",
      "Lambda User: 1.0000000000, LambdaBook: 0.0010000000, MSE of validation set = 1.505166\n",
      "Lambda User: 1.0000000000, LambdaBook: 0.0100000000, MSE of validation set = 1.522434\n",
      "Lambda User: 1.0000000000, LambdaBook: 0.1000000000, MSE of validation set = 1.525554\n",
      "Lambda User: 1.0000000000, LambdaBook: 1.0000000000, MSE of validation set = 1.525889\n",
      "Lambda User: 1.0000000000, LambdaBook: 10.0000000000, MSE of validation set = 1.525923\n",
      "Lambda User: 1.0000000000, LambdaBook: 100.0000000000, MSE of validation set = 1.525926\n",
      "Lambda User: 10.0000000000, LambdaBook: 0.0000000100, MSE of validation set = 1.577955\n",
      "Lambda User: 10.0000000000, LambdaBook: 0.0000001000, MSE of validation set = 1.577082\n",
      "Lambda User: 10.0000000000, LambdaBook: 0.0000010000, MSE of validation set = 1.575192\n",
      "Lambda User: 10.0000000000, LambdaBook: 0.0000100000, MSE of validation set = 1.558350\n",
      "Lambda User: 10.0000000000, LambdaBook: 0.0001000000, MSE of validation set = 1.507360\n",
      "Lambda User: 10.0000000000, LambdaBook: 0.0010000000, MSE of validation set = 1.505097\n",
      "Lambda User: 10.0000000000, LambdaBook: 0.0100000000, MSE of validation set = 1.522538\n",
      "Lambda User: 10.0000000000, LambdaBook: 0.1000000000, MSE of validation set = 1.525659\n",
      "Lambda User: 10.0000000000, LambdaBook: 1.0000000000, MSE of validation set = 1.525994\n",
      "Lambda User: 10.0000000000, LambdaBook: 10.0000000000, MSE of validation set = 1.526028\n",
      "Lambda User: 10.0000000000, LambdaBook: 100.0000000000, MSE of validation set = 1.526031\n",
      "Lambda User: 100.0000000000, LambdaBook: 0.0000000100, MSE of validation set = 1.579353\n",
      "Lambda User: 100.0000000000, LambdaBook: 0.0000001000, MSE of validation set = 1.579976\n",
      "Lambda User: 100.0000000000, LambdaBook: 0.0000010000, MSE of validation set = 1.575714\n",
      "Lambda User: 100.0000000000, LambdaBook: 0.0000100000, MSE of validation set = 1.560621\n",
      "Lambda User: 100.0000000000, LambdaBook: 0.0001000000, MSE of validation set = 1.508686\n",
      "Lambda User: 100.0000000000, LambdaBook: 0.0010000000, MSE of validation set = 1.505016\n",
      "Lambda User: 100.0000000000, LambdaBook: 0.0100000000, MSE of validation set = 1.522551\n",
      "Lambda User: 100.0000000000, LambdaBook: 0.1000000000, MSE of validation set = 1.525669\n",
      "Lambda User: 100.0000000000, LambdaBook: 1.0000000000, MSE of validation set = 1.526004\n",
      "Lambda User: 100.0000000000, LambdaBook: 10.0000000000, MSE of validation set = 1.526038\n",
      "Lambda User: 100.0000000000, LambdaBook: 100.0000000000, MSE of validation set = 1.526042\n"
     ]
    }
   ],
   "source": [
    "lambdaUExpList = range(-8,3)\n",
    "lambdaBExpList = range(-8,3)\n",
    "resultWithLambULambB = []\n",
    "\n",
    "for expU in lambdaUExpList:\n",
    "    lambU = pow(10,expU)\n",
    "    \n",
    "    for expB in lambdaBExpList:\n",
    "        lambB = pow(10,expB)\n",
    "        \n",
    "        scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0]*(nUsers+nItems), derivative, args = (labels, lambU, lambB))\n",
    "\n",
    "        # Predict from the model\n",
    "        predictions = [prediction(uId, bId) for uId, bId, r in bookDataValid]\n",
    "        labelsValid = [r for uId,bId,r in bookDataValid]\n",
    "        mse = MSE(predictions, labelsValid)\n",
    "        \n",
    "        print(\"Lambda User: %.10f, LambdaBook: %.10f, MSE of validation set = %f\" % (lambU, lambB, mse))\n",
    "        writeOutTestSetPred(str(lambU)+str(lambB))\n",
    "        resultWithLambULambB.append((mse,lambU,lambB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultWithLambULambB.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.5799758206202577, 100, 1e-07),\n",
       " (1.5793533128807808, 100, 1e-08),\n",
       " (1.5779545031505158, 10, 1e-08),\n",
       " (1.5777562753686416, 1, 1e-08),\n",
       " (1.5775870044007747, 1, 1e-07),\n",
       " (1.5770823088395434, 10, 1e-07),\n",
       " (1.5769597126488326, 0.1, 1e-08),\n",
       " (1.5764690013159959, 0.1, 1e-07),\n",
       " (1.5757139276375376, 100, 1e-06),\n",
       " (1.5752234008907542, 1, 1e-06)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultWithLambULambB[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.066514179379894, 1e-05, 1e-06),\n",
       " (1.0664939832140776, 1e-05, 0.1),\n",
       " (1.0654542590107277, 1e-06, 0.001),\n",
       " (1.0631795415871306, 1e-05, 0.01),\n",
       " (1.055741336710013, 1e-05, 1e-05),\n",
       " (1.051554339744204, 1e-08, 0.0001),\n",
       " (1.0510348074723637, 1e-07, 0.0001),\n",
       " (1.0473918178605763, 1e-06, 0.0001),\n",
       " (1.0434710353619576, 1e-05, 0.001),\n",
       " (1.027631586404842, 1e-05, 0.0001)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultWithLambULambB[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
