{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "from sklearn import linear_model\n",
    "import statistics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline() # Skip Header\n",
    "    for l in f:\n",
    "        yield l.strip(). split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookData = []\n",
    "for user, book, rating in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    bookData.append([user, book, int(rating)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['u79354815', 'b14275065', 4],\n",
       " ['u56917948', 'b82152306', 5],\n",
       " ['u97915914', 'b44882292', 5],\n",
       " ['u49688858', 'b79927466', 5],\n",
       " ['u08384938', 'b05683889', 2],\n",
       " ['u13530776', 'b86375465', 4],\n",
       " ['u46307273', 'b92838791', 5],\n",
       " ['u18524450', 'b35165110', 2],\n",
       " ['u69700998', 'b17128180', 5],\n",
       " ['u43359569', 'b34596567', 5]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookData[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks (Read prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Although we have built a validation set, it only consists of positive samples.\n",
    "For this task we also need examples of user/item pairs that weren’t read. For each entry (user,book) in the validation set, sample a negative entry by randomly choosing a book that user hasn’t read. Evaluate the performance (accuracy) of the baseline model on the validation set you have built.\n",
    "\n",
    "Ans: <br>\n",
    "Accurarcy of validation set: 0.7484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "190000\n",
      "190000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Separate traing and validation set\n",
    "print(len(bookData))\n",
    "numTrainSet = 190000\n",
    "bookDataTrain = bookData[:numTrainSet]\n",
    "bookDataYTrain =  [1] * len(bookDataTrain)\n",
    "bookDataValidPos = bookData[numTrainSet:]\n",
    "bookDataYValidPos = [1] * len(bookDataValidPos)\n",
    "print(len(bookDataTrain))\n",
    "print(len(bookDataYTrain))\n",
    "print(len(bookDataValidPos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7170"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookUniqueIds = set()\n",
    "for user, book, rating in bookData:\n",
    "    bookUniqueIds.add(book)\n",
    "bookUniqueIdsList = list(bookUniqueIds)\n",
    "#bookUniqueIdsList\n",
    "len(bookUniqueIdsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11357"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userUniqueIds = set()\n",
    "for user, book, rating in bookData:\n",
    "    userUniqueIds.add(user)\n",
    "userUniqueIdsList = list(userUniqueIds)\n",
    "#bookUniqueIdsList\n",
    "len(userUniqueIdsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookReadByUserIds = {}\n",
    "for user, book, rating in bookData:\n",
    "    if user in bookReadByUserIds:\n",
    "        bookReadByUserIds[user].add(book)\n",
    "    else:\n",
    "        bookReadByUserIds[user] = set()\n",
    "        bookReadByUserIds[user].add(book)\n",
    "#bookReadByUserIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNegativeEntries():\n",
    "    bookDataValidNeg = []\n",
    "    bookDataYValidNeg = [0] * len(bookDataValidPos)\n",
    "    \n",
    "    for user, book, rating in bookDataValidPos:\n",
    "        #while True:\n",
    "            #unreadBookId = random.choice(bookUniqueIdsList)\n",
    "        # For consistent validation set\n",
    "        for unreadBookId in bookUniqueIdsList:\n",
    "            if unreadBookId not in bookReadByUserIds[user]:\n",
    "                bookDataValidNeg.append([user, unreadBookId, \"-1\"])\n",
    "                break\n",
    "    return bookDataValidNeg, bookDataYValidNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNegativeEntries(numNegativeEntries):\n",
    "    bookDataNeg = []\n",
    "    bookDataYNeg = [0] * numNegativeEntries\n",
    "    \n",
    "    for i in range(numNegativeEntries):\n",
    "        # Randomly select a user\n",
    "        userId = random.choice(userUniqueIdsList)\n",
    "\n",
    "        # Randomly select a haven't read book\n",
    "        while True:\n",
    "            unreadBookId = random.choice(bookUniqueIdsList)\n",
    "            if unreadBookId not in bookReadByUserIds[userId]:\n",
    "                bookDataNeg.append([userId, unreadBookId, \"-1\"])\n",
    "                break\n",
    "\n",
    "    return bookDataNeg, bookDataYNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "bookDataValidNeg, bookDataYValidNeg = getNegativeEntries()\n",
    "bookDataValid = bookDataValidPos + bookDataValidNeg\n",
    "bookDataYValid = bookDataYValidPos + bookDataYValidNeg\n",
    "print(len(bookDataValid))\n",
    "print(len(bookDataYValid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutValidationSet(nameTag):\n",
    "    timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    fileName = \"validation_set_\" + timestr + \"_validMSE_\" + nameTag + \".txt\"\n",
    "    print(\"FileName: %s\" % (fileName))\n",
    "    outFile = open(fileName, 'w')\n",
    "    \n",
    "    # Write out current validation set\n",
    "    for data, y in zip(bookDataValid, bookDataYValid):\n",
    "        outFile.write(data[0] + '-' + data[1] + \",\" + str(y) + \"\\n\")\n",
    "\n",
    "    outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBaselinePred(Xdata, threshold):\n",
    "    ### Would-read baseline: just rank which books are popular and which are not, and return '1' if a book is among the top-ranked\n",
    "    bookCount = defaultdict(int)\n",
    "    totalRead = 0\n",
    "    \n",
    "    for user, book, _ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "        bookCount[book] += 1\n",
    "        totalRead += 1\n",
    "        \n",
    "    mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "    \n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for bkc, bkId in mostPopular:\n",
    "        count += bkc\n",
    "        return1.add(bkId)\n",
    "        if count > totalRead/threshold: break\n",
    "            \n",
    "    # Make prediction\n",
    "    prediction = []\n",
    "    for uId, bId, rating in Xdata:\n",
    "        if bId in return1:\n",
    "            prediction.append(1)\n",
    "        else:\n",
    "            prediction.append(0)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPercentile():\n",
    "    bookCount = defaultdict(int)\n",
    "    totalRead = 0\n",
    "    bookPercentile = defaultdict(float)\n",
    "    \n",
    "    for user, book, _ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "        bookCount[book] += 1\n",
    "        totalRead += 1\n",
    "        \n",
    "    mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "    print(mostPopular[:10])\n",
    "    \n",
    "    count = 0\n",
    "    for bkc, bkId in mostPopular:\n",
    "        bookPercentile[bkId] = float(count)/float(totalRead)\n",
    "        count += bkc\n",
    "    \n",
    "    return bookPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(402, 'b25543219'), (333, 'b21517939'), (331, 'b76915592'), (285, 'b55315814'), (280, 'b02830492'), (279, 'b75885962'), (274, 'b52453648'), (264, 'b25118404'), (262, 'b39244888'), (249, 'b87250311')]\n"
     ]
    }
   ],
   "source": [
    "bookPercentile = getPercentile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPopularity():\n",
    "    bookCount = defaultdict(int)\n",
    "    bookPopularity = defaultdict(float)\n",
    "    \n",
    "    for user, book, _ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "        bookCount[book] += 1\n",
    "        \n",
    "    mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "    \n",
    "    maxReadCount = mostPopular[0][0]\n",
    "    minReadCount = mostPopular[-1][0]\n",
    "    \n",
    "    for bkc, bkId in mostPopular:\n",
    "        bookPopularity[bkId] = float(bkc-minReadCount)/float(maxReadCount-minReadCount)\n",
    "    \n",
    "    return bookPopularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookPopularity = getPopularity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAcc(pred, golden):\n",
    "    correctPredictions = [p==y for p, y in zip(pred, golden)]\n",
    "    return sum(correctPredictions) / len(golden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTPR(pred, golden):\n",
    "    TP = sum([(p and l) for (p,l) in zip(pred, golden)])\n",
    "    FN = sum([(not p and l) for (p,l) in zip(pred, golden)])\n",
    "    return TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTNR(pred, golden):\n",
    "    FP = sum([(p and not l) for (p,l) in zip(pred, golden)])\n",
    "    TN = sum([(not p and not l) for (p,l) in zip(pred, golden)])\n",
    "    return TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(pred, golden):\n",
    "    TNR = getTNR(pred, golden)\n",
    "    TPR = getTPR(pred, golden)\n",
    "    acc = getAcc(pred, golden)\n",
    "    return (acc, TPR, TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "20000\n",
      "acc=0.748400, TPR=0.496800, TNR=1.000000\n"
     ]
    }
   ],
   "source": [
    "predBookDataYValid = getBaselinePred(bookDataValid, 2.0)\n",
    "print(len(predBookDataYValid))\n",
    "print(len(bookDataYValid))\n",
    "\n",
    "# Accurarcy\n",
    "predBookDataValidMSE = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "print(\"acc=%f, TPR=%f, TNR=%f\" % (predBookDataValidMSE[0], predBookDataValidMSE[1], predBookDataValidMSE[2]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileName: validation_set_20191116_121125_validMSE_0.7484.txt\n"
     ]
    }
   ],
   "source": [
    "writeOutValidationSet(str(predBookDataValidMSE[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The existing ‘read prediction’ baseline just returns True if the item in question is ‘popular,’ using a threshold of the 50th percentile of popularity (totalRead/2).\n",
    "Assuming that the ‘non-read’ test examples are a random sample of user-book pairs, this threshold may not be the best one. See if you can find a better threshold and report its performance on your validatin set.\n",
    "\n",
    "Ans: <br>\n",
    "Threshold = 1.250000, i.e. 80th percentile of popularity <br>\n",
    "Accurarcy on validation set: 0.899000 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion: t=1.000000, percentile=1.00 acc=0.500000, TPR=1.000000, TNR=0.000000\n",
      "Validataion: t=1.050000, percentile=0.95 acc=0.478050, TPR=0.954800, TNR=0.001300\n",
      "Validataion: t=1.100000, percentile=0.91 acc=0.454450, TPR=0.907600, TNR=0.001300\n",
      "Validataion: t=1.150000, percentile=0.87 acc=0.433650, TPR=0.866000, TNR=0.001300\n",
      "Validataion: t=1.200000, percentile=0.83 acc=0.915750, TPR=0.831500, TNR=1.000000\n",
      "Validataion: t=1.250000, percentile=0.80 acc=0.899000, TPR=0.798000, TNR=1.000000\n",
      "Validataion: t=1.300000, percentile=0.77 acc=0.881850, TPR=0.763700, TNR=1.000000\n",
      "Validataion: t=1.350000, percentile=0.74 acc=0.866700, TPR=0.733400, TNR=1.000000\n",
      "Validataion: t=1.400000, percentile=0.71 acc=0.853350, TPR=0.706700, TNR=1.000000\n",
      "Validataion: t=1.450000, percentile=0.69 acc=0.841500, TPR=0.683000, TNR=1.000000\n",
      "Validataion: t=1.500000, percentile=0.67 acc=0.829650, TPR=0.659300, TNR=1.000000\n",
      "Validataion: t=1.550000, percentile=0.65 acc=0.818400, TPR=0.636800, TNR=1.000000\n",
      "Validataion: t=1.600000, percentile=0.62 acc=0.808550, TPR=0.617100, TNR=1.000000\n",
      "Validataion: t=1.650000, percentile=0.61 acc=0.798950, TPR=0.597900, TNR=1.000000\n",
      "Validataion: t=1.700000, percentile=0.59 acc=0.790300, TPR=0.580600, TNR=1.000000\n",
      "Validataion: t=1.750000, percentile=0.57 acc=0.782900, TPR=0.565800, TNR=1.000000\n",
      "Validataion: t=1.800000, percentile=0.56 acc=0.775400, TPR=0.550800, TNR=1.000000\n",
      "Validataion: t=1.850000, percentile=0.54 acc=0.767550, TPR=0.535100, TNR=1.000000\n",
      "Validataion: t=1.900000, percentile=0.53 acc=0.761150, TPR=0.522300, TNR=1.000000\n",
      "Validataion: t=1.950000, percentile=0.51 acc=0.753950, TPR=0.507900, TNR=1.000000\n",
      "Validataion: t=2.000000, percentile=0.50 acc=0.748400, TPR=0.496800, TNR=1.000000\n",
      "Validataion: t=2.050000, percentile=0.49 acc=0.742450, TPR=0.484900, TNR=1.000000\n",
      "Validataion: t=2.100000, percentile=0.48 acc=0.736100, TPR=0.472200, TNR=1.000000\n",
      "Validataion: t=2.150000, percentile=0.47 acc=0.730100, TPR=0.460200, TNR=1.000000\n",
      "Validataion: t=2.200000, percentile=0.45 acc=0.724200, TPR=0.448400, TNR=1.000000\n",
      "Validataion: t=2.250000, percentile=0.44 acc=0.720400, TPR=0.440800, TNR=1.000000\n",
      "Validataion: t=2.300000, percentile=0.43 acc=0.716100, TPR=0.432200, TNR=1.000000\n",
      "Validataion: t=2.350000, percentile=0.43 acc=0.711450, TPR=0.422900, TNR=1.000000\n",
      "Validataion: t=2.400000, percentile=0.42 acc=0.706750, TPR=0.413500, TNR=1.000000\n",
      "Validataion: t=2.450000, percentile=0.41 acc=0.702800, TPR=0.405600, TNR=1.000000\n",
      "Validataion: t=2.500000, percentile=0.40 acc=0.699050, TPR=0.398100, TNR=1.000000\n",
      "Validataion: t=2.550000, percentile=0.39 acc=0.695450, TPR=0.390900, TNR=1.000000\n",
      "Validataion: t=2.600000, percentile=0.38 acc=0.691200, TPR=0.382400, TNR=1.000000\n",
      "Validataion: t=2.650000, percentile=0.38 acc=0.687300, TPR=0.374600, TNR=1.000000\n",
      "Validataion: t=2.700000, percentile=0.37 acc=0.683650, TPR=0.367300, TNR=1.000000\n",
      "Validataion: t=2.750000, percentile=0.36 acc=0.680600, TPR=0.361200, TNR=1.000000\n",
      "Validataion: t=2.800000, percentile=0.36 acc=0.677000, TPR=0.354000, TNR=1.000000\n",
      "Validataion: t=2.850000, percentile=0.35 acc=0.674550, TPR=0.349100, TNR=1.000000\n",
      "Validataion: t=2.900000, percentile=0.34 acc=0.671150, TPR=0.342300, TNR=1.000000\n",
      "Validataion: t=2.950000, percentile=0.34 acc=0.668200, TPR=0.336400, TNR=1.000000\n"
     ]
    }
   ],
   "source": [
    "for thres in np.arange(1, 3, 0.05):\n",
    "    #predBookDataYTrain = getBaselinePred(bookDataTrain, thres)\n",
    "    # Accurarcy for training set\n",
    "    #correctPredictions = [p==y for p, y in zip(predBookDataYTrain, bookDataYTrain)]\n",
    "    #print(\"Training: t=%f, acc=%f\" % (thres, sum(correctPredictions) / len(bookDataYTrain)) )\n",
    "    \n",
    "    predBookDataYValid = getBaselinePred(bookDataValid, thres)\n",
    "    # Accurarcy for validation set\n",
    "    acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "    print(\"Validataion: t=%f, percentile=%.2f acc=%f, TPR=%f, TNR=%f\" % (thres, 1.0/thres, acc, TPR, TNR) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutBaselinePred(threshold):\n",
    "    ### Would-read baseline: just rank which books are popular and which are not, and return '1' if a book is among the top-ranked\n",
    "    bookCount = defaultdict(int)\n",
    "    totalRead = 0\n",
    "    \n",
    "    for user, book, _ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "        bookCount[book] += 1\n",
    "        totalRead += 1\n",
    "    \n",
    "    mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "    \n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for bkc, bkId in mostPopular:\n",
    "        count += bkc\n",
    "        return1.add(bkId)\n",
    "        if count > totalRead/threshold: break\n",
    "    \n",
    "    fileName = \"predictions_Read_\" + str(threshold) + \".txt\"\n",
    "    predOutFile = open(fileName, 'w')\n",
    "    for l in open(\"pairs_Read.txt\", 'r'):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predOutFile.write(l)\n",
    "            continue\n",
    "        uId, bId = l.strip().split('-')\n",
    "        if bId in return1:\n",
    "            predOutFile.write(uId + '-' + bId + \",1\\n\")\n",
    "        else:\n",
    "            predOutFile.write(uId + '-' + bId + \",0\\n\")\n",
    "    predOutFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutBaselinePred(1.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. A stronger baseline than the one provided might make use of the Jaccard similarity (or another similarity metric). Given a pair (u, b) in the validation set, consider all training items b′ that user u has read.\n",
    "For each, compute the Jaccard similarity between b and b′, i.e., users (in the training set) who have read ′\n",
    "b and users who have read b . Predict as ‘read’ if the maximum of these Jaccard similarities exceeds a threshold (you may choose the threshold that works best). Report the performance on your validation set (1 mark).\n",
    "\n",
    "Ans: <br>\n",
    "Choose the threshold with the best accurarcy on validation set: threshold = 0.010000<br>\n",
    "Accurarcy on the validation set: 0.689850 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['u79354815', 'b14275065', 4],\n",
       " ['u56917948', 'b82152306', 5],\n",
       " ['u97915914', 'b44882292', 5],\n",
       " ['u49688858', 'b79927466', 5],\n",
       " ['u08384938', 'b05683889', 2],\n",
       " ['u13530776', 'b86375465', 4],\n",
       " ['u46307273', 'b92838791', 5],\n",
       " ['u18524450', 'b35165110', 2],\n",
       " ['u69700998', 'b17128180', 5],\n",
       " ['u43359569', 'b34596567', 5]]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookDataTrain[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in bookDataTrain:\n",
    "for d in bookData:\n",
    "    usersPerItem[d[1]].add(d[0])\n",
    "    itemsPerUser[d[0]].add(d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bookUniqueIdsList\n",
    "#userUniqueIdsList\n",
    "usersPerItemR = defaultdict(list)\n",
    "itemsPerUserR = defaultdict(list)\n",
    "\n",
    "for bookId in bookUniqueIdsList:\n",
    "    usersPerItemR[bookId] = [0]*len(userUniqueIdsList)\n",
    "\n",
    "for userId in userUniqueIdsList:\n",
    "    itemsPerUserR[userId] = [0]*len(bookUniqueIdsList)\n",
    "    \n",
    "for userId, bookId, r in bookDataTrain:\n",
    "    usersPerItemR[bookId][userUniqueIdsList.index(userId)] = r\n",
    "    itemsPerUserR[userId][bookUniqueIdsList.index(bookId)] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CosineSim(v1, v2):\n",
    "    # vectors\n",
    "    a = np.array(v1)\n",
    "    b = np.array(v2)\n",
    "\n",
    "    # manually compute cosine similarity\n",
    "    #dot = np.dot(a, b)\n",
    "    #norma = np.linalg.norm(a)\n",
    "    #normb = np.linalg.norm(b)\n",
    "    #cos = dot / (norma * normb)\n",
    "    \n",
    "    aa = a.reshape(1,len(v1))\n",
    "    ba = b.reshape(1,len(v2))\n",
    "    cos_lib = cosine_similarity(aa, ba)\n",
    "    \n",
    "    return cos_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairSimilarity(u, b):\n",
    "    similarities = []\n",
    "    users = usersPerItem[b]\n",
    "    candidateItems = itemsPerUser[u]\n",
    "    for b2 in candidateItems:\n",
    "        if b2 == b: continue\n",
    "        sim = Jaccard(users, usersPerItem[b2])\n",
    "        similarities.append((sim,b2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairCosineSimilarity(u, b):\n",
    "    similarities = []\n",
    "    candidateItems = itemsPerUser[u]\n",
    "    for b2 in candidateItems:\n",
    "        if b2 == b: continue\n",
    "        sim = CosineSim(usersPerItemR[b], usersPerItemR[b2])\n",
    "        similarities.append((sim,b2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairSimilarityByUser(u, b):\n",
    "    similarities = []\n",
    "    items = itemsPerUser[u]\n",
    "    candidateUsers = usersPerItem[b]\n",
    "    for u2 in candidateUsers:\n",
    "        if u2 == u: continue\n",
    "        sim = Jaccard(items, itemsPerUser[u2])\n",
    "        similarities.append((sim,u2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairCosineSimilarityByUser(u, b):\n",
    "    similarities = []\n",
    "    candidateUsers = usersPerItem[b]\n",
    "    for u2 in candidateUsers:\n",
    "        if u2 == u: continue\n",
    "        sim = CosineSim(itemsPerUserR[u], itemsPerUserR[u2])\n",
    "        similarities.append((sim,u2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJaccardPred(Xdata, threshold):      \n",
    "    # Make prediction\n",
    "    prediction = []\n",
    "    for uId, bId, rating in Xdata:\n",
    "        #print(\"Query: userId: %s, bookId: %s\" % (uId, bId))\n",
    "        #print(itemsPerUser[uId])\n",
    "        sim = pairSimilarity(uId, bId)\n",
    "        #print(sim[0][0])\n",
    "        \n",
    "        if sim and sim[0][0] > threshold:\n",
    "            prediction.append(1)\n",
    "        else:\n",
    "            prediction.append(0)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion: t=0.000000, acc=0.665700, TPR=0.920400, TNR=0.411000\n",
      "Validataion: t=0.001000, acc=0.665700, TPR=0.920400, TNR=0.411000\n",
      "Validataion: t=0.002000, acc=0.665700, TPR=0.920400, TNR=0.411000\n",
      "Validataion: t=0.003000, acc=0.671850, TPR=0.919100, TNR=0.424600\n",
      "Validataion: t=0.004000, acc=0.670100, TPR=0.915600, TNR=0.424600\n",
      "Validataion: t=0.005000, acc=0.672850, TPR=0.908800, TNR=0.436900\n",
      "Validataion: t=0.006000, acc=0.677800, TPR=0.898900, TNR=0.456700\n",
      "Validataion: t=0.007000, acc=0.682100, TPR=0.885500, TNR=0.478700\n",
      "Validataion: t=0.008000, acc=0.686800, TPR=0.869300, TNR=0.504300\n",
      "Validataion: t=0.009000, acc=0.689350, TPR=0.848700, TNR=0.530000\n",
      "Validataion: t=0.010000, acc=0.689850, TPR=0.819700, TNR=0.560000\n",
      "Validataion: t=0.011000, acc=0.681400, TPR=0.788900, TNR=0.573900\n",
      "Validataion: t=0.012000, acc=0.679250, TPR=0.756100, TNR=0.602400\n",
      "Validataion: t=0.013000, acc=0.667650, TPR=0.713700, TNR=0.621600\n",
      "Validataion: t=0.014000, acc=0.654550, TPR=0.674100, TNR=0.635000\n",
      "Validataion: t=0.015000, acc=0.639950, TPR=0.627500, TNR=0.652400\n",
      "Validataion: t=0.016000, acc=0.631200, TPR=0.583500, TNR=0.678900\n",
      "Validataion: t=0.017000, acc=0.617300, TPR=0.539200, TNR=0.695400\n",
      "Validataion: t=0.018000, acc=0.604650, TPR=0.496700, TNR=0.712600\n",
      "Validataion: t=0.019000, acc=0.591600, TPR=0.452600, TNR=0.730600\n",
      "Validataion: t=0.020000, acc=0.580350, TPR=0.407600, TNR=0.753100\n",
      "Validataion: t=0.021000, acc=0.567900, TPR=0.370000, TNR=0.765800\n",
      "Validataion: t=0.022000, acc=0.554250, TPR=0.335200, TNR=0.773300\n",
      "Validataion: t=0.023000, acc=0.552200, TPR=0.304400, TNR=0.800000\n",
      "Validataion: t=0.024000, acc=0.543850, TPR=0.272200, TNR=0.815500\n",
      "Validataion: t=0.025000, acc=0.541250, TPR=0.241200, TNR=0.841300\n",
      "Validataion: t=0.026000, acc=0.531850, TPR=0.218900, TNR=0.844800\n",
      "Validataion: t=0.027000, acc=0.524350, TPR=0.202000, TNR=0.846700\n",
      "Validataion: t=0.028000, acc=0.520700, TPR=0.176800, TNR=0.864600\n",
      "Validataion: t=0.029000, acc=0.517750, TPR=0.159500, TNR=0.876000\n"
     ]
    }
   ],
   "source": [
    "for thres in np.arange(0, 0.03, 0.001):\n",
    "    predBookDataYValid = getJaccardPred(bookDataValid, thres)\n",
    "    # Accurarcy for validation set\n",
    "    acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "    print(\"Validataion: t=%f, acc=%f, TPR=%f, TNR=%f\" % (thres, acc, TPR, TNR) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutJaccardPred(threshold):  \n",
    "    predOutFile = open(\"predictions_Read.txt\", 'w')\n",
    "    bookDataTest = []\n",
    "    \n",
    "    # Read Testing set\n",
    "    for l in open(\"pairs_Read.txt\", 'r'):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predOutFile.write(l)\n",
    "            continue\n",
    "        uId, bId = l.strip().split('-')\n",
    "        bookDataTest.append([uId, bId, -1])\n",
    "    \n",
    "    # Predict by Jaccard\n",
    "    bookDataYTest = getJaccardPred(bookDataTest, threshold)\n",
    "    \n",
    "    # Write out prediction result\n",
    "    for data, y in zip(bookDataTest, bookDataYTest):\n",
    "        predOutFile.write(data[0] + '-' + data[1] + \",\" + str(y) + \"\\n\")\n",
    "\n",
    "    predOutFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOutJaccardPred(0.011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassificationData(Xdata):\n",
    "    bookFeatures = []\n",
    "    for uId, bId, rating in Xdata:\n",
    "        sim = pairSimilarity(uId, bId)\n",
    "        if sim:\n",
    "            bookFeatures.append([sim[0][0], bookPercentile[bId]])\n",
    "        else:\n",
    "            bookFeatures.append([0, bookPercentile[bId]])\n",
    "    return bookFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassificationData2(Xdata):\n",
    "    bookFeatures = []\n",
    "    for uId, bId, rating in Xdata:\n",
    "        sim = pairSimilarity(uId, bId)\n",
    "        sim2 = pairSimilarityByUser(uId, bId)\n",
    "        \n",
    "        feature = []\n",
    "        if sim:\n",
    "            feature.append(sim[0][0])\n",
    "        else:\n",
    "            feature.append(0)\n",
    "\n",
    "        if sim2:\n",
    "            feature.append(sim2[0][0])\n",
    "        else:\n",
    "            feature.append(0)\n",
    "            \n",
    "        feature.append(bookPercentile[bId])\n",
    "        \n",
    "        bookFeatures.append(feature)\n",
    "    return bookFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassificationData3(Xdata):\n",
    "    bookFeatures = []\n",
    "    for uId, bId, rating in Xdata:\n",
    "        sim = pairSimilarity(uId, bId)\n",
    "        sim2 = pairSimilarityByUser(uId, bId)\n",
    "        if sim:\n",
    "            sim = statistics.mean([x[0] for x in sim])\n",
    "        else:\n",
    "            sim = 0\n",
    "\n",
    "        if sim2:\n",
    "            sim2 = statistics.mean([x[0] for x in sim2])\n",
    "        else:\n",
    "            sim2 = 0\n",
    "        \n",
    "        # Feature\n",
    "        feature = [sim, sim2, bookPopularity[bId]]\n",
    "        bookFeatures.append(feature)\n",
    "    return bookFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassificationData3(Xdata, topK):\n",
    "    bookFeatures = []\n",
    "    for uId, bId, rating in Xdata:\n",
    "        sim = pairSimilarity(uId, bId)\n",
    "        sim2 = pairSimilarityByUser(uId, bId)\n",
    "        if sim:\n",
    "            sim = statistics.mean([x[0] for x in sim[:topK]])\n",
    "        else:\n",
    "            sim = 0\n",
    "\n",
    "        if sim2:\n",
    "            sim2 = statistics.mean([x[0] for x in sim2[:topK]])\n",
    "        else:\n",
    "            sim2 = 0\n",
    "        \n",
    "        # Feature\n",
    "        feature = [sim, sim2, bookPopularity[bId]]\n",
    "        bookFeatures.append(feature)\n",
    "    return bookFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassificationData4(Xdata, topK):\n",
    "    bookFeatures = []\n",
    "    for uId, bId, rating in Xdata:\n",
    "        sim = pairSimilarity(uId, bId)\n",
    "        sim2 = pairSimilarityByUser(uId, bId)\n",
    "        sim3 = pairCosineSimilarity(uId, bId)\n",
    "        sim4 = pairCosineSimilarityByUser(uId, bId)\n",
    "        if sim:\n",
    "            sim = statistics.mean([x[0] for x in sim[:topK]])\n",
    "        else:\n",
    "            sim = 0\n",
    "\n",
    "        if sim2:\n",
    "            sim2 = statistics.mean([x[0] for x in sim2[:topK]])\n",
    "        else:\n",
    "            sim2 = 0\n",
    "            \n",
    "        if sim3:\n",
    "            #sim3 = statistics.mean([x[0] for x in sim3[:topK]])\n",
    "            sim3 = sim3[0][0]\n",
    "        else:\n",
    "            sim3 = 0\n",
    "\n",
    "        if sim4:\n",
    "            #sim4 = statistics.mean([x[0] for x in sim4[:topK]])\n",
    "            sim4 = sim4[0][0]\n",
    "        else:\n",
    "            sim4 = 0\n",
    "        \n",
    "        # Feature\n",
    "        feature = [sim, sim2, sim3, sim4, bookPopularity[bId]]\n",
    "        bookFeatures.append(feature)\n",
    "    return bookFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    differences = [(a-b)**2 for (a,b) in zip(predictions, y)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, y):\n",
    "    differences = [(a-b)**2 for (a,b) in zip(predictions, y)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running # Neg: 100777\n",
      "# total training data: 290777, # Neg: 100777\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.000001, acc=0.654618, TPR=0.999995, TNR=0.003463, MSE=0.345382\n",
      "Validataion: C=0.000001, acc=0.499700, TPR=0.999400, TNR=0.000000, MSE=0.500300\n",
      "Training: C=0.000005, acc=0.757391, TPR=0.999932, TNR=0.300118, MSE=0.242609\n",
      "Validataion: C=0.000005, acc=0.453500, TPR=0.905300, TNR=0.001700, MSE=0.546500\n",
      "Training: C=0.000010, acc=0.821489, TPR=0.960937, TNR=0.558580, MSE=0.178511\n",
      "Validataion: C=0.000010, acc=0.376500, TPR=0.751000, TNR=0.002000, MSE=0.623500\n",
      "Training: C=0.000050, acc=0.693542, TPR=0.633826, TNR=0.806126, MSE=0.306458\n",
      "Validataion: C=0.000050, acc=0.757600, TPR=0.515300, TNR=0.999900, MSE=0.242400\n",
      "Training: C=0.000100, acc=0.667904, TPR=0.578358, TNR=0.836729, MSE=0.332096\n",
      "Validataion: C=0.000100, acc=0.733650, TPR=0.467300, TNR=1.000000, MSE=0.266350\n",
      "Training: C=0.000500, acc=0.659499, TPR=0.549700, TNR=0.866507, MSE=0.340501\n",
      "Validataion: C=0.000500, acc=0.711700, TPR=0.423400, TNR=1.000000, MSE=0.288300\n",
      "Training: C=0.001000, acc=0.675435, TPR=0.570558, TNR=0.873166, MSE=0.324565\n",
      "Validataion: C=0.001000, acc=0.707050, TPR=0.414100, TNR=1.000000, MSE=0.292950\n",
      "Training: C=0.005000, acc=0.812722, TPR=0.767705, TNR=0.897596, MSE=0.187278\n",
      "Validataion: C=0.005000, acc=0.690350, TPR=0.380900, TNR=0.999800, MSE=0.309650\n",
      "Training: C=0.010000, acc=0.935301, TPR=0.945774, TNR=0.915556, MSE=0.064699\n",
      "Validataion: C=0.010000, acc=0.673950, TPR=0.349900, TNR=0.998000, MSE=0.326050\n",
      "Training: C=0.050000, acc=0.984720, TPR=0.999447, TNR=0.956954, MSE=0.015280\n",
      "Validataion: C=0.050000, acc=0.619900, TPR=0.250800, TNR=0.989000, MSE=0.380100\n",
      "Training: C=0.100000, acc=0.988324, TPR=0.999505, TNR=0.967245, MSE=0.011676\n",
      "Validataion: C=0.100000, acc=0.596000, TPR=0.207100, TNR=0.984900, MSE=0.404000\n",
      "Training: C=0.500000, acc=0.992723, TPR=0.998979, TNR=0.980928, MSE=0.007277\n",
      "Validataion: C=0.500000, acc=0.555350, TPR=0.127700, TNR=0.983000, MSE=0.444650\n",
      "Training: C=1.000000, acc=0.993455, TPR=0.998537, TNR=0.983875, MSE=0.006545\n",
      "Validataion: C=1.000000, acc=0.546100, TPR=0.108800, TNR=0.983400, MSE=0.453900\n",
      "Training: C=5.000000, acc=0.994621, TPR=0.997900, TNR=0.988440, MSE=0.005379\n",
      "Validataion: C=5.000000, acc=0.534150, TPR=0.082600, TNR=0.985700, MSE=0.465850\n",
      "Training: C=10.000000, acc=0.995110, TPR=0.997721, TNR=0.990186, MSE=0.004890\n",
      "Validataion: C=10.000000, acc=0.530700, TPR=0.074600, TNR=0.986800, MSE=0.469300\n",
      "Training: C=50.000000, acc=0.995839, TPR=0.997416, TNR=0.992865, MSE=0.004161\n",
      "Validataion: C=50.000000, acc=0.524200, TPR=0.061300, TNR=0.987100, MSE=0.475800\n",
      "Training: C=100.000000, acc=0.995963, TPR=0.997311, TNR=0.993421, MSE=0.004037\n",
      "Validataion: C=100.000000, acc=0.523100, TPR=0.058200, TNR=0.988000, MSE=0.476900\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.000001, acc=0.654618, TPR=0.999995, TNR=0.003463, MSE=0.345382\n",
      "Validataion: C=0.000001, acc=0.499700, TPR=0.999400, TNR=0.000000, MSE=0.500300\n",
      "Training: C=0.000005, acc=0.758330, TPR=0.999916, TNR=0.302857, MSE=0.241670\n",
      "Validataion: C=0.000005, acc=0.452550, TPR=0.903400, TNR=0.001700, MSE=0.547450\n",
      "Training: C=0.000010, acc=0.817936, TPR=0.954800, TNR=0.559900, MSE=0.182064\n",
      "Validataion: C=0.000010, acc=0.375250, TPR=0.748500, TNR=0.002000, MSE=0.624750\n",
      "Training: C=0.000050, acc=0.690423, TPR=0.629463, TNR=0.805352, MSE=0.309577\n",
      "Validataion: C=0.000050, acc=0.757000, TPR=0.514100, TNR=0.999900, MSE=0.243000\n",
      "Training: C=0.000100, acc=0.665747, TPR=0.575442, TNR=0.836004, MSE=0.334253\n",
      "Validataion: C=0.000100, acc=0.733250, TPR=0.466500, TNR=1.000000, MSE=0.266750\n",
      "Training: C=0.000500, acc=0.657432, TPR=0.546505, TNR=0.866567, MSE=0.342568\n",
      "Validataion: C=0.000500, acc=0.711000, TPR=0.422000, TNR=1.000000, MSE=0.289000\n",
      "Training: C=0.001000, acc=0.672870, TPR=0.566616, TNR=0.873195, MSE=0.327130\n",
      "Validataion: C=0.001000, acc=0.706600, TPR=0.413200, TNR=1.000000, MSE=0.293400\n",
      "Training: C=0.005000, acc=0.803764, TPR=0.753637, TNR=0.898270, MSE=0.196236\n",
      "Validataion: C=0.005000, acc=0.688100, TPR=0.376300, TNR=0.999900, MSE=0.311900\n",
      "Training: C=0.010000, acc=0.931325, TPR=0.938916, TNR=0.917015, MSE=0.068675\n",
      "Validataion: C=0.010000, acc=0.671850, TPR=0.344700, TNR=0.999000, MSE=0.328150\n",
      "Training: C=0.050000, acc=0.985828, TPR=0.999574, TNR=0.959911, MSE=0.014172\n",
      "Validataion: C=0.050000, acc=0.616850, TPR=0.242000, TNR=0.991700, MSE=0.383150\n",
      "Training: C=0.100000, acc=0.989360, TPR=0.999679, TNR=0.969904, MSE=0.010640\n",
      "Validataion: C=0.100000, acc=0.594800, TPR=0.199900, TNR=0.989700, MSE=0.405200\n",
      "Training: C=0.500000, acc=0.993607, TPR=0.999274, TNR=0.982923, MSE=0.006393\n",
      "Validataion: C=0.500000, acc=0.553850, TPR=0.119900, TNR=0.987800, MSE=0.446150\n",
      "Training: C=1.000000, acc=0.994322, TPR=0.998953, TNR=0.985592, MSE=0.005678\n",
      "Validataion: C=1.000000, acc=0.544800, TPR=0.101600, TNR=0.988000, MSE=0.455200\n",
      "Training: C=5.000000, acc=0.995288, TPR=0.998258, TNR=0.989690, MSE=0.004712\n",
      "Validataion: C=5.000000, acc=0.532100, TPR=0.075700, TNR=0.988500, MSE=0.467900\n",
      "Training: C=10.000000, acc=0.995663, TPR=0.998089, TNR=0.991089, MSE=0.004337\n",
      "Validataion: C=10.000000, acc=0.528700, TPR=0.068000, TNR=0.989400, MSE=0.471300\n",
      "Training: C=50.000000, acc=0.996444, TPR=0.997905, TNR=0.993689, MSE=0.003556\n",
      "Validataion: C=50.000000, acc=0.521900, TPR=0.053500, TNR=0.990300, MSE=0.478100\n",
      "Training: C=100.000000, acc=0.996705, TPR=0.997868, TNR=0.994513, MSE=0.003295\n",
      "Validataion: C=100.000000, acc=0.520200, TPR=0.049900, TNR=0.990500, MSE=0.479800\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.000001, acc=0.654622, TPR=0.999995, TNR=0.003473, MSE=0.345378\n",
      "Validataion: C=0.000001, acc=0.499700, TPR=0.999400, TNR=0.000000, MSE=0.500300\n",
      "Training: C=0.000005, acc=0.758970, TPR=0.999884, TNR=0.304762, MSE=0.241030\n",
      "Validataion: C=0.000005, acc=0.452000, TPR=0.902200, TNR=0.001800, MSE=0.548000\n",
      "Training: C=0.000010, acc=0.814641, TPR=0.949416, TNR=0.560545, MSE=0.185359\n",
      "Validataion: C=0.000010, acc=0.374450, TPR=0.746900, TNR=0.002000, MSE=0.625550\n",
      "Training: C=0.000050, acc=0.688259, TPR=0.626058, TNR=0.805531, MSE=0.311741\n",
      "Validataion: C=0.000050, acc=0.756350, TPR=0.512800, TNR=0.999900, MSE=0.243650\n",
      "Training: C=0.000100, acc=0.663938, TPR=0.572695, TNR=0.835965, MSE=0.336062\n",
      "Validataion: C=0.000100, acc=0.732800, TPR=0.465600, TNR=1.000000, MSE=0.267200\n",
      "Training: C=0.000500, acc=0.655540, TPR=0.543795, TNR=0.866219, MSE=0.344460\n",
      "Validataion: C=0.000500, acc=0.710650, TPR=0.421300, TNR=1.000000, MSE=0.289350\n",
      "Training: C=0.001000, acc=0.670648, TPR=0.563089, TNR=0.873433, MSE=0.329352\n",
      "Validataion: C=0.001000, acc=0.705950, TPR=0.411900, TNR=1.000000, MSE=0.294050\n",
      "Training: C=0.005000, acc=0.795610, TPR=0.741074, TNR=0.898429, MSE=0.204390\n",
      "Validataion: C=0.005000, acc=0.686750, TPR=0.373600, TNR=0.999900, MSE=0.313250\n",
      "Training: C=0.010000, acc=0.926507, TPR=0.931111, TNR=0.917828, MSE=0.073493\n",
      "Validataion: C=0.010000, acc=0.669650, TPR=0.340000, TNR=0.999300, MSE=0.330350\n",
      "Training: C=0.050000, acc=0.986646, TPR=0.999647, TNR=0.962134, MSE=0.013354\n",
      "Validataion: C=0.050000, acc=0.614500, TPR=0.233300, TNR=0.995700, MSE=0.385500\n",
      "Training: C=0.100000, acc=0.990137, TPR=0.999747, TNR=0.972017, MSE=0.009863\n",
      "Validataion: C=0.100000, acc=0.592050, TPR=0.190800, TNR=0.993300, MSE=0.407950\n",
      "Training: C=0.500000, acc=0.994305, TPR=0.999500, TNR=0.984510, MSE=0.005695\n",
      "Validataion: C=0.500000, acc=0.552600, TPR=0.114700, TNR=0.990500, MSE=0.447400\n",
      "Training: C=1.000000, acc=0.994993, TPR=0.999200, TNR=0.987061, MSE=0.005007\n",
      "Validataion: C=1.000000, acc=0.542700, TPR=0.094900, TNR=0.990500, MSE=0.457300\n",
      "Training: C=5.000000, acc=0.995859, TPR=0.998558, TNR=0.990772, MSE=0.004141\n",
      "Validataion: C=5.000000, acc=0.530950, TPR=0.070100, TNR=0.991800, MSE=0.469050\n",
      "Training: C=10.000000, acc=0.996224, TPR=0.998379, TNR=0.992161, MSE=0.003776\n",
      "Validataion: C=10.000000, acc=0.527250, TPR=0.062700, TNR=0.991800, MSE=0.472750\n",
      "Training: C=50.000000, acc=0.996970, TPR=0.998253, TNR=0.994552, MSE=0.003030\n",
      "Validataion: C=50.000000, acc=0.520800, TPR=0.049200, TNR=0.992400, MSE=0.479200\n",
      "Training: C=100.000000, acc=0.997225, TPR=0.998242, TNR=0.995306, MSE=0.002775\n",
      "Validataion: C=100.000000, acc=0.518900, TPR=0.045300, TNR=0.992500, MSE=0.481100\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.000001, acc=0.654622, TPR=0.999995, TNR=0.003473, MSE=0.345378\n",
      "Validataion: C=0.000001, acc=0.499700, TPR=0.999400, TNR=0.000000, MSE=0.500300\n",
      "Training: C=0.000005, acc=0.753375, TPR=0.999842, TNR=0.288697, MSE=0.246625\n",
      "Validataion: C=0.000005, acc=0.453600, TPR=0.905400, TNR=0.001800, MSE=0.546400\n",
      "Training: C=0.000010, acc=0.811749, TPR=0.944784, TNR=0.560932, MSE=0.188251\n",
      "Validataion: C=0.000010, acc=0.373550, TPR=0.745100, TNR=0.002000, MSE=0.626450\n",
      "Training: C=0.000050, acc=0.686089, TPR=0.622732, TNR=0.805541, MSE=0.313911\n",
      "Validataion: C=0.000050, acc=0.755700, TPR=0.511400, TNR=1.000000, MSE=0.244300\n",
      "Training: C=0.000100, acc=0.662387, TPR=0.570200, TNR=0.836193, MSE=0.337613\n",
      "Validataion: C=0.000100, acc=0.732150, TPR=0.464300, TNR=1.000000, MSE=0.267850\n",
      "Training: C=0.000500, acc=0.653717, TPR=0.541163, TNR=0.865922, MSE=0.346283\n",
      "Validataion: C=0.000500, acc=0.710500, TPR=0.421000, TNR=1.000000, MSE=0.289500\n",
      "Training: C=0.001000, acc=0.668278, TPR=0.559653, TNR=0.873076, MSE=0.331722\n",
      "Validataion: C=0.001000, acc=0.705650, TPR=0.411300, TNR=1.000000, MSE=0.294350\n",
      "Training: C=0.005000, acc=0.787535, TPR=0.728521, TNR=0.898796, MSE=0.212465\n",
      "Validataion: C=0.005000, acc=0.685100, TPR=0.370300, TNR=0.999900, MSE=0.314900\n",
      "Training: C=0.010000, acc=0.920977, TPR=0.922158, TNR=0.918751, MSE=0.079023\n",
      "Validataion: C=0.010000, acc=0.668550, TPR=0.337600, TNR=0.999500, MSE=0.331450\n",
      "Training: C=0.050000, acc=0.987410, TPR=0.999726, TNR=0.964188, MSE=0.012590\n",
      "Validataion: C=0.050000, acc=0.611100, TPR=0.225500, TNR=0.996700, MSE=0.388900\n",
      "Training: C=0.100000, acc=0.990842, TPR=0.999800, TNR=0.973952, MSE=0.009158\n",
      "Validataion: C=0.100000, acc=0.589400, TPR=0.183500, TNR=0.995300, MSE=0.410600\n",
      "Training: C=0.500000, acc=0.994804, TPR=0.999589, TNR=0.985780, MSE=0.005196\n",
      "Validataion: C=0.500000, acc=0.550650, TPR=0.106800, TNR=0.994500, MSE=0.449350\n",
      "Training: C=1.000000, acc=0.995522, TPR=0.999347, TNR=0.988311, MSE=0.004478\n",
      "Validataion: C=1.000000, acc=0.541400, TPR=0.088900, TNR=0.993900, MSE=0.458600\n",
      "Training: C=5.000000, acc=0.996344, TPR=0.998795, TNR=0.991724, MSE=0.003656\n",
      "Validataion: C=5.000000, acc=0.530250, TPR=0.066300, TNR=0.994200, MSE=0.469750\n",
      "Training: C=10.000000, acc=0.996740, TPR=0.998700, TNR=0.993044, MSE=0.003260\n",
      "Validataion: C=10.000000, acc=0.526250, TPR=0.058300, TNR=0.994200, MSE=0.473750\n",
      "Training: C=50.000000, acc=0.997421, TPR=0.998621, TNR=0.995158, MSE=0.002579\n",
      "Validataion: C=50.000000, acc=0.519850, TPR=0.044900, TNR=0.994800, MSE=0.480150\n",
      "Training: C=100.000000, acc=0.997648, TPR=0.998616, TNR=0.995822, MSE=0.002352\n",
      "Validataion: C=100.000000, acc=0.517850, TPR=0.041000, TNR=0.994700, MSE=0.482150\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.000001, acc=0.654622, TPR=0.999995, TNR=0.003473, MSE=0.345378\n",
      "Validataion: C=0.000001, acc=0.499700, TPR=0.999400, TNR=0.000000, MSE=0.500300\n",
      "Training: C=0.000005, acc=0.753481, TPR=0.999795, TNR=0.289094, MSE=0.246519\n",
      "Validataion: C=0.000005, acc=0.453600, TPR=0.905400, TNR=0.001800, MSE=0.546400\n",
      "Training: C=0.000010, acc=0.809524, TPR=0.941179, TNR=0.561309, MSE=0.190476\n",
      "Validataion: C=0.000010, acc=0.373100, TPR=0.744200, TNR=0.002000, MSE=0.626900\n",
      "Training: C=0.000050, acc=0.684102, TPR=0.619663, TNR=0.805591, MSE=0.315898\n",
      "Validataion: C=0.000050, acc=0.755050, TPR=0.510100, TNR=1.000000, MSE=0.244950\n",
      "Training: C=0.000100, acc=0.660565, TPR=0.567863, TNR=0.835339, MSE=0.339435\n",
      "Validataion: C=0.000100, acc=0.731800, TPR=0.463600, TNR=1.000000, MSE=0.268200\n",
      "Training: C=0.000500, acc=0.651988, TPR=0.538811, TNR=0.865366, MSE=0.348012\n",
      "Validataion: C=0.000500, acc=0.710950, TPR=0.421900, TNR=1.000000, MSE=0.289050\n",
      "Training: C=0.001000, acc=0.666160, TPR=0.556474, TNR=0.872957, MSE=0.333840\n",
      "Validataion: C=0.001000, acc=0.705500, TPR=0.411000, TNR=1.000000, MSE=0.294500\n",
      "Training: C=0.005000, acc=0.780406, TPR=0.717463, TNR=0.899074, MSE=0.219594\n",
      "Validataion: C=0.005000, acc=0.684350, TPR=0.368800, TNR=0.999900, MSE=0.315650\n",
      "Training: C=0.010000, acc=0.914794, TPR=0.912463, TNR=0.919188, MSE=0.085206\n",
      "Validataion: C=0.010000, acc=0.666850, TPR=0.333800, TNR=0.999900, MSE=0.333150\n",
      "Training: C=0.050000, acc=0.988073, TPR=0.999805, TNR=0.965955, MSE=0.011927\n",
      "Validataion: C=0.050000, acc=0.608300, TPR=0.218900, TNR=0.997700, MSE=0.391700\n",
      "Training: C=0.100000, acc=0.991488, TPR=0.999879, TNR=0.975669, MSE=0.008512\n",
      "Validataion: C=0.100000, acc=0.586500, TPR=0.176500, TNR=0.996500, MSE=0.413500\n",
      "Training: C=0.500000, acc=0.995326, TPR=0.999689, TNR=0.987100, MSE=0.004674\n",
      "Validataion: C=0.500000, acc=0.548500, TPR=0.101300, TNR=0.995700, MSE=0.451500\n",
      "Training: C=1.000000, acc=0.996000, TPR=0.999474, TNR=0.989452, MSE=0.004000\n",
      "Validataion: C=1.000000, acc=0.539800, TPR=0.083900, TNR=0.995700, MSE=0.460200\n",
      "Training: C=5.000000, acc=0.996757, TPR=0.998958, TNR=0.992607, MSE=0.003243\n",
      "Validataion: C=5.000000, acc=0.528750, TPR=0.061800, TNR=0.995700, MSE=0.471250\n",
      "Training: C=10.000000, acc=0.997087, TPR=0.998905, TNR=0.993659, MSE=0.002913\n",
      "Validataion: C=10.000000, acc=0.524800, TPR=0.053900, TNR=0.995700, MSE=0.475200\n",
      "Training: C=50.000000, acc=0.997737, TPR=0.998879, TNR=0.995584, MSE=0.002263\n",
      "Validataion: C=50.000000, acc=0.518650, TPR=0.041000, TNR=0.996300, MSE=0.481350\n",
      "Training: C=100.000000, acc=0.997885, TPR=0.998826, TNR=0.996110, MSE=0.002115\n",
      "Validataion: C=100.000000, acc=0.516350, TPR=0.036900, TNR=0.995800, MSE=0.483650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.7576, 0.5153, 0.9999, 0.2424, 100777, 5e-05, 8),\n",
       " (0.757, 0.5141, 0.9999, 0.243, 100777, 5e-05, 9),\n",
       " (0.75635, 0.5128, 0.9999, 0.24365, 100777, 5e-05, 10),\n",
       " (0.7557, 0.5114, 1.0, 0.2443, 100777, 5e-05, 11),\n",
       " (0.75505, 0.5101, 1.0, 0.24495, 100777, 5e-05, 12),\n",
       " (0.73365, 0.4673, 1.0, 0.26635, 100777, 0.0001, 8),\n",
       " (0.73325, 0.4665, 1.0, 0.26675, 100777, 0.0001, 9),\n",
       " (0.7328, 0.4656, 1.0, 0.2672, 100777, 0.0001, 10),\n",
       " (0.73215, 0.4643, 1.0, 0.26785, 100777, 0.0001, 11),\n",
       " (0.7318, 0.4636, 1.0, 0.2682, 100777, 0.0001, 12)]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try Tuning top K + # of Negatives\n",
    "#Includes Another Similarity feature [simItem, simUser, new percentile]\n",
    "numNegativeExamples = [100777]\n",
    "predBookResult = []\n",
    "\n",
    "for numNeg in numNegativeExamples:\n",
    "    print(\"\\nRunning # Neg: %d\" % (numNeg) )\n",
    "    bookDataNeg, bookDataYNeg = getNegativeEntries(numNeg)\n",
    "    bookDataArt = bookDataTrain + bookDataNeg\n",
    "    bookDataYArt = bookDataYTrain + bookDataYNeg\n",
    "    print(\"# total training data: %d, # Neg: %d\" % (len(bookDataArt), len(bookDataNeg)) )\n",
    "    \n",
    "    for topK in range(8,13):\n",
    "        print(\"\\nRunning Top K: %d\" % (topK))\n",
    "        \n",
    "        # Data to Features [simItem, simUser, percentile]\n",
    "        bookFeaturesArt = getClassificationData3(bookDataArt, topK)\n",
    "        bookFeaturesValid = getClassificationData3(bookDataValid, topK)\n",
    "        print(min([x[0] for x in bookFeaturesArt]))\n",
    "        print(min([x[1] for x in bookFeaturesArt]))\n",
    "        print(min([x[2] for x in bookFeaturesArt]))\n",
    "        print(max([x[0] for x in bookFeaturesArt]))\n",
    "        print(max([x[1] for x in bookFeaturesArt]))\n",
    "        print(max([x[2] for x in bookFeaturesArt]))\n",
    "\n",
    "        for cVal in [0.000001, 0.000005, 0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005,0.01,0.05,0.1,0.5,1,5,10,50,100]:\n",
    "            model = linear_model.LogisticRegression(C=cVal, solver=\"liblinear\", class_weight=\"balanced\")\n",
    "            model.fit(bookFeaturesArt, bookDataYArt)\n",
    "\n",
    "            predBookDataYArt = model.predict(bookFeaturesArt)\n",
    "            mseTrain = MSE(predBookDataYArt, bookDataYArt)\n",
    "            predBookDataYValid = model.predict(bookFeaturesValid)\n",
    "            mseValid = MSE(predBookDataYValid, bookDataYValid)\n",
    "\n",
    "            writeOutClassificationPredWithFunction(model, \"numNeg_\"+str(numNeg)+\"_C_\"+str(cVal)+\"_topK_\"+str(topK), getClassificationData3, topK)\n",
    "\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYArt, bookDataYArt)\n",
    "            print(\"Training: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseTrain) )\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "            print(\"Validataion: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseValid) )\n",
    "            predBookResult.append((acc, TPR, TNR, mseValid, numNeg, cVal, topK))\n",
    "    \n",
    "predBookResult.sort(reverse = True)\n",
    "predBookResult[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7385, 0.5473, 0.9297, 0.2615, 135000, 0.005, 12),\n",
       " (0.73325, 0.5467, 0.9198, 0.26675, 135000, 0.005, 11),\n",
       " (0.72895, 0.5462, 0.9117, 0.27105, 135000, 0.005, 10),\n",
       " (0.72665, 0.5165, 0.9368, 0.27335, 120000, 0.01, 12),\n",
       " (0.7252, 0.4939, 0.9565, 0.2748, 125000, 0.01, 12),\n",
       " (0.72475, 0.5717, 0.8778, 0.27525, 130000, 0.005, 12),\n",
       " (0.7237, 0.5479, 0.8995, 0.2763, 135000, 0.005, 9),\n",
       " (0.7231, 0.5399, 0.9063, 0.2769, 115000, 0.01, 12),\n",
       " (0.7231, 0.5176, 0.9286, 0.2769, 120000, 0.01, 11),\n",
       " (0.72225, 0.4956, 0.9489, 0.27775, 125000, 0.01, 11),\n",
       " (0.72115, 0.4735, 0.9688, 0.27885, 130000, 0.01, 12),\n",
       " (0.72085, 0.5705, 0.8712, 0.27915, 130000, 0.005, 11),\n",
       " (0.71955, 0.5397, 0.8994, 0.28045, 115000, 0.01, 11),\n",
       " (0.71945, 0.4755, 0.9634, 0.28055, 130000, 0.01, 11),\n",
       " (0.71935, 0.5505, 0.8882, 0.28065, 135000, 0.005, 8),\n",
       " (0.71885, 0.4968, 0.9409, 0.28115, 125000, 0.01, 10),\n",
       " (0.71835, 0.571, 0.8657, 0.28165, 130000, 0.005, 10),\n",
       " (0.71825, 0.519, 0.9175, 0.28175, 120000, 0.01, 10),\n",
       " (0.7173, 0.4786, 0.956, 0.2827, 130000, 0.01, 10),\n",
       " (0.7165, 0.5408, 0.8922, 0.2835, 115000, 0.01, 10),\n",
       " (0.7159, 0.455, 0.9768, 0.2841, 135000, 0.01, 12),\n",
       " (0.71535, 0.4843, 0.9464, 0.28465, 130000, 0.01, 9),\n",
       " (0.71515, 0.5021, 0.9282, 0.28485, 125000, 0.01, 9),\n",
       " (0.7147, 0.5641, 0.8653, 0.2853, 110000, 0.01, 12),\n",
       " (0.71405, 0.4577, 0.9704, 0.28595, 135000, 0.01, 11),\n",
       " (0.71375, 0.5213, 0.9062, 0.28625, 120000, 0.01, 9),\n",
       " (0.7134, 0.5727, 0.8541, 0.2866, 130000, 0.005, 9),\n",
       " (0.7125, 0.4603, 0.9647, 0.2875, 135000, 0.01, 10),\n",
       " (0.71245, 0.5648, 0.8601, 0.28755, 110000, 0.01, 11),\n",
       " (0.71185, 0.4911, 0.9326, 0.28815, 130000, 0.01, 8),\n",
       " (0.71175, 0.5433, 0.8802, 0.28825, 115000, 0.01, 9),\n",
       " (0.7111, 0.464, 0.9582, 0.2889, 135000, 0.01, 9),\n",
       " (0.7106, 0.508, 0.9132, 0.2894, 125000, 0.01, 8),\n",
       " (0.71, 0.4717, 0.9483, 0.29, 135000, 0.01, 8),\n",
       " (0.7096, 0.5255, 0.8937, 0.2904, 120000, 0.01, 8),\n",
       " (0.70915, 0.5662, 0.8521, 0.29085, 110000, 0.01, 10),\n",
       " (0.70795, 0.5746, 0.8413, 0.29205, 130000, 0.005, 8),\n",
       " (0.7068, 0.5469, 0.8667, 0.2932, 115000, 0.01, 8),\n",
       " (0.7052, 0.5689, 0.8415, 0.2948, 110000, 0.01, 9),\n",
       " (0.70145, 0.5721, 0.8308, 0.29855, 110000, 0.01, 8),\n",
       " (0.6976, 0.5952, 0.8, 0.3024, 105000, 0.01, 12),\n",
       " (0.69755, 0.5948, 0.8003, 0.30245, 105000, 0.01, 11),\n",
       " (0.6968, 0.4769, 0.9167, 0.3032, 70000, 0.05, 12),\n",
       " (0.6963, 0.5945, 0.7981, 0.3037, 105000, 0.01, 10),\n",
       " (0.69575, 0.6017, 0.7898, 0.30425, 125000, 0.005, 12),\n",
       " (0.6957, 0.6, 0.7914, 0.3043, 125000, 0.005, 11),\n",
       " (0.6956, 0.5995, 0.7917, 0.3044, 125000, 0.005, 10),\n",
       " (0.69505, 0.6002, 0.7899, 0.30495, 125000, 0.005, 9),\n",
       " (0.6948, 0.5954, 0.7942, 0.3052, 105000, 0.01, 9),\n",
       " (0.6941, 0.4813, 0.9069, 0.3059, 70000, 0.05, 11),\n",
       " (0.6932, 0.4512, 0.9352, 0.3068, 75000, 0.05, 12),\n",
       " (0.69255, 0.4873, 0.8978, 0.30745, 70000, 0.05, 10),\n",
       " (0.69235, 0.6032, 0.7815, 0.30765, 125000, 0.005, 8),\n",
       " (0.69195, 0.4578, 0.9261, 0.30805, 75000, 0.05, 11),\n",
       " (0.69175, 0.598, 0.7855, 0.30825, 105000, 0.01, 8),\n",
       " (0.6908, 0.4956, 0.886, 0.3092, 70000, 0.05, 9),\n",
       " (0.6899, 0.4655, 0.9143, 0.3101, 75000, 0.05, 10),\n",
       " (0.6895, 0.4305, 0.9485, 0.3105, 80000, 0.05, 12),\n",
       " (0.6884, 0.437, 0.9398, 0.3116, 80000, 0.05, 11),\n",
       " (0.68775, 0.5061, 0.8694, 0.31225, 70000, 0.05, 8),\n",
       " (0.68735, 0.4869, 0.8878, 0.31265, 75000, 0.05, 8),\n",
       " (0.68705, 0.4461, 0.928, 0.31295, 80000, 0.05, 10),\n",
       " (0.68695, 0.474, 0.8999, 0.31305, 75000, 0.05, 9),\n",
       " (0.6865, 0.4578, 0.9152, 0.3135, 80000, 0.05, 9),\n",
       " (0.6849, 0.471, 0.8988, 0.3151, 80000, 0.05, 8),\n",
       " (0.6846, 0.4123, 0.9569, 0.3154, 85000, 0.05, 12),\n",
       " (0.68455, 0.4416, 0.9275, 0.31545, 85000, 0.05, 9),\n",
       " (0.68455, 0.4289, 0.9402, 0.31545, 85000, 0.05, 10),\n",
       " (0.6844, 0.4193, 0.9495, 0.3156, 85000, 0.05, 11),\n",
       " (0.68325, 0.4558, 0.9107, 0.31675, 85000, 0.05, 8),\n",
       " (0.68055, 0.4237, 0.9374, 0.31945, 90000, 0.05, 9),\n",
       " (0.6797, 0.4106, 0.9488, 0.3203, 90000, 0.05, 10),\n",
       " (0.6792, 0.438, 0.9204, 0.3208, 90000, 0.05, 8),\n",
       " (0.6783, 0.3995, 0.9571, 0.3217, 90000, 0.05, 11),\n",
       " (0.67765, 0.4238, 0.9315, 0.32235, 95000, 0.05, 8),\n",
       " (0.67735, 0.3914, 0.9633, 0.32265, 90000, 0.05, 12),\n",
       " (0.67695, 0.4083, 0.9456, 0.32305, 95000, 0.05, 9),\n",
       " (0.67615, 0.6256, 0.7267, 0.32385, 100000, 0.01, 9),\n",
       " (0.676, 0.4106, 0.9414, 0.324, 100000, 0.05, 8),\n",
       " (0.67535, 0.6261, 0.7246, 0.32465, 100000, 0.01, 8),\n",
       " (0.6751, 0.3941, 0.9561, 0.3249, 95000, 0.05, 10),\n",
       " (0.675, 0.6269, 0.7231, 0.325, 100000, 0.01, 10),\n",
       " (0.6744, 0.3953, 0.9535, 0.3256, 100000, 0.05, 9),\n",
       " (0.6738, 0.4005, 0.9471, 0.3262, 105000, 0.05, 8),\n",
       " (0.6734, 0.3835, 0.9633, 0.3266, 95000, 0.05, 11),\n",
       " (0.6731, 0.4351, 0.9111, 0.3269, 70000, 0.1, 8),\n",
       " (0.6724, 0.3759, 0.9689, 0.3276, 95000, 0.05, 12),\n",
       " (0.67155, 0.6272, 0.7159, 0.32845, 100000, 0.01, 11),\n",
       " (0.6715, 0.4162, 0.9268, 0.3285, 70000, 0.1, 9),\n",
       " (0.6715, 0.4025, 0.9405, 0.3285, 70000, 0.1, 10),\n",
       " (0.6712, 0.3811, 0.9613, 0.3288, 100000, 0.05, 10),\n",
       " (0.671, 0.3842, 0.9578, 0.329, 105000, 0.05, 9),\n",
       " (0.67075, 0.3911, 0.9504, 0.32925, 70000, 0.1, 11),\n",
       " (0.67045, 0.3886, 0.9523, 0.32955, 110000, 0.05, 8),\n",
       " (0.6699, 0.4196, 0.9202, 0.3301, 75000, 0.1, 8),\n",
       " (0.6696, 0.4018, 0.9374, 0.3304, 75000, 0.1, 9),\n",
       " (0.6696, 0.3719, 0.9673, 0.3304, 100000, 0.05, 11),\n",
       " (0.66865, 0.3636, 0.9737, 0.33135, 100000, 0.05, 12),\n",
       " (0.6684, 0.3792, 0.9576, 0.3316, 70000, 0.1, 12),\n",
       " (0.6681, 0.4071, 0.9291, 0.3319, 80000, 0.1, 8)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topK_numNegative_result[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK_numNegative_result = predBookResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running # Neg: 70000\n",
      "# total training data: 280000, # Neg: 70000\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.714286, TPR=1.000000, TNR=0.000000, MSE=0.285714\n",
      "Validataion: C=0.005000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.792504, TPR=0.995465, TNR=0.285100, MSE=0.207496\n",
      "Validataion: C=0.010000, acc=0.455100, TPR=0.909400, TNR=0.000800, MSE=0.544900\n",
      "Training: C=0.050000, acc=0.940564, TPR=0.975300, TNR=0.853725, MSE=0.059436\n",
      "Validataion: C=0.050000, acc=0.687750, TPR=0.506100, TNR=0.869400, MSE=0.312250\n",
      "Training: C=0.100000, acc=0.949911, TPR=0.971750, TNR=0.895312, MSE=0.050089\n",
      "Validataion: C=0.100000, acc=0.673100, TPR=0.435100, TNR=0.911100, MSE=0.326900\n",
      "Training: C=0.500000, acc=0.956829, TPR=0.967270, TNR=0.930725, MSE=0.043171\n",
      "Validataion: C=0.500000, acc=0.643300, TPR=0.345500, TNR=0.941100, MSE=0.356700\n",
      "Training: C=1.000000, acc=0.957614, TPR=0.966185, TNR=0.936187, MSE=0.042386\n",
      "Validataion: C=1.000000, acc=0.632550, TPR=0.323900, TNR=0.941200, MSE=0.367450\n",
      "Training: C=5.000000, acc=0.958332, TPR=0.965380, TNR=0.940712, MSE=0.041668\n",
      "Validataion: C=5.000000, acc=0.621800, TPR=0.307800, TNR=0.935800, MSE=0.378200\n",
      "Training: C=10.000000, acc=0.958439, TPR=0.965315, TNR=0.941250, MSE=0.041561\n",
      "Validataion: C=10.000000, acc=0.620400, TPR=0.306400, TNR=0.934400, MSE=0.379600\n",
      "Training: C=50.000000, acc=0.958575, TPR=0.965490, TNR=0.941288, MSE=0.041425\n",
      "Validataion: C=50.000000, acc=0.620350, TPR=0.309800, TNR=0.930900, MSE=0.379650\n",
      "Training: C=100.000000, acc=0.958589, TPR=0.965465, TNR=0.941400, MSE=0.041411\n",
      "Validataion: C=100.000000, acc=0.620000, TPR=0.309300, TNR=0.930700, MSE=0.380000\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.714286, TPR=1.000000, TNR=0.000000, MSE=0.285714\n",
      "Validataion: C=0.005000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.781150, TPR=0.996320, TNR=0.243225, MSE=0.218850\n",
      "Validataion: C=0.010000, acc=0.463600, TPR=0.926400, TNR=0.000800, MSE=0.536400\n",
      "Training: C=0.050000, acc=0.942132, TPR=0.974775, TNR=0.860525, MSE=0.057868\n",
      "Validataion: C=0.050000, acc=0.690800, TPR=0.495600, TNR=0.886000, MSE=0.309200\n",
      "Training: C=0.100000, acc=0.951675, TPR=0.970805, TNR=0.903850, MSE=0.048325\n",
      "Validataion: C=0.100000, acc=0.671500, TPR=0.416200, TNR=0.926800, MSE=0.328500\n",
      "Training: C=0.500000, acc=0.958546, TPR=0.966300, TNR=0.939163, MSE=0.041454\n",
      "Validataion: C=0.500000, acc=0.639200, TPR=0.326100, TNR=0.952300, MSE=0.360800\n",
      "Training: C=1.000000, acc=0.959111, TPR=0.965360, TNR=0.943488, MSE=0.040889\n",
      "Validataion: C=1.000000, acc=0.629600, TPR=0.307300, TNR=0.951900, MSE=0.370400\n",
      "Training: C=5.000000, acc=0.959743, TPR=0.964595, TNR=0.947612, MSE=0.040257\n",
      "Validataion: C=5.000000, acc=0.620500, TPR=0.292000, TNR=0.949000, MSE=0.379500\n",
      "Training: C=10.000000, acc=0.959821, TPR=0.964595, TNR=0.947887, MSE=0.040179\n",
      "Validataion: C=10.000000, acc=0.619700, TPR=0.292000, TNR=0.947400, MSE=0.380300\n",
      "Training: C=50.000000, acc=0.959682, TPR=0.964630, TNR=0.947313, MSE=0.040318\n",
      "Validataion: C=50.000000, acc=0.617150, TPR=0.292600, TNR=0.941700, MSE=0.382850\n",
      "Training: C=100.000000, acc=0.959718, TPR=0.964725, TNR=0.947200, MSE=0.040282\n",
      "Validataion: C=100.000000, acc=0.617800, TPR=0.294500, TNR=0.941100, MSE=0.382200\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.714286, TPR=1.000000, TNR=0.000000, MSE=0.285714\n",
      "Validataion: C=0.005000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.772489, TPR=0.996980, TNR=0.211262, MSE=0.227511\n",
      "Validataion: C=0.010000, acc=0.470200, TPR=0.939600, TNR=0.000800, MSE=0.529800\n",
      "Training: C=0.050000, acc=0.943164, TPR=0.974360, TNR=0.865175, MSE=0.056836\n",
      "Validataion: C=0.050000, acc=0.692550, TPR=0.487300, TNR=0.897800, MSE=0.307450\n",
      "Training: C=0.100000, acc=0.953261, TPR=0.970120, TNR=0.911112, MSE=0.046739\n",
      "Validataion: C=0.100000, acc=0.671500, TPR=0.402500, TNR=0.940500, MSE=0.328500\n",
      "Training: C=0.500000, acc=0.959671, TPR=0.965435, TNR=0.945263, MSE=0.040329\n",
      "Validataion: C=0.500000, acc=0.634500, TPR=0.308800, TNR=0.960200, MSE=0.365500\n",
      "Training: C=1.000000, acc=0.960225, TPR=0.964555, TNR=0.949400, MSE=0.039775\n",
      "Validataion: C=1.000000, acc=0.625300, TPR=0.291200, TNR=0.959400, MSE=0.374700\n",
      "Training: C=5.000000, acc=0.960571, TPR=0.963780, TNR=0.952550, MSE=0.039429\n",
      "Validataion: C=5.000000, acc=0.615850, TPR=0.275700, TNR=0.956000, MSE=0.384150\n",
      "Training: C=10.000000, acc=0.960625, TPR=0.963810, TNR=0.952662, MSE=0.039375\n",
      "Validataion: C=10.000000, acc=0.615200, TPR=0.276300, TNR=0.954100, MSE=0.384800\n",
      "Training: C=50.000000, acc=0.960636, TPR=0.963940, TNR=0.952375, MSE=0.039364\n",
      "Validataion: C=50.000000, acc=0.614700, TPR=0.278800, TNR=0.950600, MSE=0.385300\n",
      "Training: C=100.000000, acc=0.960546, TPR=0.963985, TNR=0.951950, MSE=0.039454\n",
      "Validataion: C=100.000000, acc=0.613750, TPR=0.279700, TNR=0.947800, MSE=0.386250\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.714286, TPR=1.000000, TNR=0.000000, MSE=0.285714\n",
      "Validataion: C=0.005000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.759768, TPR=0.997650, TNR=0.165063, MSE=0.240232\n",
      "Validataion: C=0.010000, acc=0.476750, TPR=0.953000, TNR=0.000500, MSE=0.523250\n",
      "Training: C=0.050000, acc=0.943843, TPR=0.974060, TNR=0.868300, MSE=0.056157\n",
      "Validataion: C=0.050000, acc=0.694100, TPR=0.481300, TNR=0.906900, MSE=0.305900\n",
      "Training: C=0.100000, acc=0.954371, TPR=0.969550, TNR=0.916425, MSE=0.045629\n",
      "Validataion: C=0.100000, acc=0.670750, TPR=0.391100, TNR=0.950400, MSE=0.329250\n",
      "Training: C=0.500000, acc=0.960514, TPR=0.964615, TNR=0.950263, MSE=0.039486\n",
      "Validataion: C=0.500000, acc=0.629350, TPR=0.292400, TNR=0.966300, MSE=0.370650\n",
      "Training: C=1.000000, acc=0.960986, TPR=0.963740, TNR=0.954100, MSE=0.039014\n",
      "Validataion: C=1.000000, acc=0.620100, TPR=0.274900, TNR=0.965300, MSE=0.379900\n",
      "Training: C=5.000000, acc=0.961336, TPR=0.963080, TNR=0.956975, MSE=0.038664\n",
      "Validataion: C=5.000000, acc=0.611750, TPR=0.261700, TNR=0.961800, MSE=0.388250\n",
      "Training: C=10.000000, acc=0.961371, TPR=0.963045, TNR=0.957187, MSE=0.038629\n",
      "Validataion: C=10.000000, acc=0.611100, TPR=0.260900, TNR=0.961300, MSE=0.388900\n",
      "Training: C=50.000000, acc=0.961314, TPR=0.963215, TNR=0.956562, MSE=0.038686\n",
      "Validataion: C=50.000000, acc=0.610050, TPR=0.264300, TNR=0.955800, MSE=0.389950\n",
      "Training: C=100.000000, acc=0.961257, TPR=0.963235, TNR=0.956313, MSE=0.038743\n",
      "Validataion: C=100.000000, acc=0.609650, TPR=0.264700, TNR=0.954600, MSE=0.390350\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.714286, TPR=1.000000, TNR=0.000000, MSE=0.285714\n",
      "Validataion: C=0.005000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.750539, TPR=0.998285, TNR=0.131175, MSE=0.249461\n",
      "Validataion: C=0.010000, acc=0.483100, TPR=0.965700, TNR=0.000500, MSE=0.516900\n",
      "Training: C=0.050000, acc=0.944471, TPR=0.973840, TNR=0.871050, MSE=0.055529\n",
      "Validataion: C=0.050000, acc=0.696800, TPR=0.476900, TNR=0.916700, MSE=0.303200\n",
      "Training: C=0.100000, acc=0.955179, TPR=0.968955, TNR=0.920737, MSE=0.044821\n",
      "Validataion: C=0.100000, acc=0.668400, TPR=0.379200, TNR=0.957600, MSE=0.331600\n",
      "Training: C=0.500000, acc=0.961207, TPR=0.963935, TNR=0.954388, MSE=0.038793\n",
      "Validataion: C=0.500000, acc=0.625700, TPR=0.278800, TNR=0.972600, MSE=0.374300\n",
      "Training: C=1.000000, acc=0.961668, TPR=0.963035, TNR=0.958250, MSE=0.038332\n",
      "Validataion: C=1.000000, acc=0.616400, TPR=0.260800, TNR=0.972000, MSE=0.383600\n",
      "Training: C=5.000000, acc=0.961875, TPR=0.962340, TNR=0.960712, MSE=0.038125\n",
      "Validataion: C=5.000000, acc=0.607150, TPR=0.246900, TNR=0.967400, MSE=0.392850\n",
      "Training: C=10.000000, acc=0.961864, TPR=0.962375, TNR=0.960588, MSE=0.038136\n",
      "Validataion: C=10.000000, acc=0.605650, TPR=0.247500, TNR=0.963800, MSE=0.394350\n",
      "Training: C=50.000000, acc=0.961875, TPR=0.962520, TNR=0.960263, MSE=0.038125\n",
      "Validataion: C=50.000000, acc=0.605350, TPR=0.250400, TNR=0.960300, MSE=0.394650\n",
      "Training: C=100.000000, acc=0.961936, TPR=0.962625, TNR=0.960213, MSE=0.038064\n",
      "Validataion: C=100.000000, acc=0.605750, TPR=0.252500, TNR=0.959000, MSE=0.394250\n",
      "\n",
      "Running # Neg: 75000\n",
      "# total training data: 285000, # Neg: 75000\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.701754, TPR=1.000000, TNR=0.000000, MSE=0.298246\n",
      "Validataion: C=0.005000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.817084, TPR=0.992565, TNR=0.404188, MSE=0.182916\n",
      "Validataion: C=0.010000, acc=0.426350, TPR=0.851400, TNR=0.001300, MSE=0.573650\n",
      "Training: C=0.050000, acc=0.942228, TPR=0.974340, TNR=0.866671, MSE=0.057772\n",
      "Validataion: C=0.050000, acc=0.687350, TPR=0.486900, TNR=0.887800, MSE=0.312650\n",
      "Training: C=0.100000, acc=0.950628, TPR=0.970975, TNR=0.902753, MSE=0.049372\n",
      "Validataion: C=0.100000, acc=0.669900, TPR=0.419600, TNR=0.920200, MSE=0.330100\n",
      "Training: C=0.500000, acc=0.956628, TPR=0.966600, TNR=0.933165, MSE=0.043372\n",
      "Validataion: C=0.500000, acc=0.637900, TPR=0.332100, TNR=0.943700, MSE=0.362100\n",
      "Training: C=1.000000, acc=0.957439, TPR=0.965700, TNR=0.938000, MSE=0.042561\n",
      "Validataion: C=1.000000, acc=0.629500, TPR=0.314200, TNR=0.944800, MSE=0.370500\n",
      "Training: C=5.000000, acc=0.958000, TPR=0.964780, TNR=0.942047, MSE=0.042000\n",
      "Validataion: C=5.000000, acc=0.618200, TPR=0.295800, TNR=0.940600, MSE=0.381800\n",
      "Training: C=10.000000, acc=0.958084, TPR=0.964775, TNR=0.942341, MSE=0.041916\n",
      "Validataion: C=10.000000, acc=0.616750, TPR=0.295700, TNR=0.937800, MSE=0.383250\n",
      "Training: C=50.000000, acc=0.958382, TPR=0.964930, TNR=0.942976, MSE=0.041618\n",
      "Validataion: C=50.000000, acc=0.616900, TPR=0.298600, TNR=0.935200, MSE=0.383100\n",
      "Training: C=100.000000, acc=0.958428, TPR=0.964955, TNR=0.943071, MSE=0.041572\n",
      "Validataion: C=100.000000, acc=0.617150, TPR=0.299100, TNR=0.935200, MSE=0.382850\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.701754, TPR=1.000000, TNR=0.000000, MSE=0.298246\n",
      "Validataion: C=0.005000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.809712, TPR=0.993185, TNR=0.378012, MSE=0.190288\n",
      "Validataion: C=0.010000, acc=0.432500, TPR=0.863800, TNR=0.001200, MSE=0.567500\n",
      "Training: C=0.050000, acc=0.943775, TPR=0.973695, TNR=0.873376, MSE=0.056225\n",
      "Validataion: C=0.050000, acc=0.686950, TPR=0.474000, TNR=0.899900, MSE=0.313050\n",
      "Training: C=0.100000, acc=0.952516, TPR=0.970085, TNR=0.911176, MSE=0.047484\n",
      "Validataion: C=0.100000, acc=0.669600, TPR=0.401800, TNR=0.937400, MSE=0.330400\n",
      "Training: C=0.500000, acc=0.958204, TPR=0.965705, TNR=0.940553, MSE=0.041796\n",
      "Validataion: C=0.500000, acc=0.635000, TPR=0.314200, TNR=0.955800, MSE=0.365000\n",
      "Training: C=1.000000, acc=0.958895, TPR=0.964770, TNR=0.945071, MSE=0.041105\n",
      "Validataion: C=1.000000, acc=0.625500, TPR=0.295500, TNR=0.955500, MSE=0.374500\n",
      "Training: C=5.000000, acc=0.959365, TPR=0.964055, TNR=0.948329, MSE=0.040635\n",
      "Validataion: C=5.000000, acc=0.615900, TPR=0.281200, TNR=0.950600, MSE=0.384100\n",
      "Training: C=10.000000, acc=0.959477, TPR=0.964060, TNR=0.948694, MSE=0.040523\n",
      "Validataion: C=10.000000, acc=0.615200, TPR=0.281300, TNR=0.949100, MSE=0.384800\n",
      "Training: C=50.000000, acc=0.959467, TPR=0.964160, TNR=0.948424, MSE=0.040533\n",
      "Validataion: C=50.000000, acc=0.613650, TPR=0.283200, TNR=0.944100, MSE=0.386350\n",
      "Training: C=100.000000, acc=0.959502, TPR=0.964205, TNR=0.948435, MSE=0.040498\n",
      "Validataion: C=100.000000, acc=0.613850, TPR=0.284100, TNR=0.943600, MSE=0.386150\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.701754, TPR=1.000000, TNR=0.000000, MSE=0.298246\n",
      "Validataion: C=0.005000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.801484, TPR=0.993965, TNR=0.348588, MSE=0.198516\n",
      "Validataion: C=0.010000, acc=0.440300, TPR=0.879400, TNR=0.001200, MSE=0.559700\n",
      "Training: C=0.050000, acc=0.945049, TPR=0.973270, TNR=0.878647, MSE=0.054951\n",
      "Validataion: C=0.050000, acc=0.689900, TPR=0.465500, TNR=0.914300, MSE=0.310100\n",
      "Training: C=0.100000, acc=0.953888, TPR=0.969320, TNR=0.917576, MSE=0.046112\n",
      "Validataion: C=0.100000, acc=0.667450, TPR=0.386500, TNR=0.948400, MSE=0.332550\n",
      "Training: C=0.500000, acc=0.959361, TPR=0.964790, TNR=0.946588, MSE=0.040639\n",
      "Validataion: C=0.500000, acc=0.629100, TPR=0.295900, TNR=0.962300, MSE=0.370900\n",
      "Training: C=1.000000, acc=0.959909, TPR=0.963925, TNR=0.950459, MSE=0.040091\n",
      "Validataion: C=1.000000, acc=0.620000, TPR=0.278600, TNR=0.961400, MSE=0.380000\n",
      "Training: C=5.000000, acc=0.960414, TPR=0.963260, TNR=0.953718, MSE=0.039586\n",
      "Validataion: C=5.000000, acc=0.612000, TPR=0.265300, TNR=0.958700, MSE=0.388000\n",
      "Training: C=10.000000, acc=0.960375, TPR=0.963335, TNR=0.953412, MSE=0.039625\n",
      "Validataion: C=10.000000, acc=0.611200, TPR=0.266800, TNR=0.955600, MSE=0.388800\n",
      "Training: C=50.000000, acc=0.960614, TPR=0.963490, TNR=0.953847, MSE=0.039386\n",
      "Validataion: C=50.000000, acc=0.611400, TPR=0.269800, TNR=0.953000, MSE=0.388600\n",
      "Training: C=100.000000, acc=0.960586, TPR=0.963495, TNR=0.953741, MSE=0.039414\n",
      "Validataion: C=100.000000, acc=0.611000, TPR=0.269900, TNR=0.952100, MSE=0.389000\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.701754, TPR=1.000000, TNR=0.000000, MSE=0.298246\n",
      "Validataion: C=0.005000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.794077, TPR=0.994610, TNR=0.322235, MSE=0.205923\n",
      "Validataion: C=0.010000, acc=0.446650, TPR=0.892300, TNR=0.001000, MSE=0.553350\n",
      "Training: C=0.050000, acc=0.945954, TPR=0.972885, TNR=0.882588, MSE=0.054046\n",
      "Validataion: C=0.050000, acc=0.691950, TPR=0.457800, TNR=0.926100, MSE=0.308050\n",
      "Training: C=0.100000, acc=0.954814, TPR=0.968650, TNR=0.922259, MSE=0.045186\n",
      "Validataion: C=0.100000, acc=0.664800, TPR=0.373100, TNR=0.956500, MSE=0.335200\n",
      "Training: C=0.500000, acc=0.960228, TPR=0.964070, TNR=0.951188, MSE=0.039772\n",
      "Validataion: C=0.500000, acc=0.624900, TPR=0.281500, TNR=0.968300, MSE=0.375100\n",
      "Training: C=1.000000, acc=0.960846, TPR=0.963195, TNR=0.955318, MSE=0.039154\n",
      "Validataion: C=1.000000, acc=0.616250, TPR=0.264000, TNR=0.968500, MSE=0.383750\n",
      "Training: C=5.000000, acc=0.961133, TPR=0.962585, TNR=0.957718, MSE=0.038867\n",
      "Validataion: C=5.000000, acc=0.607200, TPR=0.251800, TNR=0.962600, MSE=0.392800\n",
      "Training: C=10.000000, acc=0.961193, TPR=0.962570, TNR=0.957953, MSE=0.038807\n",
      "Validataion: C=10.000000, acc=0.606700, TPR=0.251400, TNR=0.962000, MSE=0.393300\n",
      "Training: C=50.000000, acc=0.961186, TPR=0.962750, TNR=0.957506, MSE=0.038814\n",
      "Validataion: C=50.000000, acc=0.606050, TPR=0.255000, TNR=0.957100, MSE=0.393950\n",
      "Training: C=100.000000, acc=0.961168, TPR=0.962775, TNR=0.957388, MSE=0.038832\n",
      "Validataion: C=100.000000, acc=0.605800, TPR=0.255500, TNR=0.956100, MSE=0.394200\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.701754, TPR=1.000000, TNR=0.000000, MSE=0.298246\n",
      "Validataion: C=0.005000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.783965, TPR=0.995390, TNR=0.286494, MSE=0.216035\n",
      "Validataion: C=0.010000, acc=0.454300, TPR=0.907800, TNR=0.000800, MSE=0.545700\n",
      "Training: C=0.050000, acc=0.946428, TPR=0.972555, TNR=0.884953, MSE=0.053572\n",
      "Validataion: C=0.050000, acc=0.693200, TPR=0.451200, TNR=0.935200, MSE=0.306800\n",
      "Training: C=0.100000, acc=0.955544, TPR=0.968085, TNR=0.926035, MSE=0.044456\n",
      "Validataion: C=0.100000, acc=0.662350, TPR=0.361800, TNR=0.962900, MSE=0.337650\n",
      "Training: C=0.500000, acc=0.961109, TPR=0.963360, TNR=0.955812, MSE=0.038891\n",
      "Validataion: C=0.500000, acc=0.621300, TPR=0.267300, TNR=0.975300, MSE=0.378700\n",
      "Training: C=1.000000, acc=0.961614, TPR=0.962485, TNR=0.959565, MSE=0.038386\n",
      "Validataion: C=1.000000, acc=0.612450, TPR=0.249800, TNR=0.975100, MSE=0.387550\n",
      "Training: C=5.000000, acc=0.961758, TPR=0.961895, TNR=0.961435, MSE=0.038242\n",
      "Validataion: C=5.000000, acc=0.603200, TPR=0.238000, TNR=0.968400, MSE=0.396800\n",
      "Training: C=10.000000, acc=0.961740, TPR=0.961925, TNR=0.961306, MSE=0.038260\n",
      "Validataion: C=10.000000, acc=0.602100, TPR=0.238500, TNR=0.965700, MSE=0.397900\n",
      "Training: C=50.000000, acc=0.961779, TPR=0.962065, TNR=0.961106, MSE=0.038221\n",
      "Validataion: C=50.000000, acc=0.601500, TPR=0.241300, TNR=0.961700, MSE=0.398500\n",
      "Training: C=100.000000, acc=0.961782, TPR=0.962130, TNR=0.960965, MSE=0.038218\n",
      "Validataion: C=100.000000, acc=0.601550, TPR=0.242600, TNR=0.960500, MSE=0.398450\n",
      "\n",
      "Running # Neg: 80000\n",
      "# total training data: 290000, # Neg: 80000\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.693997, TPR=0.999925, TNR=0.014156, MSE=0.306003\n",
      "Validataion: C=0.005000, acc=0.499250, TPR=0.998500, TNR=0.000000, MSE=0.500750\n",
      "Training: C=0.010000, acc=0.842386, TPR=0.989630, TNR=0.515178, MSE=0.157614\n",
      "Validataion: C=0.010000, acc=0.492150, TPR=0.792700, TNR=0.191600, MSE=0.507850\n",
      "Training: C=0.050000, acc=0.943431, TPR=0.973545, TNR=0.876511, MSE=0.056569\n",
      "Validataion: C=0.050000, acc=0.684900, TPR=0.471000, TNR=0.898800, MSE=0.315100\n",
      "Training: C=0.100000, acc=0.951228, TPR=0.970350, TNR=0.908733, MSE=0.048772\n",
      "Validataion: C=0.100000, acc=0.668100, TPR=0.407100, TNR=0.929100, MSE=0.331900\n",
      "Training: C=0.500000, acc=0.957417, TPR=0.966180, TNR=0.937944, MSE=0.042583\n",
      "Validataion: C=0.500000, acc=0.635500, TPR=0.323800, TNR=0.947200, MSE=0.364500\n",
      "Training: C=1.000000, acc=0.958138, TPR=0.965330, TNR=0.942156, MSE=0.041862\n",
      "Validataion: C=1.000000, acc=0.626950, TPR=0.306800, TNR=0.947100, MSE=0.373050\n",
      "Training: C=5.000000, acc=0.958700, TPR=0.964390, TNR=0.946056, MSE=0.041300\n",
      "Validataion: C=5.000000, acc=0.615900, TPR=0.288000, TNR=0.943800, MSE=0.384100\n",
      "Training: C=10.000000, acc=0.958869, TPR=0.964370, TNR=0.946644, MSE=0.041131\n",
      "Validataion: C=10.000000, acc=0.614300, TPR=0.287600, TNR=0.941000, MSE=0.385700\n",
      "Training: C=50.000000, acc=0.959083, TPR=0.964540, TNR=0.946956, MSE=0.040917\n",
      "Validataion: C=50.000000, acc=0.613750, TPR=0.290800, TNR=0.936700, MSE=0.386250\n",
      "Training: C=100.000000, acc=0.959110, TPR=0.964560, TNR=0.947000, MSE=0.040890\n",
      "Validataion: C=100.000000, acc=0.613700, TPR=0.291200, TNR=0.936200, MSE=0.386300\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.691745, TPR=0.999955, TNR=0.006833, MSE=0.308255\n",
      "Validataion: C=0.005000, acc=0.499550, TPR=0.999100, TNR=0.000000, MSE=0.500450\n",
      "Training: C=0.010000, acc=0.831469, TPR=0.990105, TNR=0.478944, MSE=0.168531\n",
      "Validataion: C=0.010000, acc=0.401950, TPR=0.802200, TNR=0.001700, MSE=0.598050\n",
      "Training: C=0.050000, acc=0.945262, TPR=0.972885, TNR=0.883878, MSE=0.054738\n",
      "Validataion: C=0.050000, acc=0.686500, TPR=0.457800, TNR=0.915200, MSE=0.313500\n",
      "Training: C=0.100000, acc=0.953148, TPR=0.969515, TNR=0.916778, MSE=0.046852\n",
      "Validataion: C=0.100000, acc=0.666950, TPR=0.390400, TNR=0.943500, MSE=0.333050\n",
      "Training: C=0.500000, acc=0.958900, TPR=0.965285, TNR=0.944711, MSE=0.041100\n",
      "Validataion: C=0.500000, acc=0.632000, TPR=0.305800, TNR=0.958200, MSE=0.368000\n",
      "Training: C=1.000000, acc=0.959545, TPR=0.964450, TNR=0.948644, MSE=0.040455\n",
      "Validataion: C=1.000000, acc=0.623600, TPR=0.289100, TNR=0.958100, MSE=0.376400\n",
      "Training: C=5.000000, acc=0.960003, TPR=0.963745, TNR=0.951689, MSE=0.039997\n",
      "Validataion: C=5.000000, acc=0.613950, TPR=0.275000, TNR=0.952900, MSE=0.386050\n",
      "Training: C=10.000000, acc=0.960121, TPR=0.963720, TNR=0.952122, MSE=0.039879\n",
      "Validataion: C=10.000000, acc=0.612650, TPR=0.274500, TNR=0.950800, MSE=0.387350\n",
      "Training: C=50.000000, acc=0.960200, TPR=0.963850, TNR=0.952089, MSE=0.039800\n",
      "Validataion: C=50.000000, acc=0.611450, TPR=0.277000, TNR=0.945900, MSE=0.388550\n",
      "Training: C=100.000000, acc=0.960172, TPR=0.963875, TNR=0.951944, MSE=0.039828\n",
      "Validataion: C=100.000000, acc=0.611250, TPR=0.277500, TNR=0.945000, MSE=0.388750\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.690093, TPR=0.999985, TNR=0.001444, MSE=0.309907\n",
      "Validataion: C=0.005000, acc=0.499850, TPR=0.999700, TNR=0.000000, MSE=0.500150\n",
      "Training: C=0.010000, acc=0.826228, TPR=0.990670, TNR=0.460800, MSE=0.173772\n",
      "Validataion: C=0.010000, acc=0.407600, TPR=0.813500, TNR=0.001700, MSE=0.592400\n",
      "Training: C=0.050000, acc=0.946486, TPR=0.972300, TNR=0.889122, MSE=0.053514\n",
      "Validataion: C=0.050000, acc=0.687050, TPR=0.446100, TNR=0.928000, MSE=0.312950\n",
      "Training: C=0.100000, acc=0.954486, TPR=0.968665, TNR=0.922978, MSE=0.045514\n",
      "Validataion: C=0.100000, acc=0.663600, TPR=0.373400, TNR=0.953800, MSE=0.336400\n",
      "Training: C=0.500000, acc=0.960086, TPR=0.964430, TNR=0.950433, MSE=0.039914\n",
      "Validataion: C=0.500000, acc=0.626400, TPR=0.288700, TNR=0.964100, MSE=0.373600\n",
      "Training: C=1.000000, acc=0.960634, TPR=0.963645, TNR=0.953944, MSE=0.039366\n",
      "Validataion: C=1.000000, acc=0.618600, TPR=0.273000, TNR=0.964200, MSE=0.381400\n",
      "Training: C=5.000000, acc=0.961000, TPR=0.963010, TNR=0.956533, MSE=0.039000\n",
      "Validataion: C=5.000000, acc=0.610300, TPR=0.260300, TNR=0.960300, MSE=0.389700\n",
      "Training: C=10.000000, acc=0.961107, TPR=0.962985, TNR=0.956933, MSE=0.038893\n",
      "Validataion: C=10.000000, acc=0.608700, TPR=0.259800, TNR=0.957600, MSE=0.391300\n",
      "Training: C=50.000000, acc=0.961114, TPR=0.963120, TNR=0.956656, MSE=0.038886\n",
      "Validataion: C=50.000000, acc=0.608200, TPR=0.262400, TNR=0.954000, MSE=0.391800\n",
      "Training: C=100.000000, acc=0.961183, TPR=0.963210, TNR=0.956678, MSE=0.038817\n",
      "Validataion: C=100.000000, acc=0.608850, TPR=0.264200, TNR=0.953500, MSE=0.391150\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.689790, TPR=0.999995, TNR=0.000444, MSE=0.310210\n",
      "Validataion: C=0.005000, acc=0.499950, TPR=0.999900, TNR=0.000000, MSE=0.500050\n",
      "Training: C=0.010000, acc=0.820166, TPR=0.991240, TNR=0.440000, MSE=0.179834\n",
      "Validataion: C=0.010000, acc=0.413300, TPR=0.824900, TNR=0.001700, MSE=0.586700\n",
      "Training: C=0.050000, acc=0.947352, TPR=0.971845, TNR=0.892922, MSE=0.052648\n",
      "Validataion: C=0.050000, acc=0.688400, TPR=0.437000, TNR=0.939800, MSE=0.311600\n",
      "Training: C=0.100000, acc=0.955386, TPR=0.967955, TNR=0.927456, MSE=0.044614\n",
      "Validataion: C=0.100000, acc=0.660300, TPR=0.359200, TNR=0.961400, MSE=0.339700\n",
      "Training: C=0.500000, acc=0.961124, TPR=0.963705, TNR=0.955389, MSE=0.038876\n",
      "Validataion: C=0.500000, acc=0.622300, TPR=0.274200, TNR=0.970400, MSE=0.377700\n",
      "Training: C=1.000000, acc=0.961476, TPR=0.962870, TNR=0.958378, MSE=0.038524\n",
      "Validataion: C=1.000000, acc=0.613450, TPR=0.257500, TNR=0.969400, MSE=0.386550\n",
      "Training: C=5.000000, acc=0.961800, TPR=0.962295, TNR=0.960700, MSE=0.038200\n",
      "Validataion: C=5.000000, acc=0.605050, TPR=0.246000, TNR=0.964100, MSE=0.394950\n",
      "Training: C=10.000000, acc=0.961897, TPR=0.962310, TNR=0.960978, MSE=0.038103\n",
      "Validataion: C=10.000000, acc=0.604400, TPR=0.246200, TNR=0.962600, MSE=0.395600\n",
      "Training: C=50.000000, acc=0.961872, TPR=0.962475, TNR=0.960533, MSE=0.038128\n",
      "Validataion: C=50.000000, acc=0.604050, TPR=0.249500, TNR=0.958600, MSE=0.395950\n",
      "Training: C=100.000000, acc=0.961872, TPR=0.962500, TNR=0.960478, MSE=0.038128\n",
      "Validataion: C=100.000000, acc=0.604200, TPR=0.250000, TNR=0.958400, MSE=0.395800\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.689790, TPR=0.999995, TNR=0.000444, MSE=0.310210\n",
      "Validataion: C=0.005000, acc=0.499950, TPR=0.999900, TNR=0.000000, MSE=0.500050\n",
      "Training: C=0.010000, acc=0.814872, TPR=0.991815, TNR=0.421667, MSE=0.185128\n",
      "Validataion: C=0.010000, acc=0.418900, TPR=0.836400, TNR=0.001400, MSE=0.581100\n",
      "Training: C=0.050000, acc=0.948072, TPR=0.971520, TNR=0.895967, MSE=0.051928\n",
      "Validataion: C=0.050000, acc=0.689500, TPR=0.430500, TNR=0.948500, MSE=0.310500\n",
      "Training: C=0.100000, acc=0.956466, TPR=0.967530, TNR=0.931878, MSE=0.043534\n",
      "Validataion: C=0.100000, acc=0.658950, TPR=0.350700, TNR=0.967200, MSE=0.341050\n",
      "Training: C=0.500000, acc=0.961869, TPR=0.962985, TNR=0.959389, MSE=0.038131\n",
      "Validataion: C=0.500000, acc=0.618750, TPR=0.259800, TNR=0.977700, MSE=0.381250\n",
      "Training: C=1.000000, acc=0.962234, TPR=0.962135, TNR=0.962456, MSE=0.037766\n",
      "Validataion: C=1.000000, acc=0.609900, TPR=0.242800, TNR=0.977000, MSE=0.390100\n",
      "Training: C=5.000000, acc=0.962524, TPR=0.961570, TNR=0.964644, MSE=0.037476\n",
      "Validataion: C=5.000000, acc=0.600800, TPR=0.231500, TNR=0.970100, MSE=0.399200\n",
      "Training: C=10.000000, acc=0.962541, TPR=0.961680, TNR=0.964456, MSE=0.037459\n",
      "Validataion: C=10.000000, acc=0.600250, TPR=0.233600, TNR=0.966900, MSE=0.399750\n",
      "Training: C=50.000000, acc=0.962445, TPR=0.961795, TNR=0.963889, MSE=0.037555\n",
      "Validataion: C=50.000000, acc=0.599550, TPR=0.235900, TNR=0.963200, MSE=0.400450\n",
      "Training: C=100.000000, acc=0.962424, TPR=0.961890, TNR=0.963611, MSE=0.037576\n",
      "Validataion: C=100.000000, acc=0.599900, TPR=0.237800, TNR=0.962000, MSE=0.400100\n",
      "\n",
      "Running # Neg: 85000\n",
      "# total training data: 295000, # Neg: 85000\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.713115, TPR=0.998660, TNR=0.111968, MSE=0.286885\n",
      "Validataion: C=0.005000, acc=0.486850, TPR=0.973200, TNR=0.000500, MSE=0.513150\n",
      "Training: C=0.010000, acc=0.861349, TPR=0.986980, TNR=0.596863, MSE=0.138651\n",
      "Validataion: C=0.010000, acc=0.551100, TPR=0.739700, TNR=0.362500, MSE=0.448900\n",
      "Training: C=0.050000, acc=0.944542, TPR=0.972785, TNR=0.885084, MSE=0.055458\n",
      "Validataion: C=0.050000, acc=0.683250, TPR=0.455800, TNR=0.910700, MSE=0.316750\n",
      "Training: C=0.100000, acc=0.952034, TPR=0.969785, TNR=0.914663, MSE=0.047966\n",
      "Validataion: C=0.100000, acc=0.666750, TPR=0.395800, TNR=0.937700, MSE=0.333250\n",
      "Training: C=0.500000, acc=0.957695, TPR=0.965720, TNR=0.940800, MSE=0.042305\n",
      "Validataion: C=0.500000, acc=0.632350, TPR=0.314600, TNR=0.950100, MSE=0.367650\n",
      "Training: C=1.000000, acc=0.958505, TPR=0.964885, TNR=0.945074, MSE=0.041495\n",
      "Validataion: C=1.000000, acc=0.624150, TPR=0.297900, TNR=0.950400, MSE=0.375850\n",
      "Training: C=5.000000, acc=0.959125, TPR=0.963985, TNR=0.948895, MSE=0.040875\n",
      "Validataion: C=5.000000, acc=0.613300, TPR=0.279900, TNR=0.946700, MSE=0.386700\n",
      "Training: C=10.000000, acc=0.959098, TPR=0.963885, TNR=0.949021, MSE=0.040902\n",
      "Validataion: C=10.000000, acc=0.611050, TPR=0.277900, TNR=0.944200, MSE=0.388950\n",
      "Training: C=50.000000, acc=0.959149, TPR=0.964025, TNR=0.948884, MSE=0.040851\n",
      "Validataion: C=50.000000, acc=0.610650, TPR=0.280600, TNR=0.940700, MSE=0.389350\n",
      "Training: C=100.000000, acc=0.959108, TPR=0.964050, TNR=0.948705, MSE=0.040892\n",
      "Validataion: C=100.000000, acc=0.610500, TPR=0.281000, TNR=0.940000, MSE=0.389500\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.704424, TPR=0.999090, TNR=0.084074, MSE=0.295576\n",
      "Validataion: C=0.005000, acc=0.490900, TPR=0.981800, TNR=0.000000, MSE=0.509100\n",
      "Training: C=0.010000, acc=0.856061, TPR=0.987300, TNR=0.579768, MSE=0.143939\n",
      "Validataion: C=0.010000, acc=0.516950, TPR=0.746100, TNR=0.287800, MSE=0.483050\n",
      "Training: C=0.050000, acc=0.946420, TPR=0.972075, TNR=0.892411, MSE=0.053580\n",
      "Validataion: C=0.050000, acc=0.684550, TPR=0.441600, TNR=0.927500, MSE=0.315450\n",
      "Training: C=0.100000, acc=0.953953, TPR=0.968895, TNR=0.922495, MSE=0.046047\n",
      "Validataion: C=0.100000, acc=0.664350, TPR=0.378000, TNR=0.950700, MSE=0.335650\n",
      "Training: C=0.500000, acc=0.959183, TPR=0.964855, TNR=0.947242, MSE=0.040817\n",
      "Validataion: C=0.500000, acc=0.628750, TPR=0.297200, TNR=0.960300, MSE=0.371250\n",
      "Training: C=1.000000, acc=0.959851, TPR=0.964070, TNR=0.950968, MSE=0.040149\n",
      "Validataion: C=1.000000, acc=0.620850, TPR=0.281600, TNR=0.960100, MSE=0.379150\n",
      "Training: C=5.000000, acc=0.960224, TPR=0.963305, TNR=0.953737, MSE=0.039776\n",
      "Validataion: C=5.000000, acc=0.610350, TPR=0.266300, TNR=0.954400, MSE=0.389650\n",
      "Training: C=10.000000, acc=0.960142, TPR=0.963255, TNR=0.953589, MSE=0.039858\n",
      "Validataion: C=10.000000, acc=0.608900, TPR=0.265200, TNR=0.952600, MSE=0.391100\n",
      "Training: C=50.000000, acc=0.960207, TPR=0.963420, TNR=0.953442, MSE=0.039793\n",
      "Validataion: C=50.000000, acc=0.608150, TPR=0.268400, TNR=0.947900, MSE=0.391850\n",
      "Training: C=100.000000, acc=0.960200, TPR=0.963470, TNR=0.953316, MSE=0.039800\n",
      "Validataion: C=100.000000, acc=0.608050, TPR=0.269400, TNR=0.946700, MSE=0.391950\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.691851, TPR=0.999635, TNR=0.043884, MSE=0.308149\n",
      "Validataion: C=0.005000, acc=0.496350, TPR=0.992700, TNR=0.000000, MSE=0.503650\n",
      "Training: C=0.010000, acc=0.850000, TPR=0.987545, TNR=0.560432, MSE=0.150000\n",
      "Validataion: C=0.010000, acc=0.473350, TPR=0.751000, TNR=0.195700, MSE=0.526650\n",
      "Training: C=0.050000, acc=0.947766, TPR=0.971440, TNR=0.897926, MSE=0.052234\n",
      "Validataion: C=0.050000, acc=0.684550, TPR=0.428900, TNR=0.940200, MSE=0.315450\n",
      "Training: C=0.100000, acc=0.955325, TPR=0.968060, TNR=0.928516, MSE=0.044675\n",
      "Validataion: C=0.100000, acc=0.660600, TPR=0.361300, TNR=0.959900, MSE=0.339400\n",
      "Training: C=0.500000, acc=0.960325, TPR=0.963950, TNR=0.952695, MSE=0.039675\n",
      "Validataion: C=0.500000, acc=0.622550, TPR=0.279100, TNR=0.966000, MSE=0.377450\n",
      "Training: C=1.000000, acc=0.960837, TPR=0.963250, TNR=0.955758, MSE=0.039163\n",
      "Validataion: C=1.000000, acc=0.615150, TPR=0.265100, TNR=0.965200, MSE=0.384850\n",
      "Training: C=5.000000, acc=0.961085, TPR=0.962650, TNR=0.957789, MSE=0.038915\n",
      "Validataion: C=5.000000, acc=0.607500, TPR=0.253100, TNR=0.961900, MSE=0.392500\n",
      "Training: C=10.000000, acc=0.961020, TPR=0.962595, TNR=0.957705, MSE=0.038980\n",
      "Validataion: C=10.000000, acc=0.605850, TPR=0.252000, TNR=0.959700, MSE=0.394150\n",
      "Training: C=50.000000, acc=0.961058, TPR=0.962715, TNR=0.957568, MSE=0.038942\n",
      "Validataion: C=50.000000, acc=0.605250, TPR=0.254300, TNR=0.956200, MSE=0.394750\n",
      "Training: C=100.000000, acc=0.961017, TPR=0.962750, TNR=0.957368, MSE=0.038983\n",
      "Validataion: C=100.000000, acc=0.605100, TPR=0.255000, TNR=0.955200, MSE=0.394900\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.686681, TPR=0.999830, TNR=0.027421, MSE=0.313319\n",
      "Validataion: C=0.005000, acc=0.498300, TPR=0.996600, TNR=0.000000, MSE=0.501700\n",
      "Training: C=0.010000, acc=0.846281, TPR=0.987945, TNR=0.548042, MSE=0.153719\n",
      "Validataion: C=0.010000, acc=0.475350, TPR=0.759000, TNR=0.191700, MSE=0.524650\n",
      "Training: C=0.050000, acc=0.948712, TPR=0.970960, TNR=0.901874, MSE=0.051288\n",
      "Validataion: C=0.050000, acc=0.684400, TPR=0.419300, TNR=0.949500, MSE=0.315600\n",
      "Training: C=0.100000, acc=0.956319, TPR=0.967420, TNR=0.932947, MSE=0.043681\n",
      "Validataion: C=0.100000, acc=0.657000, TPR=0.348500, TNR=0.965500, MSE=0.343000\n",
      "Training: C=0.500000, acc=0.961329, TPR=0.963250, TNR=0.957284, MSE=0.038671\n",
      "Validataion: C=0.500000, acc=0.618750, TPR=0.265100, TNR=0.972400, MSE=0.381250\n",
      "Training: C=1.000000, acc=0.961654, TPR=0.962520, TNR=0.959832, MSE=0.038346\n",
      "Validataion: C=1.000000, acc=0.610900, TPR=0.250500, TNR=0.971300, MSE=0.389100\n",
      "Training: C=5.000000, acc=0.961841, TPR=0.961885, TNR=0.961747, MSE=0.038159\n",
      "Validataion: C=5.000000, acc=0.601550, TPR=0.237800, TNR=0.965300, MSE=0.398450\n",
      "Training: C=10.000000, acc=0.961834, TPR=0.961930, TNR=0.961632, MSE=0.038166\n",
      "Validataion: C=10.000000, acc=0.600950, TPR=0.238700, TNR=0.963200, MSE=0.399050\n",
      "Training: C=50.000000, acc=0.961817, TPR=0.962010, TNR=0.961411, MSE=0.038183\n",
      "Validataion: C=50.000000, acc=0.600450, TPR=0.240200, TNR=0.960700, MSE=0.399550\n",
      "Training: C=100.000000, acc=0.961858, TPR=0.962105, TNR=0.961337, MSE=0.038142\n",
      "Validataion: C=100.000000, acc=0.601150, TPR=0.242100, TNR=0.960200, MSE=0.398850\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.686590, TPR=0.999835, TNR=0.027126, MSE=0.313410\n",
      "Validataion: C=0.005000, acc=0.498350, TPR=0.996700, TNR=0.000000, MSE=0.501650\n",
      "Training: C=0.010000, acc=0.836620, TPR=0.988300, TNR=0.517295, MSE=0.163380\n",
      "Validataion: C=0.010000, acc=0.383950, TPR=0.766100, TNR=0.001800, MSE=0.616050\n",
      "Training: C=0.050000, acc=0.949386, TPR=0.970610, TNR=0.904705, MSE=0.050614\n",
      "Validataion: C=0.050000, acc=0.684600, TPR=0.412300, TNR=0.956900, MSE=0.315400\n",
      "Training: C=0.100000, acc=0.957234, TPR=0.966925, TNR=0.936832, MSE=0.042766\n",
      "Validataion: C=0.100000, acc=0.655300, TPR=0.338600, TNR=0.972000, MSE=0.344700\n",
      "Training: C=0.500000, acc=0.962061, TPR=0.962550, TNR=0.961032, MSE=0.037939\n",
      "Validataion: C=0.500000, acc=0.614650, TPR=0.251100, TNR=0.978200, MSE=0.385350\n",
      "Training: C=1.000000, acc=0.962407, TPR=0.961730, TNR=0.963832, MSE=0.037593\n",
      "Validataion: C=1.000000, acc=0.606450, TPR=0.234700, TNR=0.978200, MSE=0.393550\n",
      "Training: C=5.000000, acc=0.962573, TPR=0.961210, TNR=0.965442, MSE=0.037427\n",
      "Validataion: C=5.000000, acc=0.598250, TPR=0.224300, TNR=0.972200, MSE=0.401750\n",
      "Training: C=10.000000, acc=0.962563, TPR=0.961285, TNR=0.965253, MSE=0.037437\n",
      "Validataion: C=10.000000, acc=0.597300, TPR=0.225700, TNR=0.968900, MSE=0.402700\n",
      "Training: C=50.000000, acc=0.962661, TPR=0.961540, TNR=0.965021, MSE=0.037339\n",
      "Validataion: C=50.000000, acc=0.597900, TPR=0.230800, TNR=0.965000, MSE=0.402100\n",
      "Training: C=100.000000, acc=0.962600, TPR=0.961585, TNR=0.964737, MSE=0.037400\n",
      "Validataion: C=100.000000, acc=0.597600, TPR=0.231700, TNR=0.963500, MSE=0.402400\n",
      "\n",
      "Running # Neg: 90000\n",
      "# total training data: 300000, # Neg: 90000\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.744787, TPR=0.996425, TNR=0.241510, MSE=0.255213\n",
      "Validataion: C=0.005000, acc=0.464700, TPR=0.928600, TNR=0.000800, MSE=0.535300\n",
      "Training: C=0.010000, acc=0.876280, TPR=0.984790, TNR=0.659260, MSE=0.123720\n",
      "Validataion: C=0.010000, acc=0.603750, TPR=0.695900, TNR=0.511600, MSE=0.396250\n",
      "Training: C=0.050000, acc=0.946177, TPR=0.971895, TNR=0.894740, MSE=0.053823\n",
      "Validataion: C=0.050000, acc=0.679200, TPR=0.438000, TNR=0.920400, MSE=0.320800\n",
      "Training: C=0.100000, acc=0.952733, TPR=0.969180, TNR=0.919840, MSE=0.047267\n",
      "Validataion: C=0.100000, acc=0.663100, TPR=0.383700, TNR=0.942500, MSE=0.336900\n",
      "Training: C=0.500000, acc=0.957813, TPR=0.965130, TNR=0.943180, MSE=0.042187\n",
      "Validataion: C=0.500000, acc=0.627500, TPR=0.302800, TNR=0.952200, MSE=0.372500\n",
      "Training: C=1.000000, acc=0.958553, TPR=0.964210, TNR=0.947240, MSE=0.041447\n",
      "Validataion: C=1.000000, acc=0.618350, TPR=0.284400, TNR=0.952300, MSE=0.381650\n",
      "Training: C=5.000000, acc=0.959237, TPR=0.963340, TNR=0.951030, MSE=0.040763\n",
      "Validataion: C=5.000000, acc=0.607650, TPR=0.267000, TNR=0.948300, MSE=0.392350\n",
      "Training: C=10.000000, acc=0.959277, TPR=0.963315, TNR=0.951200, MSE=0.040723\n",
      "Validataion: C=10.000000, acc=0.606050, TPR=0.266500, TNR=0.945600, MSE=0.393950\n",
      "Training: C=50.000000, acc=0.959457, TPR=0.963460, TNR=0.951450, MSE=0.040543\n",
      "Validataion: C=50.000000, acc=0.605500, TPR=0.269500, TNR=0.941500, MSE=0.394500\n",
      "Training: C=100.000000, acc=0.959460, TPR=0.963470, TNR=0.951440, MSE=0.040540\n",
      "Validataion: C=100.000000, acc=0.605200, TPR=0.269600, TNR=0.940800, MSE=0.394800\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.734817, TPR=0.997030, TNR=0.210390, MSE=0.265183\n",
      "Validataion: C=0.005000, acc=0.470750, TPR=0.940700, TNR=0.000800, MSE=0.529250\n",
      "Training: C=0.010000, acc=0.873290, TPR=0.984895, TNR=0.650080, MSE=0.126710\n",
      "Validataion: C=0.010000, acc=0.588050, TPR=0.698000, TNR=0.478100, MSE=0.411950\n",
      "Training: C=0.050000, acc=0.948170, TPR=0.971180, TNR=0.902150, MSE=0.051830\n",
      "Validataion: C=0.050000, acc=0.680550, TPR=0.423700, TNR=0.937400, MSE=0.319450\n",
      "Training: C=0.100000, acc=0.954547, TPR=0.968200, TNR=0.927240, MSE=0.045453\n",
      "Validataion: C=0.100000, acc=0.659350, TPR=0.364100, TNR=0.954600, MSE=0.340650\n",
      "Training: C=0.500000, acc=0.959270, TPR=0.964195, TNR=0.949420, MSE=0.040730\n",
      "Validataion: C=0.500000, acc=0.623050, TPR=0.284100, TNR=0.962000, MSE=0.376950\n",
      "Training: C=1.000000, acc=0.960023, TPR=0.963535, TNR=0.953000, MSE=0.039977\n",
      "Validataion: C=1.000000, acc=0.615900, TPR=0.270900, TNR=0.960900, MSE=0.384100\n",
      "Training: C=5.000000, acc=0.960450, TPR=0.962735, TNR=0.955880, MSE=0.039550\n",
      "Validataion: C=5.000000, acc=0.605250, TPR=0.254900, TNR=0.955600, MSE=0.394750\n",
      "Training: C=10.000000, acc=0.960600, TPR=0.962785, TNR=0.956230, MSE=0.039400\n",
      "Validataion: C=10.000000, acc=0.604950, TPR=0.255800, TNR=0.954100, MSE=0.395050\n",
      "Training: C=50.000000, acc=0.960623, TPR=0.962840, TNR=0.956190, MSE=0.039377\n",
      "Validataion: C=50.000000, acc=0.603600, TPR=0.256900, TNR=0.950300, MSE=0.396400\n",
      "Training: C=100.000000, acc=0.960597, TPR=0.962910, TNR=0.955970, MSE=0.039403\n",
      "Validataion: C=100.000000, acc=0.603350, TPR=0.258300, TNR=0.948400, MSE=0.396650\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.724693, TPR=0.997510, TNR=0.179060, MSE=0.275307\n",
      "Validataion: C=0.005000, acc=0.475450, TPR=0.950300, TNR=0.000600, MSE=0.524550\n",
      "Training: C=0.010000, acc=0.869377, TPR=0.985115, TNR=0.637900, MSE=0.130623\n",
      "Validataion: C=0.010000, acc=0.567850, TPR=0.702400, TNR=0.433300, MSE=0.432150\n",
      "Training: C=0.050000, acc=0.949397, TPR=0.970525, TNR=0.907140, MSE=0.050603\n",
      "Validataion: C=0.050000, acc=0.679700, TPR=0.410600, TNR=0.948800, MSE=0.320300\n",
      "Training: C=0.100000, acc=0.955927, TPR=0.967400, TNR=0.932980, MSE=0.044073\n",
      "Validataion: C=0.100000, acc=0.655250, TPR=0.348100, TNR=0.962400, MSE=0.344750\n",
      "Training: C=0.500000, acc=0.960353, TPR=0.963435, TNR=0.954190, MSE=0.039647\n",
      "Validataion: C=0.500000, acc=0.618100, TPR=0.268800, TNR=0.967400, MSE=0.381900\n",
      "Training: C=1.000000, acc=0.961013, TPR=0.962755, TNR=0.957530, MSE=0.038987\n",
      "Validataion: C=1.000000, acc=0.610900, TPR=0.255200, TNR=0.966600, MSE=0.389100\n",
      "Training: C=5.000000, acc=0.961407, TPR=0.962030, TNR=0.960160, MSE=0.038593\n",
      "Validataion: C=5.000000, acc=0.601500, TPR=0.240700, TNR=0.962300, MSE=0.398500\n",
      "Training: C=10.000000, acc=0.961440, TPR=0.962045, TNR=0.960230, MSE=0.038560\n",
      "Validataion: C=10.000000, acc=0.600950, TPR=0.241000, TNR=0.960900, MSE=0.399050\n",
      "Training: C=50.000000, acc=0.961377, TPR=0.962175, TNR=0.959780, MSE=0.038623\n",
      "Validataion: C=50.000000, acc=0.600150, TPR=0.243500, TNR=0.956800, MSE=0.399850\n",
      "Training: C=100.000000, acc=0.961300, TPR=0.962205, TNR=0.959490, MSE=0.038700\n",
      "Validataion: C=100.000000, acc=0.599700, TPR=0.244100, TNR=0.955300, MSE=0.400300\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.713977, TPR=0.998115, TNR=0.145700, MSE=0.286023\n",
      "Validataion: C=0.005000, acc=0.481450, TPR=0.962400, TNR=0.000500, MSE=0.518550\n",
      "Training: C=0.010000, acc=0.865327, TPR=0.985525, TNR=0.624930, MSE=0.134673\n",
      "Validataion: C=0.010000, acc=0.547650, TPR=0.710600, TNR=0.384700, MSE=0.452350\n",
      "Training: C=0.050000, acc=0.950350, TPR=0.969970, TNR=0.911110, MSE=0.049650\n",
      "Validataion: C=0.050000, acc=0.678300, TPR=0.399500, TNR=0.957100, MSE=0.321700\n",
      "Training: C=0.100000, acc=0.956900, TPR=0.966735, TNR=0.937230, MSE=0.043100\n",
      "Validataion: C=0.100000, acc=0.651700, TPR=0.334800, TNR=0.968600, MSE=0.348300\n",
      "Training: C=0.500000, acc=0.961287, TPR=0.962650, TNR=0.958560, MSE=0.038713\n",
      "Validataion: C=0.500000, acc=0.613700, TPR=0.253100, TNR=0.974300, MSE=0.386300\n",
      "Training: C=1.000000, acc=0.961780, TPR=0.961990, TNR=0.961360, MSE=0.038220\n",
      "Validataion: C=1.000000, acc=0.606650, TPR=0.239900, TNR=0.973400, MSE=0.393350\n",
      "Training: C=5.000000, acc=0.961983, TPR=0.961335, TNR=0.963280, MSE=0.038017\n",
      "Validataion: C=5.000000, acc=0.596600, TPR=0.226800, TNR=0.966400, MSE=0.403400\n",
      "Training: C=10.000000, acc=0.962060, TPR=0.961355, TNR=0.963470, MSE=0.037940\n",
      "Validataion: C=10.000000, acc=0.595500, TPR=0.227200, TNR=0.963800, MSE=0.404500\n",
      "Training: C=50.000000, acc=0.962167, TPR=0.961540, TNR=0.963420, MSE=0.037833\n",
      "Validataion: C=50.000000, acc=0.596300, TPR=0.230800, TNR=0.961800, MSE=0.403700\n",
      "Training: C=100.000000, acc=0.962173, TPR=0.961590, TNR=0.963340, MSE=0.037827\n",
      "Validataion: C=100.000000, acc=0.596100, TPR=0.231800, TNR=0.960400, MSE=0.403900\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.703840, TPR=0.998605, TNR=0.114310, MSE=0.296160\n",
      "Validataion: C=0.005000, acc=0.486300, TPR=0.972100, TNR=0.000500, MSE=0.513700\n",
      "Training: C=0.010000, acc=0.861100, TPR=0.985750, TNR=0.611800, MSE=0.138900\n",
      "Validataion: C=0.010000, acc=0.521450, TPR=0.715100, TNR=0.327800, MSE=0.478550\n",
      "Training: C=0.050000, acc=0.950953, TPR=0.969565, TNR=0.913730, MSE=0.049047\n",
      "Validataion: C=0.050000, acc=0.677350, TPR=0.391400, TNR=0.963300, MSE=0.322650\n",
      "Training: C=0.100000, acc=0.957740, TPR=0.966160, TNR=0.940900, MSE=0.042260\n",
      "Validataion: C=0.100000, acc=0.649750, TPR=0.323300, TNR=0.976200, MSE=0.350250\n",
      "Training: C=0.500000, acc=0.962160, TPR=0.962095, TNR=0.962290, MSE=0.037840\n",
      "Validataion: C=0.500000, acc=0.610550, TPR=0.242000, TNR=0.979100, MSE=0.389450\n",
      "Training: C=1.000000, acc=0.962540, TPR=0.961315, TNR=0.964990, MSE=0.037460\n",
      "Validataion: C=1.000000, acc=0.602450, TPR=0.226400, TNR=0.978500, MSE=0.397550\n",
      "Training: C=5.000000, acc=0.962800, TPR=0.960715, TNR=0.966970, MSE=0.037200\n",
      "Validataion: C=5.000000, acc=0.593900, TPR=0.214400, TNR=0.973400, MSE=0.406100\n",
      "Training: C=10.000000, acc=0.962867, TPR=0.960745, TNR=0.967110, MSE=0.037133\n",
      "Validataion: C=10.000000, acc=0.592600, TPR=0.214900, TNR=0.970300, MSE=0.407400\n",
      "Training: C=50.000000, acc=0.962860, TPR=0.961010, TNR=0.966560, MSE=0.037140\n",
      "Validataion: C=50.000000, acc=0.593050, TPR=0.220200, TNR=0.965900, MSE=0.406950\n",
      "Training: C=100.000000, acc=0.962860, TPR=0.961090, TNR=0.966400, MSE=0.037140\n",
      "Validataion: C=100.000000, acc=0.593100, TPR=0.221800, TNR=0.964400, MSE=0.406900\n",
      "\n",
      "Running # Neg: 95000\n",
      "# total training data: 305000, # Neg: 95000\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.780000, TPR=0.993395, TNR=0.373533, MSE=0.220000\n",
      "Validataion: C=0.005000, acc=0.434650, TPR=0.868000, TNR=0.001300, MSE=0.565350\n",
      "Training: C=0.010000, acc=0.887538, TPR=0.982980, TNR=0.705743, MSE=0.112462\n",
      "Validataion: C=0.010000, acc=0.648800, TPR=0.659700, TNR=0.637900, MSE=0.351200\n",
      "Training: C=0.050000, acc=0.946987, TPR=0.971185, TNR=0.900895, MSE=0.053013\n",
      "Validataion: C=0.050000, acc=0.677650, TPR=0.423800, TNR=0.931500, MSE=0.322350\n",
      "Training: C=0.100000, acc=0.952957, TPR=0.968605, TNR=0.923152, MSE=0.047043\n",
      "Validataion: C=0.100000, acc=0.659950, TPR=0.372200, TNR=0.947700, MSE=0.340050\n",
      "Training: C=0.500000, acc=0.958016, TPR=0.964695, TNR=0.945295, MSE=0.041984\n",
      "Validataion: C=0.500000, acc=0.624850, TPR=0.294100, TNR=0.955600, MSE=0.375150\n",
      "Training: C=1.000000, acc=0.958643, TPR=0.963785, TNR=0.948848, MSE=0.041357\n",
      "Validataion: C=1.000000, acc=0.615250, TPR=0.275900, TNR=0.954600, MSE=0.384750\n",
      "Training: C=5.000000, acc=0.959285, TPR=0.963000, TNR=0.952210, MSE=0.040715\n",
      "Validataion: C=5.000000, acc=0.605450, TPR=0.260200, TNR=0.950700, MSE=0.394550\n",
      "Training: C=10.000000, acc=0.959279, TPR=0.962945, TNR=0.952295, MSE=0.040721\n",
      "Validataion: C=10.000000, acc=0.603450, TPR=0.259100, TNR=0.947800, MSE=0.396550\n",
      "Training: C=50.000000, acc=0.959361, TPR=0.963040, TNR=0.952352, MSE=0.040639\n",
      "Validataion: C=50.000000, acc=0.602250, TPR=0.261100, TNR=0.943400, MSE=0.397750\n",
      "Training: C=100.000000, acc=0.959407, TPR=0.963100, TNR=0.952371, MSE=0.040593\n",
      "Validataion: C=100.000000, acc=0.602700, TPR=0.262300, TNR=0.943100, MSE=0.397300\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.772925, TPR=0.993995, TNR=0.351838, MSE=0.227075\n",
      "Validataion: C=0.005000, acc=0.440650, TPR=0.880000, TNR=0.001300, MSE=0.559350\n",
      "Training: C=0.010000, acc=0.886030, TPR=0.982935, TNR=0.701448, MSE=0.113970\n",
      "Validataion: C=0.010000, acc=0.641000, TPR=0.658800, TNR=0.623200, MSE=0.359000\n",
      "Training: C=0.050000, acc=0.948800, TPR=0.970410, TNR=0.907638, MSE=0.051200\n",
      "Validataion: C=0.050000, acc=0.676950, TPR=0.408300, TNR=0.945600, MSE=0.323050\n",
      "Training: C=0.100000, acc=0.954626, TPR=0.967565, TNR=0.929981, MSE=0.045374\n",
      "Validataion: C=0.100000, acc=0.655000, TPR=0.351400, TNR=0.958600, MSE=0.345000\n",
      "Training: C=0.500000, acc=0.959469, TPR=0.963865, TNR=0.951095, MSE=0.040531\n",
      "Validataion: C=0.500000, acc=0.620350, TPR=0.277500, TNR=0.963200, MSE=0.379650\n",
      "Training: C=1.000000, acc=0.960056, TPR=0.963080, TNR=0.954295, MSE=0.039944\n",
      "Validataion: C=1.000000, acc=0.612500, TPR=0.261800, TNR=0.963200, MSE=0.387500\n",
      "Training: C=5.000000, acc=0.960403, TPR=0.962400, TNR=0.956600, MSE=0.039597\n",
      "Validataion: C=5.000000, acc=0.603000, TPR=0.248200, TNR=0.957800, MSE=0.397000\n",
      "Training: C=10.000000, acc=0.960492, TPR=0.962410, TNR=0.956838, MSE=0.039508\n",
      "Validataion: C=10.000000, acc=0.601850, TPR=0.248400, TNR=0.955300, MSE=0.398150\n",
      "Training: C=50.000000, acc=0.960534, TPR=0.962380, TNR=0.957019, MSE=0.039466\n",
      "Validataion: C=50.000000, acc=0.600550, TPR=0.247700, TNR=0.953400, MSE=0.399450\n",
      "Training: C=100.000000, acc=0.960518, TPR=0.962430, TNR=0.956876, MSE=0.039482\n",
      "Validataion: C=100.000000, acc=0.600400, TPR=0.248700, TNR=0.952100, MSE=0.399600\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.762377, TPR=0.994700, TNR=0.319857, MSE=0.237623\n",
      "Validataion: C=0.005000, acc=0.447650, TPR=0.894100, TNR=0.001200, MSE=0.552350\n",
      "Training: C=0.010000, acc=0.883774, TPR=0.983050, TNR=0.694676, MSE=0.116226\n",
      "Validataion: C=0.010000, acc=0.632150, TPR=0.661100, TNR=0.603200, MSE=0.367850\n",
      "Training: C=0.050000, acc=0.950125, TPR=0.969700, TNR=0.912838, MSE=0.049875\n",
      "Validataion: C=0.050000, acc=0.675100, TPR=0.394100, TNR=0.956100, MSE=0.324900\n",
      "Training: C=0.100000, acc=0.956121, TPR=0.966870, TNR=0.935648, MSE=0.043879\n",
      "Validataion: C=0.100000, acc=0.651400, TPR=0.337500, TNR=0.965300, MSE=0.348600\n",
      "Training: C=0.500000, acc=0.960534, TPR=0.963070, TNR=0.955705, MSE=0.039466\n",
      "Validataion: C=0.500000, acc=0.615100, TPR=0.261500, TNR=0.968700, MSE=0.384900\n",
      "Training: C=1.000000, acc=0.961075, TPR=0.962335, TNR=0.958676, MSE=0.038925\n",
      "Validataion: C=1.000000, acc=0.607450, TPR=0.246900, TNR=0.968000, MSE=0.392550\n",
      "Training: C=5.000000, acc=0.961351, TPR=0.961660, TNR=0.960762, MSE=0.038649\n",
      "Validataion: C=5.000000, acc=0.598150, TPR=0.233300, TNR=0.963000, MSE=0.401850\n",
      "Training: C=10.000000, acc=0.961443, TPR=0.961700, TNR=0.960952, MSE=0.038557\n",
      "Validataion: C=10.000000, acc=0.598050, TPR=0.234100, TNR=0.962000, MSE=0.401950\n",
      "Training: C=50.000000, acc=0.961511, TPR=0.961825, TNR=0.960914, MSE=0.038489\n",
      "Validataion: C=50.000000, acc=0.597250, TPR=0.236500, TNR=0.958000, MSE=0.402750\n",
      "Training: C=100.000000, acc=0.961492, TPR=0.961880, TNR=0.960752, MSE=0.038508\n",
      "Validataion: C=100.000000, acc=0.597550, TPR=0.237600, TNR=0.957500, MSE=0.402450\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.754033, TPR=0.995290, TNR=0.294495, MSE=0.245967\n",
      "Validataion: C=0.005000, acc=0.453550, TPR=0.905900, TNR=0.001200, MSE=0.546450\n",
      "Training: C=0.010000, acc=0.881321, TPR=0.983180, TNR=0.687305, MSE=0.118679\n",
      "Validataion: C=0.010000, acc=0.620100, TPR=0.663700, TNR=0.576500, MSE=0.379900\n",
      "Training: C=0.050000, acc=0.951030, TPR=0.969170, TNR=0.916476, MSE=0.048970\n",
      "Validataion: C=0.050000, acc=0.673400, TPR=0.383500, TNR=0.963300, MSE=0.326600\n",
      "Training: C=0.100000, acc=0.957184, TPR=0.966205, TNR=0.940000, MSE=0.042816\n",
      "Validataion: C=0.100000, acc=0.647850, TPR=0.324200, TNR=0.971500, MSE=0.352150\n",
      "Training: C=0.500000, acc=0.961538, TPR=0.962365, TNR=0.959962, MSE=0.038462\n",
      "Validataion: C=0.500000, acc=0.611750, TPR=0.247400, TNR=0.976100, MSE=0.388250\n",
      "Training: C=1.000000, acc=0.962036, TPR=0.961660, TNR=0.962752, MSE=0.037964\n",
      "Validataion: C=1.000000, acc=0.604250, TPR=0.233300, TNR=0.975200, MSE=0.395750\n",
      "Training: C=5.000000, acc=0.962233, TPR=0.960955, TNR=0.964667, MSE=0.037767\n",
      "Validataion: C=5.000000, acc=0.593900, TPR=0.219200, TNR=0.968600, MSE=0.406100\n",
      "Training: C=10.000000, acc=0.962203, TPR=0.961060, TNR=0.964381, MSE=0.037797\n",
      "Validataion: C=10.000000, acc=0.593650, TPR=0.221300, TNR=0.966000, MSE=0.406350\n",
      "Training: C=50.000000, acc=0.962305, TPR=0.961255, TNR=0.964305, MSE=0.037695\n",
      "Validataion: C=50.000000, acc=0.594200, TPR=0.225100, TNR=0.963300, MSE=0.405800\n",
      "Training: C=100.000000, acc=0.962256, TPR=0.961325, TNR=0.964029, MSE=0.037744\n",
      "Validataion: C=100.000000, acc=0.594400, TPR=0.226500, TNR=0.962300, MSE=0.405600\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.744849, TPR=0.995875, TNR=0.266705, MSE=0.255151\n",
      "Validataion: C=0.005000, acc=0.459200, TPR=0.917600, TNR=0.000800, MSE=0.540800\n",
      "Training: C=0.010000, acc=0.878059, TPR=0.983430, TNR=0.677352, MSE=0.121941\n",
      "Validataion: C=0.010000, acc=0.606450, TPR=0.668700, TNR=0.544200, MSE=0.393550\n",
      "Training: C=0.050000, acc=0.951780, TPR=0.968790, TNR=0.919381, MSE=0.048220\n",
      "Validataion: C=0.050000, acc=0.672400, TPR=0.375900, TNR=0.968900, MSE=0.327600\n",
      "Training: C=0.100000, acc=0.958108, TPR=0.965595, TNR=0.943848, MSE=0.041892\n",
      "Validataion: C=0.100000, acc=0.645050, TPR=0.312000, TNR=0.978100, MSE=0.354950\n",
      "Training: C=0.500000, acc=0.962390, TPR=0.961725, TNR=0.963657, MSE=0.037610\n",
      "Validataion: C=0.500000, acc=0.607400, TPR=0.234600, TNR=0.980200, MSE=0.392600\n",
      "Training: C=1.000000, acc=0.962767, TPR=0.960975, TNR=0.966181, MSE=0.037233\n",
      "Validataion: C=1.000000, acc=0.599650, TPR=0.219600, TNR=0.979700, MSE=0.400350\n",
      "Training: C=5.000000, acc=0.962977, TPR=0.960360, TNR=0.967962, MSE=0.037023\n",
      "Validataion: C=5.000000, acc=0.591200, TPR=0.207300, TNR=0.975100, MSE=0.408800\n",
      "Training: C=10.000000, acc=0.963030, TPR=0.960450, TNR=0.967943, MSE=0.036970\n",
      "Validataion: C=10.000000, acc=0.590600, TPR=0.209000, TNR=0.972200, MSE=0.409400\n",
      "Training: C=50.000000, acc=0.962987, TPR=0.960695, TNR=0.967352, MSE=0.037013\n",
      "Validataion: C=50.000000, acc=0.590500, TPR=0.213900, TNR=0.967100, MSE=0.409500\n",
      "Training: C=100.000000, acc=0.962967, TPR=0.960785, TNR=0.967124, MSE=0.037033\n",
      "Validataion: C=100.000000, acc=0.590950, TPR=0.215700, TNR=0.966200, MSE=0.409050\n",
      "\n",
      "Running # Neg: 100000\n",
      "# total training data: 310000, # Neg: 100000\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.805716, TPR=0.990500, TNR=0.469745, MSE=0.194284\n",
      "Validataion: C=0.005000, acc=0.405950, TPR=0.810100, TNR=0.001800, MSE=0.594050\n",
      "Training: C=0.010000, acc=0.897310, TPR=0.981300, TNR=0.744600, MSE=0.102690\n",
      "Validataion: C=0.010000, acc=0.675350, TPR=0.626100, TNR=0.724600, MSE=0.324650\n",
      "Training: C=0.050000, acc=0.947848, TPR=0.970525, TNR=0.906618, MSE=0.052152\n",
      "Validataion: C=0.050000, acc=0.676000, TPR=0.410600, TNR=0.941400, MSE=0.324000\n",
      "Training: C=0.100000, acc=0.953606, TPR=0.968090, TNR=0.927273, MSE=0.046394\n",
      "Validataion: C=0.100000, acc=0.657300, TPR=0.361900, TNR=0.952700, MSE=0.342700\n",
      "Training: C=0.500000, acc=0.958594, TPR=0.964320, TNR=0.948182, MSE=0.041406\n",
      "Validataion: C=0.500000, acc=0.622150, TPR=0.286600, TNR=0.957700, MSE=0.377850\n",
      "Training: C=1.000000, acc=0.959439, TPR=0.963530, TNR=0.952000, MSE=0.040561\n",
      "Validataion: C=1.000000, acc=0.614050, TPR=0.270800, TNR=0.957300, MSE=0.385950\n",
      "Training: C=5.000000, acc=0.960206, TPR=0.962795, TNR=0.955500, MSE=0.039794\n",
      "Validataion: C=5.000000, acc=0.604050, TPR=0.256100, TNR=0.952000, MSE=0.395950\n",
      "Training: C=10.000000, acc=0.960290, TPR=0.962735, TNR=0.955845, MSE=0.039710\n",
      "Validataion: C=10.000000, acc=0.602400, TPR=0.254900, TNR=0.949900, MSE=0.397600\n",
      "Training: C=50.000000, acc=0.960252, TPR=0.962835, TNR=0.955555, MSE=0.039748\n",
      "Validataion: C=50.000000, acc=0.601100, TPR=0.256900, TNR=0.945300, MSE=0.398900\n",
      "Training: C=100.000000, acc=0.960294, TPR=0.962895, TNR=0.955564, MSE=0.039706\n",
      "Validataion: C=100.000000, acc=0.601550, TPR=0.258000, TNR=0.945100, MSE=0.398450\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.800755, TPR=0.990850, TNR=0.455127, MSE=0.199245\n",
      "Validataion: C=0.005000, acc=0.409450, TPR=0.817100, TNR=0.001800, MSE=0.590550\n",
      "Training: C=0.010000, acc=0.896429, TPR=0.981275, TNR=0.742164, MSE=0.103571\n",
      "Validataion: C=0.010000, acc=0.676150, TPR=0.625600, TNR=0.726700, MSE=0.323850\n",
      "Training: C=0.050000, acc=0.949723, TPR=0.969760, TNR=0.913291, MSE=0.050277\n",
      "Validataion: C=0.050000, acc=0.674400, TPR=0.395300, TNR=0.953500, MSE=0.325600\n",
      "Training: C=0.100000, acc=0.955481, TPR=0.967135, TNR=0.934291, MSE=0.044519\n",
      "Validataion: C=0.100000, acc=0.652450, TPR=0.342800, TNR=0.962100, MSE=0.347550\n",
      "Training: C=0.500000, acc=0.960081, TPR=0.963580, TNR=0.953718, MSE=0.039919\n",
      "Validataion: C=0.500000, acc=0.618200, TPR=0.271800, TNR=0.964600, MSE=0.381800\n",
      "Training: C=1.000000, acc=0.960735, TPR=0.962820, TNR=0.956945, MSE=0.039265\n",
      "Validataion: C=1.000000, acc=0.610250, TPR=0.256600, TNR=0.963900, MSE=0.389750\n",
      "Training: C=5.000000, acc=0.961281, TPR=0.962175, TNR=0.959655, MSE=0.038719\n",
      "Validataion: C=5.000000, acc=0.601650, TPR=0.243700, TNR=0.959600, MSE=0.398350\n",
      "Training: C=10.000000, acc=0.961297, TPR=0.962165, TNR=0.959718, MSE=0.038703\n",
      "Validataion: C=10.000000, acc=0.600050, TPR=0.243500, TNR=0.956600, MSE=0.399950\n",
      "Training: C=50.000000, acc=0.961287, TPR=0.962250, TNR=0.959536, MSE=0.038713\n",
      "Validataion: C=50.000000, acc=0.599400, TPR=0.245000, TNR=0.953800, MSE=0.400600\n",
      "Training: C=100.000000, acc=0.961277, TPR=0.962285, TNR=0.959445, MSE=0.038723\n",
      "Validataion: C=100.000000, acc=0.599400, TPR=0.245700, TNR=0.953100, MSE=0.400600\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.795558, TPR=0.991230, TNR=0.439791, MSE=0.204442\n",
      "Validataion: C=0.005000, acc=0.413250, TPR=0.824700, TNR=0.001800, MSE=0.586750\n",
      "Training: C=0.010000, acc=0.895129, TPR=0.981340, TNR=0.738382, MSE=0.104871\n",
      "Validataion: C=0.010000, acc=0.675000, TPR=0.626900, TNR=0.723100, MSE=0.325000\n",
      "Training: C=0.050000, acc=0.950974, TPR=0.969050, TNR=0.918109, MSE=0.049026\n",
      "Validataion: C=0.050000, acc=0.671200, TPR=0.381100, TNR=0.961300, MSE=0.328800\n",
      "Training: C=0.100000, acc=0.956900, TPR=0.966410, TNR=0.939609, MSE=0.043100\n",
      "Validataion: C=0.100000, acc=0.647900, TPR=0.328300, TNR=0.967500, MSE=0.352100\n",
      "Training: C=0.500000, acc=0.961226, TPR=0.962790, TNR=0.958382, MSE=0.038774\n",
      "Validataion: C=0.500000, acc=0.613050, TPR=0.256000, TNR=0.970100, MSE=0.386950\n",
      "Training: C=1.000000, acc=0.961742, TPR=0.962135, TNR=0.961027, MSE=0.038258\n",
      "Validataion: C=1.000000, acc=0.606100, TPR=0.242900, TNR=0.969300, MSE=0.393900\n",
      "Training: C=5.000000, acc=0.962045, TPR=0.961455, TNR=0.963118, MSE=0.037955\n",
      "Validataion: C=5.000000, acc=0.596250, TPR=0.229200, TNR=0.963300, MSE=0.403750\n",
      "Training: C=10.000000, acc=0.962161, TPR=0.961480, TNR=0.963400, MSE=0.037839\n",
      "Validataion: C=10.000000, acc=0.596300, TPR=0.229700, TNR=0.962900, MSE=0.403700\n",
      "Training: C=50.000000, acc=0.962245, TPR=0.961680, TNR=0.963273, MSE=0.037755\n",
      "Validataion: C=50.000000, acc=0.596100, TPR=0.233600, TNR=0.958600, MSE=0.403900\n",
      "Training: C=100.000000, acc=0.962248, TPR=0.961705, TNR=0.963236, MSE=0.037752\n",
      "Validataion: C=100.000000, acc=0.596100, TPR=0.234100, TNR=0.958100, MSE=0.403900\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.788219, TPR=0.991755, TNR=0.418155, MSE=0.211781\n",
      "Validataion: C=0.005000, acc=0.418450, TPR=0.835200, TNR=0.001700, MSE=0.581550\n",
      "Training: C=0.010000, acc=0.893442, TPR=0.981355, TNR=0.733600, MSE=0.106558\n",
      "Validataion: C=0.010000, acc=0.671550, TPR=0.627200, TNR=0.715900, MSE=0.328450\n",
      "Training: C=0.050000, acc=0.952094, TPR=0.968590, TNR=0.922100, MSE=0.047906\n",
      "Validataion: C=0.050000, acc=0.669600, TPR=0.371900, TNR=0.967300, MSE=0.330400\n",
      "Training: C=0.100000, acc=0.958042, TPR=0.965760, TNR=0.944009, MSE=0.041958\n",
      "Validataion: C=0.100000, acc=0.645000, TPR=0.315300, TNR=0.974700, MSE=0.355000\n",
      "Training: C=0.500000, acc=0.962277, TPR=0.962110, TNR=0.962582, MSE=0.037723\n",
      "Validataion: C=0.500000, acc=0.610250, TPR=0.242300, TNR=0.978200, MSE=0.389750\n",
      "Training: C=1.000000, acc=0.962719, TPR=0.961430, TNR=0.965064, MSE=0.037281\n",
      "Validataion: C=1.000000, acc=0.602500, TPR=0.228700, TNR=0.976300, MSE=0.397500\n",
      "Training: C=5.000000, acc=0.962865, TPR=0.960765, TNR=0.966682, MSE=0.037135\n",
      "Validataion: C=5.000000, acc=0.592500, TPR=0.215400, TNR=0.969600, MSE=0.407500\n",
      "Training: C=10.000000, acc=0.962913, TPR=0.960905, TNR=0.966564, MSE=0.037087\n",
      "Validataion: C=10.000000, acc=0.592500, TPR=0.218200, TNR=0.966800, MSE=0.407500\n",
      "Training: C=50.000000, acc=0.963061, TPR=0.961140, TNR=0.966555, MSE=0.036939\n",
      "Validataion: C=50.000000, acc=0.593250, TPR=0.222800, TNR=0.963700, MSE=0.406750\n",
      "Training: C=100.000000, acc=0.963123, TPR=0.961220, TNR=0.966582, MSE=0.036877\n",
      "Validataion: C=100.000000, acc=0.593700, TPR=0.224400, TNR=0.963000, MSE=0.406300\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.784823, TPR=0.992195, TNR=0.407782, MSE=0.215177\n",
      "Validataion: C=0.005000, acc=0.422850, TPR=0.844000, TNR=0.001700, MSE=0.577150\n",
      "Training: C=0.010000, acc=0.891729, TPR=0.981450, TNR=0.728600, MSE=0.108271\n",
      "Validataion: C=0.010000, acc=0.667650, TPR=0.629100, TNR=0.706200, MSE=0.332350\n",
      "Training: C=0.050000, acc=0.952794, TPR=0.968175, TNR=0.924827, MSE=0.047206\n",
      "Validataion: C=0.050000, acc=0.668650, TPR=0.363600, TNR=0.973700, MSE=0.331350\n",
      "Training: C=0.100000, acc=0.958855, TPR=0.965155, TNR=0.947400, MSE=0.041145\n",
      "Validataion: C=0.100000, acc=0.641250, TPR=0.303200, TNR=0.979300, MSE=0.358750\n",
      "Training: C=0.500000, acc=0.962997, TPR=0.961465, TNR=0.965782, MSE=0.037003\n",
      "Validataion: C=0.500000, acc=0.605400, TPR=0.229400, TNR=0.981400, MSE=0.394600\n",
      "Training: C=1.000000, acc=0.963355, TPR=0.960785, TNR=0.968027, MSE=0.036645\n",
      "Validataion: C=1.000000, acc=0.598050, TPR=0.215800, TNR=0.980300, MSE=0.401950\n",
      "Training: C=5.000000, acc=0.963645, TPR=0.960255, TNR=0.969809, MSE=0.036355\n",
      "Validataion: C=5.000000, acc=0.590850, TPR=0.205200, TNR=0.976500, MSE=0.409150\n",
      "Training: C=10.000000, acc=0.963671, TPR=0.960310, TNR=0.969782, MSE=0.036329\n",
      "Validataion: C=10.000000, acc=0.589900, TPR=0.206200, TNR=0.973600, MSE=0.410100\n",
      "Training: C=50.000000, acc=0.963677, TPR=0.960550, TNR=0.969364, MSE=0.036323\n",
      "Validataion: C=50.000000, acc=0.589900, TPR=0.211000, TNR=0.968800, MSE=0.410100\n",
      "Training: C=100.000000, acc=0.963681, TPR=0.960655, TNR=0.969182, MSE=0.036319\n",
      "Validataion: C=100.000000, acc=0.590300, TPR=0.213100, TNR=0.967500, MSE=0.409700\n",
      "\n",
      "Running # Neg: 105000\n",
      "# total training data: 315000, # Neg: 105000\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.832517, TPR=0.987590, TNR=0.562826, MSE=0.167483\n",
      "Validataion: C=0.005000, acc=0.471800, TPR=0.751900, TNR=0.191700, MSE=0.528200\n",
      "Training: C=0.010000, acc=0.905086, TPR=0.979895, TNR=0.774983, MSE=0.094914\n",
      "Validataion: C=0.010000, acc=0.691750, TPR=0.598000, TNR=0.785500, MSE=0.308250\n",
      "Training: C=0.050000, acc=0.948619, TPR=0.970020, TNR=0.911400, MSE=0.051381\n",
      "Validataion: C=0.050000, acc=0.673800, TPR=0.400500, TNR=0.947100, MSE=0.326200\n",
      "Training: C=0.100000, acc=0.953971, TPR=0.967580, TNR=0.930304, MSE=0.046029\n",
      "Validataion: C=0.100000, acc=0.653550, TPR=0.351700, TNR=0.955400, MSE=0.346450\n",
      "Training: C=0.500000, acc=0.958549, TPR=0.963865, TNR=0.949304, MSE=0.041451\n",
      "Validataion: C=0.500000, acc=0.618200, TPR=0.277500, TNR=0.958900, MSE=0.381800\n",
      "Training: C=1.000000, acc=0.959486, TPR=0.963020, TNR=0.953339, MSE=0.040514\n",
      "Validataion: C=1.000000, acc=0.609950, TPR=0.260700, TNR=0.959200, MSE=0.390050\n",
      "Training: C=5.000000, acc=0.960190, TPR=0.962300, TNR=0.956522, MSE=0.039810\n",
      "Validataion: C=5.000000, acc=0.599200, TPR=0.246300, TNR=0.952100, MSE=0.400800\n",
      "Training: C=10.000000, acc=0.960321, TPR=0.962305, TNR=0.956870, MSE=0.039679\n",
      "Validataion: C=10.000000, acc=0.598750, TPR=0.246400, TNR=0.951100, MSE=0.401250\n",
      "Training: C=50.000000, acc=0.960317, TPR=0.962410, TNR=0.956678, MSE=0.039683\n",
      "Validataion: C=50.000000, acc=0.597050, TPR=0.248500, TNR=0.945600, MSE=0.402950\n",
      "Training: C=100.000000, acc=0.960317, TPR=0.962430, TNR=0.956643, MSE=0.039683\n",
      "Validataion: C=100.000000, acc=0.597300, TPR=0.248900, TNR=0.945700, MSE=0.402700\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.823337, TPR=0.987840, TNR=0.537243, MSE=0.176663\n",
      "Validataion: C=0.005000, acc=0.379350, TPR=0.756900, TNR=0.001800, MSE=0.620650\n",
      "Training: C=0.010000, acc=0.904797, TPR=0.979765, TNR=0.774417, MSE=0.095203\n",
      "Validataion: C=0.010000, acc=0.694800, TPR=0.595400, TNR=0.794200, MSE=0.305200\n",
      "Training: C=0.050000, acc=0.950349, TPR=0.969205, TNR=0.917557, MSE=0.049651\n",
      "Validataion: C=0.050000, acc=0.671000, TPR=0.384200, TNR=0.957800, MSE=0.329000\n",
      "Training: C=0.100000, acc=0.955835, TPR=0.966700, TNR=0.936939, MSE=0.044165\n",
      "Validataion: C=0.100000, acc=0.649200, TPR=0.334100, TNR=0.964300, MSE=0.350800\n",
      "Training: C=0.500000, acc=0.960165, TPR=0.963145, TNR=0.954983, MSE=0.039835\n",
      "Validataion: C=0.500000, acc=0.614500, TPR=0.263100, TNR=0.965900, MSE=0.385500\n",
      "Training: C=1.000000, acc=0.960784, TPR=0.962345, TNR=0.958070, MSE=0.039216\n",
      "Validataion: C=1.000000, acc=0.605850, TPR=0.247100, TNR=0.964600, MSE=0.394150\n",
      "Training: C=5.000000, acc=0.961327, TPR=0.961660, TNR=0.960748, MSE=0.038673\n",
      "Validataion: C=5.000000, acc=0.597250, TPR=0.233500, TNR=0.961000, MSE=0.402750\n",
      "Training: C=10.000000, acc=0.961381, TPR=0.961655, TNR=0.960904, MSE=0.038619\n",
      "Validataion: C=10.000000, acc=0.595650, TPR=0.233400, TNR=0.957900, MSE=0.404350\n",
      "Training: C=50.000000, acc=0.961397, TPR=0.961845, TNR=0.960617, MSE=0.038603\n",
      "Validataion: C=50.000000, acc=0.595750, TPR=0.237000, TNR=0.954500, MSE=0.404250\n",
      "Training: C=100.000000, acc=0.961403, TPR=0.961930, TNR=0.960487, MSE=0.038597\n",
      "Validataion: C=100.000000, acc=0.596300, TPR=0.238700, TNR=0.953900, MSE=0.403700\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.819022, TPR=0.988190, TNR=0.524817, MSE=0.180978\n",
      "Validataion: C=0.005000, acc=0.382950, TPR=0.763900, TNR=0.002000, MSE=0.617050\n",
      "Training: C=0.010000, acc=0.904168, TPR=0.979720, TNR=0.772774, MSE=0.095832\n",
      "Validataion: C=0.010000, acc=0.696300, TPR=0.594500, TNR=0.798100, MSE=0.303700\n",
      "Training: C=0.050000, acc=0.951749, TPR=0.968580, TNR=0.922478, MSE=0.048251\n",
      "Validataion: C=0.050000, acc=0.668000, TPR=0.371700, TNR=0.964300, MSE=0.332000\n",
      "Training: C=0.100000, acc=0.957333, TPR=0.965955, TNR=0.942339, MSE=0.042667\n",
      "Validataion: C=0.100000, acc=0.644400, TPR=0.319200, TNR=0.969600, MSE=0.355600\n",
      "Training: C=0.500000, acc=0.961337, TPR=0.962425, TNR=0.959443, MSE=0.038663\n",
      "Validataion: C=0.500000, acc=0.610100, TPR=0.248700, TNR=0.971500, MSE=0.389900\n",
      "Training: C=1.000000, acc=0.961930, TPR=0.961740, TNR=0.962261, MSE=0.038070\n",
      "Validataion: C=1.000000, acc=0.602400, TPR=0.235000, TNR=0.969800, MSE=0.397600\n",
      "Training: C=5.000000, acc=0.962219, TPR=0.961020, TNR=0.964304, MSE=0.037781\n",
      "Validataion: C=5.000000, acc=0.592500, TPR=0.220600, TNR=0.964400, MSE=0.407500\n",
      "Training: C=10.000000, acc=0.962314, TPR=0.961080, TNR=0.964461, MSE=0.037686\n",
      "Validataion: C=10.000000, acc=0.592700, TPR=0.221700, TNR=0.963700, MSE=0.407300\n",
      "Training: C=50.000000, acc=0.962321, TPR=0.961270, TNR=0.964148, MSE=0.037679\n",
      "Validataion: C=50.000000, acc=0.592700, TPR=0.225500, TNR=0.959900, MSE=0.407300\n",
      "Training: C=100.000000, acc=0.962390, TPR=0.961370, TNR=0.964165, MSE=0.037610\n",
      "Validataion: C=100.000000, acc=0.593500, TPR=0.227500, TNR=0.959500, MSE=0.406500\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.815190, TPR=0.988575, TNR=0.513652, MSE=0.184810\n",
      "Validataion: C=0.005000, acc=0.386700, TPR=0.771600, TNR=0.001800, MSE=0.613300\n",
      "Training: C=0.010000, acc=0.903171, TPR=0.979735, TNR=0.770017, MSE=0.096829\n",
      "Validataion: C=0.010000, acc=0.697550, TPR=0.594800, TNR=0.800300, MSE=0.302450\n",
      "Training: C=0.050000, acc=0.952813, TPR=0.967995, TNR=0.926409, MSE=0.047187\n",
      "Validataion: C=0.050000, acc=0.665100, TPR=0.360000, TNR=0.970200, MSE=0.334900\n",
      "Training: C=0.100000, acc=0.958521, TPR=0.965310, TNR=0.946713, MSE=0.041479\n",
      "Validataion: C=0.100000, acc=0.641850, TPR=0.306300, TNR=0.977400, MSE=0.358150\n",
      "Training: C=0.500000, acc=0.962337, TPR=0.961745, TNR=0.963365, MSE=0.037663\n",
      "Validataion: C=0.500000, acc=0.606800, TPR=0.235000, TNR=0.978600, MSE=0.393200\n",
      "Training: C=1.000000, acc=0.962841, TPR=0.961020, TNR=0.966009, MSE=0.037159\n",
      "Validataion: C=1.000000, acc=0.599150, TPR=0.220500, TNR=0.977800, MSE=0.400850\n",
      "Training: C=5.000000, acc=0.963130, TPR=0.960410, TNR=0.967861, MSE=0.036870\n",
      "Validataion: C=5.000000, acc=0.589250, TPR=0.208300, TNR=0.970200, MSE=0.410750\n",
      "Training: C=10.000000, acc=0.963194, TPR=0.960510, TNR=0.967861, MSE=0.036806\n",
      "Validataion: C=10.000000, acc=0.588900, TPR=0.210300, TNR=0.967500, MSE=0.411100\n",
      "Training: C=50.000000, acc=0.963222, TPR=0.960815, TNR=0.967409, MSE=0.036778\n",
      "Validataion: C=50.000000, acc=0.590450, TPR=0.216300, TNR=0.964600, MSE=0.409550\n",
      "Training: C=100.000000, acc=0.963184, TPR=0.960845, TNR=0.967252, MSE=0.036816\n",
      "Validataion: C=100.000000, acc=0.590300, TPR=0.216900, TNR=0.963700, MSE=0.409700\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.811117, TPR=0.988920, TNR=0.501896, MSE=0.188883\n",
      "Validataion: C=0.005000, acc=0.390150, TPR=0.778500, TNR=0.001800, MSE=0.609850\n",
      "Training: C=0.010000, acc=0.902263, TPR=0.979755, TNR=0.767496, MSE=0.097737\n",
      "Validataion: C=0.010000, acc=0.697600, TPR=0.595200, TNR=0.800000, MSE=0.302400\n",
      "Training: C=0.050000, acc=0.953622, TPR=0.967595, TNR=0.929322, MSE=0.046378\n",
      "Validataion: C=0.050000, acc=0.664550, TPR=0.352000, TNR=0.977100, MSE=0.335450\n",
      "Training: C=0.100000, acc=0.959397, TPR=0.964730, TNR=0.950122, MSE=0.040603\n",
      "Validataion: C=0.100000, acc=0.637950, TPR=0.294700, TNR=0.981200, MSE=0.362050\n",
      "Training: C=0.500000, acc=0.963162, TPR=0.961105, TNR=0.966739, MSE=0.036838\n",
      "Validataion: C=0.500000, acc=0.602550, TPR=0.222200, TNR=0.982900, MSE=0.397450\n",
      "Training: C=1.000000, acc=0.963663, TPR=0.960475, TNR=0.969209, MSE=0.036337\n",
      "Validataion: C=1.000000, acc=0.595750, TPR=0.209600, TNR=0.981900, MSE=0.404250\n",
      "Training: C=5.000000, acc=0.963943, TPR=0.959860, TNR=0.971043, MSE=0.036057\n",
      "Validataion: C=5.000000, acc=0.587250, TPR=0.197300, TNR=0.977200, MSE=0.412750\n",
      "Training: C=10.000000, acc=0.963978, TPR=0.959955, TNR=0.970974, MSE=0.036022\n",
      "Validataion: C=10.000000, acc=0.587200, TPR=0.199100, TNR=0.975300, MSE=0.412800\n",
      "Training: C=50.000000, acc=0.963854, TPR=0.960195, TNR=0.970217, MSE=0.036146\n",
      "Validataion: C=50.000000, acc=0.587350, TPR=0.203900, TNR=0.970800, MSE=0.412650\n",
      "Training: C=100.000000, acc=0.963889, TPR=0.960285, TNR=0.970157, MSE=0.036111\n",
      "Validataion: C=100.000000, acc=0.587750, TPR=0.205700, TNR=0.969800, MSE=0.412250\n",
      "\n",
      "Running # Neg: 110000\n",
      "# total training data: 320000, # Neg: 110000\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.851697, TPR=0.985280, TNR=0.629058, MSE=0.148303\n",
      "Validataion: C=0.005000, acc=0.543400, TPR=0.705700, TNR=0.381100, MSE=0.456600\n",
      "Training: C=0.010000, acc=0.910484, TPR=0.978595, TNR=0.796967, MSE=0.089516\n",
      "Validataion: C=0.010000, acc=0.701450, TPR=0.572100, TNR=0.830800, MSE=0.298550\n",
      "Training: C=0.050000, acc=0.949353, TPR=0.969425, TNR=0.915900, MSE=0.050647\n",
      "Validataion: C=0.050000, acc=0.670450, TPR=0.388600, TNR=0.952300, MSE=0.329550\n",
      "Training: C=0.100000, acc=0.954337, TPR=0.966960, TNR=0.933300, MSE=0.045663\n",
      "Validataion: C=0.100000, acc=0.649050, TPR=0.339300, TNR=0.958800, MSE=0.350950\n",
      "Training: C=0.500000, acc=0.959047, TPR=0.963515, TNR=0.951600, MSE=0.040953\n",
      "Validataion: C=0.500000, acc=0.615950, TPR=0.270600, TNR=0.961300, MSE=0.384050\n",
      "Training: C=1.000000, acc=0.959750, TPR=0.962575, TNR=0.955042, MSE=0.040250\n",
      "Validataion: C=1.000000, acc=0.605950, TPR=0.252000, TNR=0.959900, MSE=0.394050\n",
      "Training: C=5.000000, acc=0.960509, TPR=0.961920, TNR=0.958158, MSE=0.039491\n",
      "Validataion: C=5.000000, acc=0.596750, TPR=0.239000, TNR=0.954500, MSE=0.403250\n",
      "Training: C=10.000000, acc=0.960725, TPR=0.961985, TNR=0.958625, MSE=0.039275\n",
      "Validataion: C=10.000000, acc=0.596450, TPR=0.240100, TNR=0.952800, MSE=0.403550\n",
      "Training: C=50.000000, acc=0.960728, TPR=0.962105, TNR=0.958433, MSE=0.039272\n",
      "Validataion: C=50.000000, acc=0.594850, TPR=0.242400, TNR=0.947300, MSE=0.405150\n",
      "Training: C=100.000000, acc=0.960678, TPR=0.962155, TNR=0.958217, MSE=0.039322\n",
      "Validataion: C=100.000000, acc=0.594700, TPR=0.243400, TNR=0.946000, MSE=0.405300\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.847947, TPR=0.985360, TNR=0.618925, MSE=0.152053\n",
      "Validataion: C=0.005000, acc=0.514250, TPR=0.707300, TNR=0.321200, MSE=0.485750\n",
      "Training: C=0.010000, acc=0.910669, TPR=0.978440, TNR=0.797717, MSE=0.089331\n",
      "Validataion: C=0.010000, acc=0.705200, TPR=0.568900, TNR=0.841500, MSE=0.294800\n",
      "Training: C=0.050000, acc=0.951281, TPR=0.968620, TNR=0.922383, MSE=0.048719\n",
      "Validataion: C=0.050000, acc=0.667400, TPR=0.372500, TNR=0.962300, MSE=0.332600\n",
      "Training: C=0.100000, acc=0.956187, TPR=0.966240, TNR=0.939433, MSE=0.043812\n",
      "Validataion: C=0.100000, acc=0.645650, TPR=0.324900, TNR=0.966400, MSE=0.354350\n",
      "Training: C=0.500000, acc=0.960491, TPR=0.962810, TNR=0.956625, MSE=0.039509\n",
      "Validataion: C=0.500000, acc=0.612050, TPR=0.256400, TNR=0.967700, MSE=0.387950\n",
      "Training: C=1.000000, acc=0.961106, TPR=0.961930, TNR=0.959733, MSE=0.038894\n",
      "Validataion: C=1.000000, acc=0.602450, TPR=0.238800, TNR=0.966100, MSE=0.397550\n",
      "Training: C=5.000000, acc=0.961641, TPR=0.961315, TNR=0.962183, MSE=0.038359\n",
      "Validataion: C=5.000000, acc=0.594450, TPR=0.226700, TNR=0.962200, MSE=0.405550\n",
      "Training: C=10.000000, acc=0.961772, TPR=0.961380, TNR=0.962425, MSE=0.038228\n",
      "Validataion: C=10.000000, acc=0.593700, TPR=0.228000, TNR=0.959400, MSE=0.406300\n",
      "Training: C=50.000000, acc=0.961828, TPR=0.961540, TNR=0.962308, MSE=0.038172\n",
      "Validataion: C=50.000000, acc=0.593300, TPR=0.230900, TNR=0.955700, MSE=0.406700\n",
      "Training: C=100.000000, acc=0.961784, TPR=0.961555, TNR=0.962167, MSE=0.038216\n",
      "Validataion: C=100.000000, acc=0.593100, TPR=0.231200, TNR=0.955000, MSE=0.406900\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.841406, TPR=0.985585, TNR=0.601108, MSE=0.158594\n",
      "Validataion: C=0.005000, acc=0.459250, TPR=0.711800, TNR=0.206700, MSE=0.540750\n",
      "Training: C=0.010000, acc=0.910534, TPR=0.978305, TNR=0.797583, MSE=0.089466\n",
      "Validataion: C=0.010000, acc=0.709150, TPR=0.566200, TNR=0.852100, MSE=0.290850\n",
      "Training: C=0.050000, acc=0.952472, TPR=0.967920, TNR=0.926725, MSE=0.047528\n",
      "Validataion: C=0.050000, acc=0.663000, TPR=0.358500, TNR=0.967500, MSE=0.337000\n",
      "Training: C=0.100000, acc=0.957628, TPR=0.965480, TNR=0.944542, MSE=0.042372\n",
      "Validataion: C=0.100000, acc=0.640950, TPR=0.309700, TNR=0.972200, MSE=0.359050\n",
      "Training: C=0.500000, acc=0.961712, TPR=0.962130, TNR=0.961017, MSE=0.038288\n",
      "Validataion: C=0.500000, acc=0.608200, TPR=0.242800, TNR=0.973600, MSE=0.391800\n",
      "Training: C=1.000000, acc=0.962166, TPR=0.961330, TNR=0.963558, MSE=0.037834\n",
      "Validataion: C=1.000000, acc=0.598750, TPR=0.226800, TNR=0.970700, MSE=0.401250\n",
      "Training: C=5.000000, acc=0.962566, TPR=0.960675, TNR=0.965717, MSE=0.037434\n",
      "Validataion: C=5.000000, acc=0.589300, TPR=0.213800, TNR=0.964800, MSE=0.410700\n",
      "Training: C=10.000000, acc=0.962694, TPR=0.960725, TNR=0.965975, MSE=0.037306\n",
      "Validataion: C=10.000000, acc=0.589550, TPR=0.214800, TNR=0.964300, MSE=0.410450\n",
      "Training: C=50.000000, acc=0.962669, TPR=0.960970, TNR=0.965500, MSE=0.037331\n",
      "Validataion: C=50.000000, acc=0.590100, TPR=0.219500, TNR=0.960700, MSE=0.409900\n",
      "Training: C=100.000000, acc=0.962703, TPR=0.961030, TNR=0.965492, MSE=0.037297\n",
      "Validataion: C=100.000000, acc=0.590550, TPR=0.220700, TNR=0.960400, MSE=0.409450\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.838347, TPR=0.985775, TNR=0.592633, MSE=0.161653\n",
      "Validataion: C=0.005000, acc=0.453750, TPR=0.715600, TNR=0.191900, MSE=0.546250\n",
      "Training: C=0.010000, acc=0.909841, TPR=0.978235, TNR=0.795850, MSE=0.090159\n",
      "Validataion: C=0.010000, acc=0.712450, TPR=0.564800, TNR=0.860100, MSE=0.287550\n",
      "Training: C=0.050000, acc=0.953541, TPR=0.967460, TNR=0.930342, MSE=0.046459\n",
      "Validataion: C=0.050000, acc=0.661900, TPR=0.349300, TNR=0.974500, MSE=0.338100\n",
      "Training: C=0.100000, acc=0.958791, TPR=0.964800, TNR=0.948775, MSE=0.041209\n",
      "Validataion: C=0.100000, acc=0.637300, TPR=0.296100, TNR=0.978500, MSE=0.362700\n",
      "Training: C=0.500000, acc=0.962741, TPR=0.961420, TNR=0.964942, MSE=0.037259\n",
      "Validataion: C=0.500000, acc=0.603900, TPR=0.228500, TNR=0.979300, MSE=0.396100\n",
      "Training: C=1.000000, acc=0.963159, TPR=0.960690, TNR=0.967275, MSE=0.036841\n",
      "Validataion: C=1.000000, acc=0.596000, TPR=0.214000, TNR=0.978000, MSE=0.404000\n",
      "Training: C=5.000000, acc=0.963503, TPR=0.960070, TNR=0.969225, MSE=0.036497\n",
      "Validataion: C=5.000000, acc=0.587100, TPR=0.201600, TNR=0.972600, MSE=0.412900\n",
      "Training: C=10.000000, acc=0.963547, TPR=0.960210, TNR=0.969108, MSE=0.036453\n",
      "Validataion: C=10.000000, acc=0.586600, TPR=0.204300, TNR=0.968900, MSE=0.413400\n",
      "Training: C=50.000000, acc=0.963422, TPR=0.960470, TNR=0.968342, MSE=0.036578\n",
      "Validataion: C=50.000000, acc=0.587450, TPR=0.209500, TNR=0.965400, MSE=0.412550\n",
      "Training: C=100.000000, acc=0.963419, TPR=0.960540, TNR=0.968217, MSE=0.036581\n",
      "Validataion: C=100.000000, acc=0.587950, TPR=0.210900, TNR=0.965000, MSE=0.412050\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.829800, TPR=0.986010, TNR=0.569450, MSE=0.170200\n",
      "Validataion: C=0.005000, acc=0.361150, TPR=0.720300, TNR=0.002000, MSE=0.638850\n",
      "Training: C=0.010000, acc=0.909025, TPR=0.978200, TNR=0.793733, MSE=0.090975\n",
      "Validataion: C=0.010000, acc=0.714700, TPR=0.564100, TNR=0.865300, MSE=0.285300\n",
      "Training: C=0.050000, acc=0.954297, TPR=0.967080, TNR=0.932992, MSE=0.045703\n",
      "Validataion: C=0.050000, acc=0.660250, TPR=0.341700, TNR=0.978800, MSE=0.339750\n",
      "Training: C=0.100000, acc=0.959734, TPR=0.964160, TNR=0.952358, MSE=0.040266\n",
      "Validataion: C=0.100000, acc=0.633300, TPR=0.283300, TNR=0.983300, MSE=0.366700\n",
      "Training: C=0.500000, acc=0.963472, TPR=0.960805, TNR=0.967917, MSE=0.036528\n",
      "Validataion: C=0.500000, acc=0.600250, TPR=0.216200, TNR=0.984300, MSE=0.399750\n",
      "Training: C=1.000000, acc=0.963950, TPR=0.960200, TNR=0.970200, MSE=0.036050\n",
      "Validataion: C=1.000000, acc=0.593400, TPR=0.204100, TNR=0.982700, MSE=0.406600\n",
      "Training: C=5.000000, acc=0.964194, TPR=0.959570, TNR=0.971900, MSE=0.035806\n",
      "Validataion: C=5.000000, acc=0.584600, TPR=0.191500, TNR=0.977700, MSE=0.415400\n",
      "Training: C=10.000000, acc=0.964259, TPR=0.959630, TNR=0.971975, MSE=0.035741\n",
      "Validataion: C=10.000000, acc=0.584600, TPR=0.192600, TNR=0.976600, MSE=0.415400\n",
      "Training: C=50.000000, acc=0.964222, TPR=0.959910, TNR=0.971408, MSE=0.035778\n",
      "Validataion: C=50.000000, acc=0.584750, TPR=0.198200, TNR=0.971300, MSE=0.415250\n",
      "Training: C=100.000000, acc=0.964194, TPR=0.960005, TNR=0.971175, MSE=0.035806\n",
      "Validataion: C=100.000000, acc=0.585250, TPR=0.200100, TNR=0.970400, MSE=0.414750\n",
      "\n",
      "Running # Neg: 115000\n",
      "# total training data: 325000, # Neg: 115000\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.869403, TPR=0.983290, TNR=0.687184, MSE=0.130597\n",
      "Validataion: C=0.005000, acc=0.611800, TPR=0.666000, TNR=0.557600, MSE=0.388200\n",
      "Training: C=0.010000, acc=0.915800, TPR=0.977330, TNR=0.817352, MSE=0.084200\n",
      "Validataion: C=0.010000, acc=0.706800, TPR=0.546900, TNR=0.866700, MSE=0.293200\n",
      "Training: C=0.050000, acc=0.950538, TPR=0.968965, TNR=0.921056, MSE=0.049462\n",
      "Validataion: C=0.050000, acc=0.667650, TPR=0.379400, TNR=0.955900, MSE=0.332350\n",
      "Training: C=0.100000, acc=0.955234, TPR=0.966615, TNR=0.937024, MSE=0.044766\n",
      "Validataion: C=0.100000, acc=0.646950, TPR=0.332400, TNR=0.961500, MSE=0.353050\n",
      "Training: C=0.500000, acc=0.959726, TPR=0.963295, TNR=0.954016, MSE=0.040274\n",
      "Validataion: C=0.500000, acc=0.614800, TPR=0.266300, TNR=0.963300, MSE=0.385200\n",
      "Training: C=1.000000, acc=0.960351, TPR=0.962355, TNR=0.957144, MSE=0.039649\n",
      "Validataion: C=1.000000, acc=0.604250, TPR=0.247600, TNR=0.960900, MSE=0.395750\n",
      "Training: C=5.000000, acc=0.960914, TPR=0.961710, TNR=0.959640, MSE=0.039086\n",
      "Validataion: C=5.000000, acc=0.595150, TPR=0.234800, TNR=0.955500, MSE=0.404850\n",
      "Training: C=10.000000, acc=0.961151, TPR=0.961805, TNR=0.960104, MSE=0.038849\n",
      "Validataion: C=10.000000, acc=0.595050, TPR=0.236500, TNR=0.953600, MSE=0.404950\n",
      "Training: C=50.000000, acc=0.961185, TPR=0.961950, TNR=0.959960, MSE=0.038815\n",
      "Validataion: C=50.000000, acc=0.593600, TPR=0.239300, TNR=0.947900, MSE=0.406400\n",
      "Training: C=100.000000, acc=0.961231, TPR=0.961970, TNR=0.960048, MSE=0.038769\n",
      "Validataion: C=100.000000, acc=0.593700, TPR=0.239700, TNR=0.947700, MSE=0.406300\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.866492, TPR=0.983370, TNR=0.679488, MSE=0.133508\n",
      "Validataion: C=0.005000, acc=0.598050, TPR=0.667500, TNR=0.528600, MSE=0.401950\n",
      "Training: C=0.010000, acc=0.916148, TPR=0.977155, TNR=0.818536, MSE=0.083852\n",
      "Validataion: C=0.010000, acc=0.711750, TPR=0.543300, TNR=0.880200, MSE=0.288250\n",
      "Training: C=0.050000, acc=0.952295, TPR=0.968115, TNR=0.926984, MSE=0.047705\n",
      "Validataion: C=0.050000, acc=0.663700, TPR=0.362400, TNR=0.965000, MSE=0.336300\n",
      "Training: C=0.100000, acc=0.957086, TPR=0.965865, TNR=0.943040, MSE=0.042914\n",
      "Validataion: C=0.100000, acc=0.642650, TPR=0.317400, TNR=0.967900, MSE=0.357350\n",
      "Training: C=0.500000, acc=0.961172, TPR=0.962535, TNR=0.958992, MSE=0.038828\n",
      "Validataion: C=0.500000, acc=0.609700, TPR=0.250900, TNR=0.968500, MSE=0.390300\n",
      "Training: C=1.000000, acc=0.961726, TPR=0.961770, TNR=0.961656, MSE=0.038274\n",
      "Validataion: C=1.000000, acc=0.601350, TPR=0.235700, TNR=0.967000, MSE=0.398650\n",
      "Training: C=5.000000, acc=0.962200, TPR=0.961135, TNR=0.963904, MSE=0.037800\n",
      "Validataion: C=5.000000, acc=0.592950, TPR=0.223100, TNR=0.962800, MSE=0.407050\n",
      "Training: C=10.000000, acc=0.962289, TPR=0.961180, TNR=0.964064, MSE=0.037711\n",
      "Validataion: C=10.000000, acc=0.592500, TPR=0.224000, TNR=0.961000, MSE=0.407500\n",
      "Training: C=50.000000, acc=0.962357, TPR=0.961375, TNR=0.963928, MSE=0.037643\n",
      "Validataion: C=50.000000, acc=0.591750, TPR=0.227600, TNR=0.955900, MSE=0.408250\n",
      "Training: C=100.000000, acc=0.962298, TPR=0.961390, TNR=0.963752, MSE=0.037702\n",
      "Validataion: C=100.000000, acc=0.591650, TPR=0.227900, TNR=0.955400, MSE=0.408350\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.863649, TPR=0.983350, TNR=0.672128, MSE=0.136351\n",
      "Validataion: C=0.005000, acc=0.579400, TPR=0.667100, TNR=0.491700, MSE=0.420600\n",
      "Training: C=0.010000, acc=0.916262, TPR=0.977030, TNR=0.819032, MSE=0.083738\n",
      "Validataion: C=0.010000, acc=0.716500, TPR=0.540800, TNR=0.892200, MSE=0.283500\n",
      "Training: C=0.050000, acc=0.953640, TPR=0.967530, TNR=0.931416, MSE=0.046360\n",
      "Validataion: C=0.050000, acc=0.660450, TPR=0.350700, TNR=0.970200, MSE=0.339550\n",
      "Training: C=0.100000, acc=0.958637, TPR=0.965145, TNR=0.948224, MSE=0.041363\n",
      "Validataion: C=0.100000, acc=0.638950, TPR=0.303000, TNR=0.974900, MSE=0.361050\n",
      "Training: C=0.500000, acc=0.962406, TPR=0.961885, TNR=0.963240, MSE=0.037594\n",
      "Validataion: C=0.500000, acc=0.606450, TPR=0.237900, TNR=0.975000, MSE=0.393550\n",
      "Training: C=1.000000, acc=0.962935, TPR=0.961120, TNR=0.965840, MSE=0.037065\n",
      "Validataion: C=1.000000, acc=0.597700, TPR=0.222600, TNR=0.972800, MSE=0.402300\n",
      "Training: C=5.000000, acc=0.963222, TPR=0.960510, TNR=0.967560, MSE=0.036778\n",
      "Validataion: C=5.000000, acc=0.588550, TPR=0.210500, TNR=0.966600, MSE=0.411450\n",
      "Training: C=10.000000, acc=0.963228, TPR=0.960555, TNR=0.967504, MSE=0.036772\n",
      "Validataion: C=10.000000, acc=0.587950, TPR=0.211400, TNR=0.964500, MSE=0.412050\n",
      "Training: C=50.000000, acc=0.963277, TPR=0.960825, TNR=0.967200, MSE=0.036723\n",
      "Validataion: C=50.000000, acc=0.589150, TPR=0.216600, TNR=0.961700, MSE=0.410850\n",
      "Training: C=100.000000, acc=0.963308, TPR=0.960880, TNR=0.967192, MSE=0.036692\n",
      "Validataion: C=100.000000, acc=0.589500, TPR=0.217700, TNR=0.961300, MSE=0.410500\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.860548, TPR=0.983480, TNR=0.663856, MSE=0.139452\n",
      "Validataion: C=0.005000, acc=0.558700, TPR=0.669700, TNR=0.447700, MSE=0.441300\n",
      "Training: C=0.010000, acc=0.915902, TPR=0.976980, TNR=0.818176, MSE=0.084098\n",
      "Validataion: C=0.010000, acc=0.719550, TPR=0.539700, TNR=0.899400, MSE=0.280450\n",
      "Training: C=0.050000, acc=0.954760, TPR=0.967095, TNR=0.935024, MSE=0.045240\n",
      "Validataion: C=0.050000, acc=0.659700, TPR=0.342000, TNR=0.977400, MSE=0.340300\n",
      "Training: C=0.100000, acc=0.959594, TPR=0.964410, TNR=0.951888, MSE=0.040406\n",
      "Validataion: C=0.100000, acc=0.634050, TPR=0.288300, TNR=0.979800, MSE=0.365950\n",
      "Training: C=0.500000, acc=0.963360, TPR=0.961175, TNR=0.966856, MSE=0.036640\n",
      "Validataion: C=0.500000, acc=0.601850, TPR=0.223700, TNR=0.980000, MSE=0.398150\n",
      "Training: C=1.000000, acc=0.963883, TPR=0.960525, TNR=0.969256, MSE=0.036117\n",
      "Validataion: C=1.000000, acc=0.595050, TPR=0.210700, TNR=0.979400, MSE=0.404950\n",
      "Training: C=5.000000, acc=0.964117, TPR=0.959980, TNR=0.970736, MSE=0.035883\n",
      "Validataion: C=5.000000, acc=0.586450, TPR=0.199800, TNR=0.973100, MSE=0.413550\n",
      "Training: C=10.000000, acc=0.964117, TPR=0.960075, TNR=0.970584, MSE=0.035883\n",
      "Validataion: C=10.000000, acc=0.586100, TPR=0.201700, TNR=0.970500, MSE=0.413900\n",
      "Training: C=50.000000, acc=0.964126, TPR=0.960335, TNR=0.970192, MSE=0.035874\n",
      "Validataion: C=50.000000, acc=0.586750, TPR=0.206800, TNR=0.966700, MSE=0.413250\n",
      "Training: C=100.000000, acc=0.964092, TPR=0.960395, TNR=0.970008, MSE=0.035908\n",
      "Validataion: C=100.000000, acc=0.586800, TPR=0.208000, TNR=0.965600, MSE=0.413200\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.857058, TPR=0.983590, TNR=0.654608, MSE=0.142942\n",
      "Validataion: C=0.005000, acc=0.533100, TPR=0.671900, TNR=0.394300, MSE=0.466900\n",
      "Training: C=0.010000, acc=0.915495, TPR=0.976990, TNR=0.817104, MSE=0.084505\n",
      "Validataion: C=0.010000, acc=0.723100, TPR=0.539900, TNR=0.906300, MSE=0.276900\n",
      "Training: C=0.050000, acc=0.955465, TPR=0.966560, TNR=0.937712, MSE=0.044535\n",
      "Validataion: C=0.050000, acc=0.656500, TPR=0.331300, TNR=0.981700, MSE=0.343500\n",
      "Training: C=0.100000, acc=0.960471, TPR=0.963840, TNR=0.955080, MSE=0.039529\n",
      "Validataion: C=0.100000, acc=0.631100, TPR=0.276900, TNR=0.985300, MSE=0.368900\n",
      "Training: C=0.500000, acc=0.964206, TPR=0.960600, TNR=0.969976, MSE=0.035794\n",
      "Validataion: C=0.500000, acc=0.598550, TPR=0.212100, TNR=0.985000, MSE=0.401450\n",
      "Training: C=1.000000, acc=0.964609, TPR=0.960025, TNR=0.971944, MSE=0.035391\n",
      "Validataion: C=1.000000, acc=0.592150, TPR=0.200600, TNR=0.983700, MSE=0.407850\n",
      "Training: C=5.000000, acc=0.964782, TPR=0.959445, TNR=0.973320, MSE=0.035218\n",
      "Validataion: C=5.000000, acc=0.583650, TPR=0.189000, TNR=0.978300, MSE=0.416350\n",
      "Training: C=10.000000, acc=0.964837, TPR=0.959500, TNR=0.973376, MSE=0.035163\n",
      "Validataion: C=10.000000, acc=0.583550, TPR=0.190000, TNR=0.977100, MSE=0.416450\n",
      "Training: C=50.000000, acc=0.964898, TPR=0.959795, TNR=0.973064, MSE=0.035102\n",
      "Validataion: C=50.000000, acc=0.583750, TPR=0.195900, TNR=0.971600, MSE=0.416250\n",
      "Training: C=100.000000, acc=0.964889, TPR=0.959855, TNR=0.972944, MSE=0.035111\n",
      "Validataion: C=100.000000, acc=0.584150, TPR=0.197100, TNR=0.971200, MSE=0.415850\n",
      "\n",
      "Running # Neg: 120000\n",
      "# total training data: 330000, # Neg: 120000\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.881679, TPR=0.981590, TNR=0.727969, MSE=0.118321\n",
      "Validataion: C=0.005000, acc=0.663550, TPR=0.632300, TNR=0.694800, MSE=0.336450\n",
      "Training: C=0.010000, acc=0.919221, TPR=0.976245, TNR=0.831492, MSE=0.080779\n",
      "Validataion: C=0.010000, acc=0.709600, TPR=0.525500, TNR=0.893700, MSE=0.290400\n",
      "Training: C=0.050000, acc=0.950845, TPR=0.968375, TNR=0.923877, MSE=0.049155\n",
      "Validataion: C=0.050000, acc=0.664050, TPR=0.367700, TNR=0.960400, MSE=0.335950\n",
      "Training: C=0.100000, acc=0.955585, TPR=0.966085, TNR=0.939431, MSE=0.044415\n",
      "Validataion: C=0.100000, acc=0.643600, TPR=0.321900, TNR=0.965300, MSE=0.356400\n",
      "Training: C=0.500000, acc=0.960000, TPR=0.962800, TNR=0.955692, MSE=0.040000\n",
      "Validataion: C=0.500000, acc=0.610450, TPR=0.256500, TNR=0.964400, MSE=0.389550\n",
      "Training: C=1.000000, acc=0.960670, TPR=0.961915, TNR=0.958754, MSE=0.039330\n",
      "Validataion: C=1.000000, acc=0.600800, TPR=0.238900, TNR=0.962700, MSE=0.399200\n",
      "Training: C=5.000000, acc=0.961315, TPR=0.961315, TNR=0.961315, MSE=0.038685\n",
      "Validataion: C=5.000000, acc=0.591900, TPR=0.227000, TNR=0.956800, MSE=0.408100\n",
      "Training: C=10.000000, acc=0.961430, TPR=0.961370, TNR=0.961523, MSE=0.038570\n",
      "Validataion: C=10.000000, acc=0.591400, TPR=0.228000, TNR=0.954800, MSE=0.408600\n",
      "Training: C=50.000000, acc=0.961506, TPR=0.961580, TNR=0.961392, MSE=0.038494\n",
      "Validataion: C=50.000000, acc=0.590650, TPR=0.232000, TNR=0.949300, MSE=0.409350\n",
      "Training: C=100.000000, acc=0.961533, TPR=0.961605, TNR=0.961423, MSE=0.038467\n",
      "Validataion: C=100.000000, acc=0.590750, TPR=0.232500, TNR=0.949000, MSE=0.409250\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.880127, TPR=0.981585, TNR=0.724038, MSE=0.119873\n",
      "Validataion: C=0.005000, acc=0.660150, TPR=0.631900, TNR=0.688400, MSE=0.339850\n",
      "Training: C=0.010000, acc=0.919955, TPR=0.976045, TNR=0.833662, MSE=0.080045\n",
      "Validataion: C=0.010000, acc=0.713750, TPR=0.521300, TNR=0.906200, MSE=0.286250\n",
      "Training: C=0.050000, acc=0.952676, TPR=0.967580, TNR=0.929746, MSE=0.047324\n",
      "Validataion: C=0.050000, acc=0.659750, TPR=0.351700, TNR=0.967800, MSE=0.340250\n",
      "Training: C=0.100000, acc=0.957288, TPR=0.965350, TNR=0.944885, MSE=0.042712\n",
      "Validataion: C=0.100000, acc=0.638500, TPR=0.307100, TNR=0.969900, MSE=0.361500\n",
      "Training: C=0.500000, acc=0.961321, TPR=0.962120, TNR=0.960092, MSE=0.038679\n",
      "Validataion: C=0.500000, acc=0.606100, TPR=0.242700, TNR=0.969500, MSE=0.393900\n",
      "Training: C=1.000000, acc=0.961870, TPR=0.961325, TNR=0.962708, MSE=0.038130\n",
      "Validataion: C=1.000000, acc=0.597750, TPR=0.227000, TNR=0.968500, MSE=0.402250\n",
      "Training: C=5.000000, acc=0.962379, TPR=0.960730, TNR=0.964915, MSE=0.037621\n",
      "Validataion: C=5.000000, acc=0.589300, TPR=0.215100, TNR=0.963500, MSE=0.410700\n",
      "Training: C=10.000000, acc=0.962533, TPR=0.960785, TNR=0.965223, MSE=0.037467\n",
      "Validataion: C=10.000000, acc=0.589050, TPR=0.216200, TNR=0.961900, MSE=0.410950\n",
      "Training: C=50.000000, acc=0.962548, TPR=0.961025, TNR=0.964892, MSE=0.037452\n",
      "Validataion: C=50.000000, acc=0.589300, TPR=0.220800, TNR=0.957800, MSE=0.410700\n",
      "Training: C=100.000000, acc=0.962464, TPR=0.961075, TNR=0.964600, MSE=0.037536\n",
      "Validataion: C=100.000000, acc=0.589150, TPR=0.221700, TNR=0.956600, MSE=0.410850\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.878373, TPR=0.981600, TNR=0.719562, MSE=0.121627\n",
      "Validataion: C=0.005000, acc=0.655000, TPR=0.632300, TNR=0.677700, MSE=0.345000\n",
      "Training: C=0.010000, acc=0.920164, TPR=0.975940, TNR=0.834354, MSE=0.079836\n",
      "Validataion: C=0.010000, acc=0.718250, TPR=0.519000, TNR=0.917500, MSE=0.281750\n",
      "Training: C=0.050000, acc=0.954185, TPR=0.967090, TNR=0.934331, MSE=0.045815\n",
      "Validataion: C=0.050000, acc=0.657850, TPR=0.341900, TNR=0.973800, MSE=0.342150\n",
      "Training: C=0.100000, acc=0.958712, TPR=0.964545, TNR=0.949738, MSE=0.041288\n",
      "Validataion: C=0.100000, acc=0.634200, TPR=0.291000, TNR=0.977400, MSE=0.365800\n",
      "Training: C=0.500000, acc=0.962567, TPR=0.961460, TNR=0.964269, MSE=0.037433\n",
      "Validataion: C=0.500000, acc=0.603100, TPR=0.229500, TNR=0.976700, MSE=0.396900\n",
      "Training: C=1.000000, acc=0.962924, TPR=0.960625, TNR=0.966462, MSE=0.037076\n",
      "Validataion: C=1.000000, acc=0.593600, TPR=0.212800, TNR=0.974400, MSE=0.406400\n",
      "Training: C=5.000000, acc=0.963227, TPR=0.960190, TNR=0.967900, MSE=0.036773\n",
      "Validataion: C=5.000000, acc=0.585850, TPR=0.204200, TNR=0.967500, MSE=0.414150\n",
      "Training: C=10.000000, acc=0.963303, TPR=0.960235, TNR=0.968023, MSE=0.036697\n",
      "Validataion: C=10.000000, acc=0.585000, TPR=0.205100, TNR=0.964900, MSE=0.415000\n",
      "Training: C=50.000000, acc=0.963385, TPR=0.960490, TNR=0.967838, MSE=0.036615\n",
      "Validataion: C=50.000000, acc=0.586400, TPR=0.209900, TNR=0.962900, MSE=0.413600\n",
      "Training: C=100.000000, acc=0.963364, TPR=0.960525, TNR=0.967731, MSE=0.036636\n",
      "Validataion: C=100.000000, acc=0.586300, TPR=0.210600, TNR=0.962000, MSE=0.413700\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.876585, TPR=0.981660, TNR=0.714931, MSE=0.123415\n",
      "Validataion: C=0.005000, acc=0.647050, TPR=0.633400, TNR=0.660700, MSE=0.352950\n",
      "Training: C=0.010000, acc=0.920282, TPR=0.975870, TNR=0.834762, MSE=0.079718\n",
      "Validataion: C=0.010000, acc=0.723100, TPR=0.517600, TNR=0.928600, MSE=0.276900\n",
      "Training: C=0.050000, acc=0.955191, TPR=0.966475, TNR=0.937831, MSE=0.044809\n",
      "Validataion: C=0.050000, acc=0.654100, TPR=0.329600, TNR=0.978600, MSE=0.345900\n",
      "Training: C=0.100000, acc=0.959776, TPR=0.963895, TNR=0.953438, MSE=0.040224\n",
      "Validataion: C=0.100000, acc=0.629700, TPR=0.278000, TNR=0.981400, MSE=0.370300\n",
      "Training: C=0.500000, acc=0.963488, TPR=0.960850, TNR=0.967546, MSE=0.036512\n",
      "Validataion: C=0.500000, acc=0.598850, TPR=0.217200, TNR=0.980500, MSE=0.401150\n",
      "Training: C=1.000000, acc=0.963882, TPR=0.960080, TNR=0.969731, MSE=0.036118\n",
      "Validataion: C=1.000000, acc=0.590800, TPR=0.201800, TNR=0.979800, MSE=0.409200\n",
      "Training: C=5.000000, acc=0.964127, TPR=0.959600, TNR=0.971092, MSE=0.035873\n",
      "Validataion: C=5.000000, acc=0.583250, TPR=0.192200, TNR=0.974300, MSE=0.416750\n",
      "Training: C=10.000000, acc=0.964161, TPR=0.959670, TNR=0.971069, MSE=0.035839\n",
      "Validataion: C=10.000000, acc=0.582950, TPR=0.193700, TNR=0.972200, MSE=0.417050\n",
      "Training: C=50.000000, acc=0.964191, TPR=0.959955, TNR=0.970708, MSE=0.035809\n",
      "Validataion: C=50.000000, acc=0.583200, TPR=0.199200, TNR=0.967200, MSE=0.416800\n",
      "Training: C=100.000000, acc=0.964227, TPR=0.960070, TNR=0.970623, MSE=0.035773\n",
      "Validataion: C=100.000000, acc=0.584050, TPR=0.201500, TNR=0.966600, MSE=0.415950\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.874339, TPR=0.981725, TNR=0.709131, MSE=0.125661\n",
      "Validataion: C=0.005000, acc=0.637350, TPR=0.634600, TNR=0.640100, MSE=0.362650\n",
      "Training: C=0.010000, acc=0.920027, TPR=0.975815, TNR=0.834200, MSE=0.079973\n",
      "Validataion: C=0.010000, acc=0.726650, TPR=0.516500, TNR=0.936800, MSE=0.273350\n",
      "Training: C=0.050000, acc=0.956055, TPR=0.966025, TNR=0.940715, MSE=0.043945\n",
      "Validataion: C=0.050000, acc=0.652450, TPR=0.320600, TNR=0.984300, MSE=0.347550\n",
      "Training: C=0.100000, acc=0.960709, TPR=0.963405, TNR=0.956562, MSE=0.039291\n",
      "Validataion: C=0.100000, acc=0.627250, TPR=0.268200, TNR=0.986300, MSE=0.372750\n",
      "Training: C=0.500000, acc=0.964261, TPR=0.960290, TNR=0.970369, MSE=0.035739\n",
      "Validataion: C=0.500000, acc=0.595950, TPR=0.205900, TNR=0.986000, MSE=0.404050\n",
      "Training: C=1.000000, acc=0.964685, TPR=0.959670, TNR=0.972400, MSE=0.035315\n",
      "Validataion: C=1.000000, acc=0.588850, TPR=0.193600, TNR=0.984100, MSE=0.411150\n",
      "Training: C=5.000000, acc=0.964939, TPR=0.959145, TNR=0.973854, MSE=0.035061\n",
      "Validataion: C=5.000000, acc=0.581150, TPR=0.183100, TNR=0.979200, MSE=0.418850\n",
      "Training: C=10.000000, acc=0.964967, TPR=0.959175, TNR=0.973877, MSE=0.035033\n",
      "Validataion: C=10.000000, acc=0.580500, TPR=0.183700, TNR=0.977300, MSE=0.419500\n",
      "Training: C=50.000000, acc=0.964988, TPR=0.959525, TNR=0.973392, MSE=0.035012\n",
      "Validataion: C=50.000000, acc=0.581500, TPR=0.190600, TNR=0.972400, MSE=0.418500\n",
      "Training: C=100.000000, acc=0.964958, TPR=0.959580, TNR=0.973231, MSE=0.035042\n",
      "Validataion: C=100.000000, acc=0.581900, TPR=0.191700, TNR=0.972100, MSE=0.418100\n",
      "\n",
      "Running # Neg: 125000\n",
      "# total training data: 335000, # Neg: 125000\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.891857, TPR=0.980080, TNR=0.761156, MSE=0.108143\n",
      "Validataion: C=0.005000, acc=0.692350, TPR=0.603200, TNR=0.781500, MSE=0.307650\n",
      "Training: C=0.010000, acc=0.922958, TPR=0.975350, TNR=0.845341, MSE=0.077042\n",
      "Validataion: C=0.010000, acc=0.710600, TPR=0.508000, TNR=0.913200, MSE=0.289400\n",
      "Training: C=0.050000, acc=0.951564, TPR=0.967870, TNR=0.927407, MSE=0.048436\n",
      "Validataion: C=0.050000, acc=0.660750, TPR=0.357600, TNR=0.963900, MSE=0.339250\n",
      "Training: C=0.100000, acc=0.955970, TPR=0.965700, TNR=0.941556, MSE=0.044030\n",
      "Validataion: C=0.100000, acc=0.640300, TPR=0.314200, TNR=0.966400, MSE=0.359700\n",
      "Training: C=0.500000, acc=0.960185, TPR=0.962420, TNR=0.956874, MSE=0.039815\n",
      "Validataion: C=0.500000, acc=0.607100, TPR=0.248900, TNR=0.965300, MSE=0.392900\n",
      "Training: C=1.000000, acc=0.960854, TPR=0.961620, TNR=0.959719, MSE=0.039146\n",
      "Validataion: C=1.000000, acc=0.598350, TPR=0.233100, TNR=0.963600, MSE=0.401650\n",
      "Training: C=5.000000, acc=0.961469, TPR=0.961050, TNR=0.962089, MSE=0.038531\n",
      "Validataion: C=5.000000, acc=0.589800, TPR=0.221700, TNR=0.957900, MSE=0.410200\n",
      "Training: C=10.000000, acc=0.961564, TPR=0.961090, TNR=0.962267, MSE=0.038436\n",
      "Validataion: C=10.000000, acc=0.589000, TPR=0.222400, TNR=0.955600, MSE=0.411000\n",
      "Training: C=50.000000, acc=0.961669, TPR=0.961265, TNR=0.962267, MSE=0.038331\n",
      "Validataion: C=50.000000, acc=0.588850, TPR=0.225800, TNR=0.951900, MSE=0.411150\n",
      "Training: C=100.000000, acc=0.961657, TPR=0.961325, TNR=0.962148, MSE=0.038343\n",
      "Validataion: C=100.000000, acc=0.588450, TPR=0.227000, TNR=0.949900, MSE=0.411550\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.891284, TPR=0.979940, TNR=0.759941, MSE=0.108716\n",
      "Validataion: C=0.005000, acc=0.695050, TPR=0.600200, TNR=0.789900, MSE=0.304950\n",
      "Training: C=0.010000, acc=0.923773, TPR=0.975060, TNR=0.847793, MSE=0.076227\n",
      "Validataion: C=0.010000, acc=0.715150, TPR=0.502100, TNR=0.928200, MSE=0.284850\n",
      "Training: C=0.050000, acc=0.953382, TPR=0.967210, TNR=0.932896, MSE=0.046618\n",
      "Validataion: C=0.050000, acc=0.656950, TPR=0.344300, TNR=0.969600, MSE=0.343050\n",
      "Training: C=0.100000, acc=0.957785, TPR=0.964980, TNR=0.947126, MSE=0.042215\n",
      "Validataion: C=0.100000, acc=0.635750, TPR=0.299700, TNR=0.971800, MSE=0.364250\n",
      "Training: C=0.500000, acc=0.961585, TPR=0.961840, TNR=0.961207, MSE=0.038415\n",
      "Validataion: C=0.500000, acc=0.604100, TPR=0.237200, TNR=0.971000, MSE=0.395900\n",
      "Training: C=1.000000, acc=0.962081, TPR=0.961010, TNR=0.963667, MSE=0.037919\n",
      "Validataion: C=1.000000, acc=0.594650, TPR=0.220800, TNR=0.968500, MSE=0.405350\n",
      "Training: C=5.000000, acc=0.962540, TPR=0.960450, TNR=0.965637, MSE=0.037460\n",
      "Validataion: C=5.000000, acc=0.586850, TPR=0.209600, TNR=0.964100, MSE=0.413150\n",
      "Training: C=10.000000, acc=0.962719, TPR=0.960550, TNR=0.965933, MSE=0.037281\n",
      "Validataion: C=10.000000, acc=0.587000, TPR=0.211500, TNR=0.962500, MSE=0.413000\n",
      "Training: C=50.000000, acc=0.962788, TPR=0.960760, TNR=0.965793, MSE=0.037212\n",
      "Validataion: C=50.000000, acc=0.586800, TPR=0.215500, TNR=0.958100, MSE=0.413200\n",
      "Training: C=100.000000, acc=0.962785, TPR=0.960805, TNR=0.965719, MSE=0.037215\n",
      "Validataion: C=100.000000, acc=0.587000, TPR=0.216400, TNR=0.957600, MSE=0.413000\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.890304, TPR=0.979915, TNR=0.757548, MSE=0.109696\n",
      "Validataion: C=0.005000, acc=0.695600, TPR=0.599500, TNR=0.791700, MSE=0.304400\n",
      "Training: C=0.010000, acc=0.924122, TPR=0.974800, TNR=0.849044, MSE=0.075878\n",
      "Validataion: C=0.010000, acc=0.718850, TPR=0.496800, TNR=0.940900, MSE=0.281150\n",
      "Training: C=0.050000, acc=0.954818, TPR=0.966620, TNR=0.937333, MSE=0.045182\n",
      "Validataion: C=0.050000, acc=0.654800, TPR=0.332500, TNR=0.977100, MSE=0.345200\n",
      "Training: C=0.100000, acc=0.959072, TPR=0.964165, TNR=0.951526, MSE=0.040928\n",
      "Validataion: C=0.100000, acc=0.631000, TPR=0.283400, TNR=0.978600, MSE=0.369000\n",
      "Training: C=0.500000, acc=0.962737, TPR=0.961160, TNR=0.965074, MSE=0.037263\n",
      "Validataion: C=0.500000, acc=0.600800, TPR=0.223500, TNR=0.978100, MSE=0.399200\n",
      "Training: C=1.000000, acc=0.963113, TPR=0.960385, TNR=0.967156, MSE=0.036887\n",
      "Validataion: C=1.000000, acc=0.591800, TPR=0.208100, TNR=0.975500, MSE=0.408200\n",
      "Training: C=5.000000, acc=0.963439, TPR=0.959920, TNR=0.968652, MSE=0.036561\n",
      "Validataion: C=5.000000, acc=0.583750, TPR=0.198900, TNR=0.968600, MSE=0.416250\n",
      "Training: C=10.000000, acc=0.963558, TPR=0.959985, TNR=0.968852, MSE=0.036442\n",
      "Validataion: C=10.000000, acc=0.582850, TPR=0.200100, TNR=0.965600, MSE=0.417150\n",
      "Training: C=50.000000, acc=0.963699, TPR=0.960265, TNR=0.968785, MSE=0.036301\n",
      "Validataion: C=50.000000, acc=0.584550, TPR=0.205500, TNR=0.963600, MSE=0.415450\n",
      "Training: C=100.000000, acc=0.963770, TPR=0.960355, TNR=0.968830, MSE=0.036230\n",
      "Validataion: C=100.000000, acc=0.584950, TPR=0.207300, TNR=0.962600, MSE=0.415050\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.888988, TPR=0.979940, TNR=0.754244, MSE=0.111012\n",
      "Validataion: C=0.005000, acc=0.695700, TPR=0.600000, TNR=0.791400, MSE=0.304300\n",
      "Training: C=0.010000, acc=0.924125, TPR=0.974745, TNR=0.849133, MSE=0.075875\n",
      "Validataion: C=0.010000, acc=0.722250, TPR=0.495600, TNR=0.948900, MSE=0.277750\n",
      "Training: C=0.050000, acc=0.955863, TPR=0.966075, TNR=0.940733, MSE=0.044137\n",
      "Validataion: C=0.050000, acc=0.651500, TPR=0.321600, TNR=0.981400, MSE=0.348500\n",
      "Training: C=0.100000, acc=0.960137, TPR=0.963550, TNR=0.955081, MSE=0.039863\n",
      "Validataion: C=0.100000, acc=0.626600, TPR=0.271100, TNR=0.982100, MSE=0.373400\n",
      "Training: C=0.500000, acc=0.963654, TPR=0.960565, TNR=0.968230, MSE=0.036346\n",
      "Validataion: C=0.500000, acc=0.596450, TPR=0.211600, TNR=0.981300, MSE=0.403550\n",
      "Training: C=1.000000, acc=0.964143, TPR=0.959865, TNR=0.970481, MSE=0.035857\n",
      "Validataion: C=1.000000, acc=0.588900, TPR=0.197600, TNR=0.980200, MSE=0.411100\n",
      "Training: C=5.000000, acc=0.964442, TPR=0.959405, TNR=0.971904, MSE=0.035558\n",
      "Validataion: C=5.000000, acc=0.582100, TPR=0.188500, TNR=0.975700, MSE=0.417900\n",
      "Training: C=10.000000, acc=0.964534, TPR=0.959475, TNR=0.972030, MSE=0.035466\n",
      "Validataion: C=10.000000, acc=0.581450, TPR=0.189800, TNR=0.973100, MSE=0.418550\n",
      "Training: C=50.000000, acc=0.964666, TPR=0.959765, TNR=0.971926, MSE=0.035334\n",
      "Validataion: C=50.000000, acc=0.581950, TPR=0.195400, TNR=0.968500, MSE=0.418050\n",
      "Training: C=100.000000, acc=0.964663, TPR=0.959860, TNR=0.971778, MSE=0.035337\n",
      "Validataion: C=100.000000, acc=0.582350, TPR=0.197300, TNR=0.967400, MSE=0.417650\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.887845, TPR=0.980040, TNR=0.751259, MSE=0.112155\n",
      "Validataion: C=0.005000, acc=0.695750, TPR=0.601700, TNR=0.789800, MSE=0.304250\n",
      "Training: C=0.010000, acc=0.923967, TPR=0.974665, TNR=0.848859, MSE=0.076033\n",
      "Validataion: C=0.010000, acc=0.725200, TPR=0.493900, TNR=0.956500, MSE=0.274800\n",
      "Training: C=0.050000, acc=0.956666, TPR=0.965620, TNR=0.943400, MSE=0.043334\n",
      "Validataion: C=0.050000, acc=0.649400, TPR=0.312500, TNR=0.986300, MSE=0.350600\n",
      "Training: C=0.100000, acc=0.961200, TPR=0.963075, TNR=0.958422, MSE=0.038800\n",
      "Validataion: C=0.100000, acc=0.624450, TPR=0.261600, TNR=0.987300, MSE=0.375550\n",
      "Training: C=0.500000, acc=0.964654, TPR=0.960125, TNR=0.971363, MSE=0.035346\n",
      "Validataion: C=0.500000, acc=0.594600, TPR=0.202700, TNR=0.986500, MSE=0.405400\n",
      "Training: C=1.000000, acc=0.965066, TPR=0.959445, TNR=0.973393, MSE=0.034934\n",
      "Validataion: C=1.000000, acc=0.586950, TPR=0.189100, TNR=0.984800, MSE=0.413050\n",
      "Training: C=5.000000, acc=0.965361, TPR=0.958910, TNR=0.974919, MSE=0.034639\n",
      "Validataion: C=5.000000, acc=0.579100, TPR=0.178400, TNR=0.979800, MSE=0.420900\n",
      "Training: C=10.000000, acc=0.965349, TPR=0.958960, TNR=0.974815, MSE=0.034651\n",
      "Validataion: C=10.000000, acc=0.578650, TPR=0.179500, TNR=0.977800, MSE=0.421350\n",
      "Training: C=50.000000, acc=0.965394, TPR=0.959330, TNR=0.974378, MSE=0.034606\n",
      "Validataion: C=50.000000, acc=0.580000, TPR=0.186700, TNR=0.973300, MSE=0.420000\n",
      "Training: C=100.000000, acc=0.965355, TPR=0.959370, TNR=0.974222, MSE=0.034645\n",
      "Validataion: C=100.000000, acc=0.580100, TPR=0.187500, TNR=0.972700, MSE=0.419900\n",
      "\n",
      "Running # Neg: 130000\n",
      "# total training data: 340000, # Neg: 130000\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.899156, TPR=0.978540, TNR=0.785750, MSE=0.100844\n",
      "Validataion: C=0.005000, acc=0.707950, TPR=0.574600, TNR=0.841300, MSE=0.292050\n",
      "Training: C=0.010000, acc=0.925538, TPR=0.974470, TNR=0.855636, MSE=0.074462\n",
      "Validataion: C=0.010000, acc=0.711850, TPR=0.491100, TNR=0.932600, MSE=0.288150\n",
      "Training: C=0.050000, acc=0.952200, TPR=0.967315, TNR=0.930607, MSE=0.047800\n",
      "Validataion: C=0.050000, acc=0.656750, TPR=0.346600, TNR=0.966900, MSE=0.343250\n",
      "Training: C=0.100000, acc=0.956259, TPR=0.965205, TNR=0.943479, MSE=0.043741\n",
      "Validataion: C=0.100000, acc=0.636000, TPR=0.304400, TNR=0.967600, MSE=0.364000\n",
      "Training: C=0.500000, acc=0.960600, TPR=0.961915, TNR=0.958721, MSE=0.039400\n",
      "Validataion: C=0.500000, acc=0.602700, TPR=0.238900, TNR=0.966500, MSE=0.397300\n",
      "Training: C=1.000000, acc=0.961241, TPR=0.961150, TNR=0.961371, MSE=0.038759\n",
      "Validataion: C=1.000000, acc=0.594250, TPR=0.223900, TNR=0.964600, MSE=0.405750\n",
      "Training: C=5.000000, acc=0.962050, TPR=0.960665, TNR=0.964029, MSE=0.037950\n",
      "Validataion: C=5.000000, acc=0.586250, TPR=0.214300, TNR=0.958200, MSE=0.413750\n",
      "Training: C=10.000000, acc=0.962282, TPR=0.960770, TNR=0.964443, MSE=0.037718\n",
      "Validataion: C=10.000000, acc=0.586150, TPR=0.216200, TNR=0.956100, MSE=0.413850\n",
      "Training: C=50.000000, acc=0.962426, TPR=0.960965, TNR=0.964514, MSE=0.037574\n",
      "Validataion: C=50.000000, acc=0.586900, TPR=0.220000, TNR=0.953800, MSE=0.413100\n",
      "Training: C=100.000000, acc=0.962374, TPR=0.961040, TNR=0.964279, MSE=0.037626\n",
      "Validataion: C=100.000000, acc=0.586150, TPR=0.221400, TNR=0.950900, MSE=0.413850\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.898924, TPR=0.978455, TNR=0.785307, MSE=0.101076\n",
      "Validataion: C=0.005000, acc=0.713400, TPR=0.572700, TNR=0.854100, MSE=0.286600\n",
      "Training: C=0.010000, acc=0.926494, TPR=0.974130, TNR=0.858443, MSE=0.073506\n",
      "Validataion: C=0.010000, acc=0.715350, TPR=0.484300, TNR=0.946400, MSE=0.284650\n",
      "Training: C=0.050000, acc=0.953988, TPR=0.966755, TNR=0.935750, MSE=0.046012\n",
      "Validataion: C=0.050000, acc=0.653700, TPR=0.335200, TNR=0.972200, MSE=0.346300\n",
      "Training: C=0.100000, acc=0.958074, TPR=0.964445, TNR=0.948971, MSE=0.041926\n",
      "Validataion: C=0.100000, acc=0.631150, TPR=0.289100, TNR=0.973200, MSE=0.368850\n",
      "Training: C=0.500000, acc=0.961947, TPR=0.961360, TNR=0.962786, MSE=0.038053\n",
      "Validataion: C=0.500000, acc=0.599700, TPR=0.227700, TNR=0.971700, MSE=0.400300\n",
      "Training: C=1.000000, acc=0.962438, TPR=0.960655, TNR=0.964986, MSE=0.037562\n",
      "Validataion: C=1.000000, acc=0.591500, TPR=0.213700, TNR=0.969300, MSE=0.408500\n",
      "Training: C=5.000000, acc=0.963088, TPR=0.960065, TNR=0.967407, MSE=0.036912\n",
      "Validataion: C=5.000000, acc=0.583000, TPR=0.201900, TNR=0.964100, MSE=0.417000\n",
      "Training: C=10.000000, acc=0.963297, TPR=0.960240, TNR=0.967664, MSE=0.036703\n",
      "Validataion: C=10.000000, acc=0.583950, TPR=0.205300, TNR=0.962600, MSE=0.416050\n",
      "Training: C=50.000000, acc=0.963312, TPR=0.960460, TNR=0.967386, MSE=0.036688\n",
      "Validataion: C=50.000000, acc=0.584150, TPR=0.209500, TNR=0.958800, MSE=0.415850\n",
      "Training: C=100.000000, acc=0.963309, TPR=0.960500, TNR=0.967321, MSE=0.036691\n",
      "Validataion: C=100.000000, acc=0.584350, TPR=0.210300, TNR=0.958400, MSE=0.415650\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.898106, TPR=0.978385, TNR=0.783421, MSE=0.101894\n",
      "Validataion: C=0.005000, acc=0.718350, TPR=0.571000, TNR=0.865700, MSE=0.281650\n",
      "Training: C=0.010000, acc=0.926853, TPR=0.973860, TNR=0.859700, MSE=0.073147\n",
      "Validataion: C=0.010000, acc=0.717300, TPR=0.478600, TNR=0.956000, MSE=0.282700\n",
      "Training: C=0.050000, acc=0.955465, TPR=0.966090, TNR=0.940286, MSE=0.044535\n",
      "Validataion: C=0.050000, acc=0.650250, TPR=0.321900, TNR=0.978600, MSE=0.349750\n",
      "Training: C=0.100000, acc=0.959371, TPR=0.963705, TNR=0.953179, MSE=0.040629\n",
      "Validataion: C=0.100000, acc=0.626700, TPR=0.274200, TNR=0.979200, MSE=0.373300\n",
      "Training: C=0.500000, acc=0.963159, TPR=0.960775, TNR=0.966564, MSE=0.036841\n",
      "Validataion: C=0.500000, acc=0.597300, TPR=0.215800, TNR=0.978800, MSE=0.402700\n",
      "Training: C=1.000000, acc=0.963668, TPR=0.960030, TNR=0.968864, MSE=0.036332\n",
      "Validataion: C=1.000000, acc=0.588950, TPR=0.201100, TNR=0.976800, MSE=0.411050\n",
      "Training: C=5.000000, acc=0.963944, TPR=0.959585, TNR=0.970171, MSE=0.036056\n",
      "Validataion: C=5.000000, acc=0.580500, TPR=0.192200, TNR=0.968800, MSE=0.419500\n",
      "Training: C=10.000000, acc=0.964106, TPR=0.959735, TNR=0.970350, MSE=0.035894\n",
      "Validataion: C=10.000000, acc=0.580950, TPR=0.195200, TNR=0.966700, MSE=0.419050\n",
      "Training: C=50.000000, acc=0.964147, TPR=0.959995, TNR=0.970079, MSE=0.035853\n",
      "Validataion: C=50.000000, acc=0.582000, TPR=0.200100, TNR=0.963900, MSE=0.418000\n",
      "Training: C=100.000000, acc=0.964150, TPR=0.960080, TNR=0.969964, MSE=0.035850\n",
      "Validataion: C=100.000000, acc=0.582250, TPR=0.201800, TNR=0.962700, MSE=0.417750\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.897288, TPR=0.978370, TNR=0.781457, MSE=0.102712\n",
      "Validataion: C=0.005000, acc=0.720850, TPR=0.570500, TNR=0.871200, MSE=0.279150\n",
      "Training: C=0.010000, acc=0.927053, TPR=0.973710, TNR=0.860400, MSE=0.072947\n",
      "Validataion: C=0.010000, acc=0.719450, TPR=0.475500, TNR=0.963400, MSE=0.280550\n",
      "Training: C=0.050000, acc=0.956462, TPR=0.965525, TNR=0.943514, MSE=0.043538\n",
      "Validataion: C=0.050000, acc=0.646550, TPR=0.310600, TNR=0.982500, MSE=0.353450\n",
      "Training: C=0.100000, acc=0.960618, TPR=0.963170, TNR=0.956971, MSE=0.039382\n",
      "Validataion: C=0.100000, acc=0.624250, TPR=0.263500, TNR=0.985000, MSE=0.375750\n",
      "Training: C=0.500000, acc=0.964088, TPR=0.960210, TNR=0.969629, MSE=0.035912\n",
      "Validataion: C=0.500000, acc=0.593400, TPR=0.204500, TNR=0.982300, MSE=0.406600\n",
      "Training: C=1.000000, acc=0.964485, TPR=0.959530, TNR=0.971564, MSE=0.035515\n",
      "Validataion: C=1.000000, acc=0.585850, TPR=0.191000, TNR=0.980700, MSE=0.414150\n",
      "Training: C=5.000000, acc=0.964882, TPR=0.959085, TNR=0.973164, MSE=0.035118\n",
      "Validataion: C=5.000000, acc=0.579500, TPR=0.182200, TNR=0.976800, MSE=0.420500\n",
      "Training: C=10.000000, acc=0.964900, TPR=0.959155, TNR=0.973107, MSE=0.035100\n",
      "Validataion: C=10.000000, acc=0.578500, TPR=0.183500, TNR=0.973500, MSE=0.421500\n",
      "Training: C=50.000000, acc=0.964935, TPR=0.959480, TNR=0.972729, MSE=0.035065\n",
      "Validataion: C=50.000000, acc=0.579950, TPR=0.189800, TNR=0.970100, MSE=0.420050\n",
      "Training: C=100.000000, acc=0.964944, TPR=0.959525, TNR=0.972686, MSE=0.035056\n",
      "Validataion: C=100.000000, acc=0.579950, TPR=0.190700, TNR=0.969200, MSE=0.420050\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.896565, TPR=0.978435, TNR=0.779607, MSE=0.103435\n",
      "Validataion: C=0.005000, acc=0.724750, TPR=0.571700, TNR=0.877800, MSE=0.275250\n",
      "Training: C=0.010000, acc=0.926935, TPR=0.973610, TNR=0.860257, MSE=0.073065\n",
      "Validataion: C=0.010000, acc=0.721150, TPR=0.473500, TNR=0.968800, MSE=0.278850\n",
      "Training: C=0.050000, acc=0.957247, TPR=0.965080, TNR=0.946057, MSE=0.042753\n",
      "Validataion: C=0.050000, acc=0.644750, TPR=0.301700, TNR=0.987800, MSE=0.355250\n",
      "Training: C=0.100000, acc=0.961568, TPR=0.962640, TNR=0.960036, MSE=0.038432\n",
      "Validataion: C=0.100000, acc=0.620950, TPR=0.252900, TNR=0.989000, MSE=0.379050\n",
      "Training: C=0.500000, acc=0.964976, TPR=0.959740, TNR=0.972457, MSE=0.035024\n",
      "Validataion: C=0.500000, acc=0.591000, TPR=0.195100, TNR=0.986900, MSE=0.409000\n",
      "Training: C=1.000000, acc=0.965362, TPR=0.959120, TNR=0.974279, MSE=0.034638\n",
      "Validataion: C=1.000000, acc=0.584050, TPR=0.182700, TNR=0.985400, MSE=0.415950\n",
      "Training: C=5.000000, acc=0.965671, TPR=0.958615, TNR=0.975750, MSE=0.034329\n",
      "Validataion: C=5.000000, acc=0.576500, TPR=0.172600, TNR=0.980400, MSE=0.423500\n",
      "Training: C=10.000000, acc=0.965679, TPR=0.958675, TNR=0.975686, MSE=0.034321\n",
      "Validataion: C=10.000000, acc=0.576050, TPR=0.173800, TNR=0.978300, MSE=0.423950\n",
      "Training: C=50.000000, acc=0.965659, TPR=0.959015, TNR=0.975150, MSE=0.034341\n",
      "Validataion: C=50.000000, acc=0.577350, TPR=0.180400, TNR=0.974300, MSE=0.422650\n",
      "Training: C=100.000000, acc=0.965606, TPR=0.959085, TNR=0.974921, MSE=0.034394\n",
      "Validataion: C=100.000000, acc=0.577400, TPR=0.181800, TNR=0.973000, MSE=0.422600\n",
      "\n",
      "Running # Neg: 135000\n",
      "# total training data: 345000, # Neg: 135000\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.905235, TPR=0.977115, TNR=0.806090, MSE=0.094765\n",
      "Validataion: C=0.005000, acc=0.719350, TPR=0.550500, TNR=0.888200, MSE=0.280650\n",
      "Training: C=0.010000, acc=0.928383, TPR=0.973455, TNR=0.866214, MSE=0.071617\n",
      "Validataion: C=0.010000, acc=0.710000, TPR=0.471700, TNR=0.948300, MSE=0.290000\n",
      "Training: C=0.050000, acc=0.953014, TPR=0.966870, TNR=0.933903, MSE=0.046986\n",
      "Validataion: C=0.050000, acc=0.653100, TPR=0.337700, TNR=0.968500, MSE=0.346900\n",
      "Training: C=0.100000, acc=0.957029, TPR=0.964720, TNR=0.946421, MSE=0.042971\n",
      "Validataion: C=0.100000, acc=0.631600, TPR=0.294700, TNR=0.968500, MSE=0.368400\n",
      "Training: C=0.500000, acc=0.960870, TPR=0.961440, TNR=0.960083, MSE=0.039130\n",
      "Validataion: C=0.500000, acc=0.598500, TPR=0.229700, TNR=0.967300, MSE=0.401500\n",
      "Training: C=1.000000, acc=0.961470, TPR=0.960665, TNR=0.962579, MSE=0.038530\n",
      "Validataion: C=1.000000, acc=0.589850, TPR=0.214500, TNR=0.965200, MSE=0.410150\n",
      "Training: C=5.000000, acc=0.962307, TPR=0.960300, TNR=0.965076, MSE=0.037693\n",
      "Validataion: C=5.000000, acc=0.583050, TPR=0.207200, TNR=0.958900, MSE=0.416950\n",
      "Training: C=10.000000, acc=0.962571, TPR=0.960390, TNR=0.965579, MSE=0.037429\n",
      "Validataion: C=10.000000, acc=0.582800, TPR=0.208800, TNR=0.956800, MSE=0.417200\n",
      "Training: C=50.000000, acc=0.962675, TPR=0.960580, TNR=0.965566, MSE=0.037325\n",
      "Validataion: C=50.000000, acc=0.583300, TPR=0.212300, TNR=0.954300, MSE=0.416700\n",
      "Training: C=100.000000, acc=0.962672, TPR=0.960605, TNR=0.965524, MSE=0.037328\n",
      "Validataion: C=100.000000, acc=0.583100, TPR=0.212800, TNR=0.953400, MSE=0.416900\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.905075, TPR=0.977005, TNR=0.805862, MSE=0.094925\n",
      "Validataion: C=0.005000, acc=0.723700, TPR=0.547900, TNR=0.899500, MSE=0.276300\n",
      "Training: C=0.010000, acc=0.929157, TPR=0.973080, TNR=0.868572, MSE=0.070843\n",
      "Validataion: C=0.010000, acc=0.711100, TPR=0.464000, TNR=0.958200, MSE=0.288900\n",
      "Training: C=0.050000, acc=0.954719, TPR=0.966190, TNR=0.938897, MSE=0.045281\n",
      "Validataion: C=0.050000, acc=0.648850, TPR=0.323900, TNR=0.973800, MSE=0.351150\n",
      "Training: C=0.100000, acc=0.958516, TPR=0.963945, TNR=0.951028, MSE=0.041484\n",
      "Validataion: C=0.100000, acc=0.626850, TPR=0.279100, TNR=0.974600, MSE=0.373150\n",
      "Training: C=0.500000, acc=0.962229, TPR=0.960865, TNR=0.964110, MSE=0.037771\n",
      "Validataion: C=0.500000, acc=0.595400, TPR=0.218000, TNR=0.972800, MSE=0.404600\n",
      "Training: C=1.000000, acc=0.962809, TPR=0.960255, TNR=0.966331, MSE=0.037191\n",
      "Validataion: C=1.000000, acc=0.588200, TPR=0.205900, TNR=0.970500, MSE=0.411800\n",
      "Training: C=5.000000, acc=0.963391, TPR=0.959780, TNR=0.968372, MSE=0.036609\n",
      "Validataion: C=5.000000, acc=0.580200, TPR=0.196200, TNR=0.964200, MSE=0.419800\n",
      "Training: C=10.000000, acc=0.963603, TPR=0.959875, TNR=0.968745, MSE=0.036397\n",
      "Validataion: C=10.000000, acc=0.580600, TPR=0.198000, TNR=0.963200, MSE=0.419400\n",
      "Training: C=50.000000, acc=0.963722, TPR=0.960130, TNR=0.968676, MSE=0.036278\n",
      "Validataion: C=50.000000, acc=0.581300, TPR=0.203000, TNR=0.959600, MSE=0.418700\n",
      "Training: C=100.000000, acc=0.963716, TPR=0.960175, TNR=0.968600, MSE=0.036284\n",
      "Validataion: C=100.000000, acc=0.581300, TPR=0.203900, TNR=0.958700, MSE=0.418700\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.904846, TPR=0.976925, TNR=0.805428, MSE=0.095154\n",
      "Validataion: C=0.005000, acc=0.728950, TPR=0.546200, TNR=0.911700, MSE=0.271050\n",
      "Training: C=0.010000, acc=0.929516, TPR=0.972900, TNR=0.869676, MSE=0.070484\n",
      "Validataion: C=0.010000, acc=0.712500, TPR=0.460300, TNR=0.964700, MSE=0.287500\n",
      "Training: C=0.050000, acc=0.955957, TPR=0.965545, TNR=0.942731, MSE=0.044043\n",
      "Validataion: C=0.050000, acc=0.645100, TPR=0.311000, TNR=0.979200, MSE=0.354900\n",
      "Training: C=0.100000, acc=0.959884, TPR=0.963265, TNR=0.955221, MSE=0.040116\n",
      "Validataion: C=0.100000, acc=0.622450, TPR=0.265400, TNR=0.979500, MSE=0.377550\n",
      "Training: C=0.500000, acc=0.963455, TPR=0.960230, TNR=0.967903, MSE=0.036545\n",
      "Validataion: C=0.500000, acc=0.592100, TPR=0.205000, TNR=0.979200, MSE=0.407900\n",
      "Training: C=1.000000, acc=0.963977, TPR=0.959585, TNR=0.970034, MSE=0.036023\n",
      "Validataion: C=1.000000, acc=0.584800, TPR=0.192300, TNR=0.977300, MSE=0.415200\n",
      "Training: C=5.000000, acc=0.964380, TPR=0.959280, TNR=0.971414, MSE=0.035620\n",
      "Validataion: C=5.000000, acc=0.577800, TPR=0.186200, TNR=0.969400, MSE=0.422200\n",
      "Training: C=10.000000, acc=0.964499, TPR=0.959440, TNR=0.971476, MSE=0.035501\n",
      "Validataion: C=10.000000, acc=0.578200, TPR=0.189300, TNR=0.967100, MSE=0.421800\n",
      "Training: C=50.000000, acc=0.964591, TPR=0.959645, TNR=0.971414, MSE=0.035409\n",
      "Validataion: C=50.000000, acc=0.578700, TPR=0.193200, TNR=0.964200, MSE=0.421300\n",
      "Training: C=100.000000, acc=0.964548, TPR=0.959685, TNR=0.971255, MSE=0.035452\n",
      "Validataion: C=100.000000, acc=0.578700, TPR=0.193900, TNR=0.963500, MSE=0.421300\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.904200, TPR=0.976965, TNR=0.803834, MSE=0.095800\n",
      "Validataion: C=0.005000, acc=0.733250, TPR=0.546700, TNR=0.919800, MSE=0.266750\n",
      "Training: C=0.010000, acc=0.929765, TPR=0.972780, TNR=0.870434, MSE=0.070235\n",
      "Validataion: C=0.010000, acc=0.714050, TPR=0.457700, TNR=0.970400, MSE=0.285950\n",
      "Training: C=0.050000, acc=0.957162, TPR=0.965020, TNR=0.946324, MSE=0.042838\n",
      "Validataion: C=0.050000, acc=0.643250, TPR=0.300500, TNR=0.986000, MSE=0.356750\n",
      "Training: C=0.100000, acc=0.961188, TPR=0.962760, TNR=0.959021, MSE=0.038812\n",
      "Validataion: C=0.100000, acc=0.620750, TPR=0.255300, TNR=0.986200, MSE=0.379250\n",
      "Training: C=0.500000, acc=0.964470, TPR=0.959790, TNR=0.970924, MSE=0.035530\n",
      "Validataion: C=0.500000, acc=0.589700, TPR=0.196100, TNR=0.983300, MSE=0.410300\n",
      "Training: C=1.000000, acc=0.964884, TPR=0.959125, TNR=0.972828, MSE=0.035116\n",
      "Validataion: C=1.000000, acc=0.582200, TPR=0.183000, TNR=0.981400, MSE=0.417800\n",
      "Training: C=5.000000, acc=0.965252, TPR=0.958785, TNR=0.974172, MSE=0.034748\n",
      "Validataion: C=5.000000, acc=0.576650, TPR=0.176200, TNR=0.977100, MSE=0.423350\n",
      "Training: C=10.000000, acc=0.965301, TPR=0.958845, TNR=0.974207, MSE=0.034699\n",
      "Validataion: C=10.000000, acc=0.575850, TPR=0.177300, TNR=0.974400, MSE=0.424150\n",
      "Training: C=50.000000, acc=0.965400, TPR=0.959180, TNR=0.973979, MSE=0.034600\n",
      "Validataion: C=50.000000, acc=0.577100, TPR=0.183800, TNR=0.970400, MSE=0.422900\n",
      "Training: C=100.000000, acc=0.965400, TPR=0.959265, TNR=0.973862, MSE=0.034600\n",
      "Validataion: C=100.000000, acc=0.577650, TPR=0.185500, TNR=0.969800, MSE=0.422350\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.005000, acc=0.903748, TPR=0.976975, TNR=0.802745, MSE=0.096252\n",
      "Validataion: C=0.005000, acc=0.738500, TPR=0.547300, TNR=0.929700, MSE=0.261500\n",
      "Training: C=0.010000, acc=0.929748, TPR=0.972650, TNR=0.870572, MSE=0.070252\n",
      "Validataion: C=0.010000, acc=0.715900, TPR=0.455000, TNR=0.976800, MSE=0.284100\n",
      "Training: C=0.050000, acc=0.958090, TPR=0.964540, TNR=0.949193, MSE=0.041910\n",
      "Validataion: C=0.050000, acc=0.640000, TPR=0.290900, TNR=0.989100, MSE=0.360000\n",
      "Training: C=0.100000, acc=0.962090, TPR=0.962220, TNR=0.961910, MSE=0.037910\n",
      "Validataion: C=0.100000, acc=0.617000, TPR=0.244500, TNR=0.989500, MSE=0.383000\n",
      "Training: C=0.500000, acc=0.965278, TPR=0.959405, TNR=0.973379, MSE=0.034722\n",
      "Validataion: C=0.500000, acc=0.587750, TPR=0.188400, TNR=0.987100, MSE=0.412250\n",
      "Training: C=1.000000, acc=0.965748, TPR=0.958750, TNR=0.975400, MSE=0.034252\n",
      "Validataion: C=1.000000, acc=0.580700, TPR=0.175400, TNR=0.986000, MSE=0.419300\n",
      "Training: C=5.000000, acc=0.965968, TPR=0.958325, TNR=0.976510, MSE=0.034032\n",
      "Validataion: C=5.000000, acc=0.574300, TPR=0.166900, TNR=0.981700, MSE=0.425700\n",
      "Training: C=10.000000, acc=0.965971, TPR=0.958395, TNR=0.976421, MSE=0.034029\n",
      "Validataion: C=10.000000, acc=0.573350, TPR=0.168300, TNR=0.978400, MSE=0.426650\n",
      "Training: C=50.000000, acc=0.966090, TPR=0.958695, TNR=0.976290, MSE=0.033910\n",
      "Validataion: C=50.000000, acc=0.574550, TPR=0.174100, TNR=0.975000, MSE=0.425450\n",
      "Training: C=100.000000, acc=0.966038, TPR=0.958725, TNR=0.976124, MSE=0.033962\n",
      "Validataion: C=100.000000, acc=0.574150, TPR=0.174700, TNR=0.973600, MSE=0.425850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.7385, 0.5473, 0.9297, 0.2615, 135000, 0.005, 12),\n",
       " (0.73325, 0.5467, 0.9198, 0.26675, 135000, 0.005, 11),\n",
       " (0.72895, 0.5462, 0.9117, 0.27105, 135000, 0.005, 10),\n",
       " (0.72665, 0.5165, 0.9368, 0.27335, 120000, 0.01, 12),\n",
       " (0.7252, 0.4939, 0.9565, 0.2748, 125000, 0.01, 12),\n",
       " (0.72475, 0.5717, 0.8778, 0.27525, 130000, 0.005, 12),\n",
       " (0.7237, 0.5479, 0.8995, 0.2763, 135000, 0.005, 9),\n",
       " (0.7231, 0.5399, 0.9063, 0.2769, 115000, 0.01, 12),\n",
       " (0.7231, 0.5176, 0.9286, 0.2769, 120000, 0.01, 11),\n",
       " (0.72225, 0.4956, 0.9489, 0.27775, 125000, 0.01, 11)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try Tuning top K + # of Negatives\n",
    "#Includes Another Similarity feature [simItem, simUser, new percentile]\n",
    "numNegativeExamples = range(70000, 140000, 5000)\n",
    "predBookResult = []\n",
    "\n",
    "for numNeg in numNegativeExamples:\n",
    "    print(\"\\nRunning # Neg: %d\" % (numNeg) )\n",
    "    bookDataNeg, bookDataYNeg = getNegativeEntries(numNeg)\n",
    "    bookDataArt = bookDataTrain + bookDataValid + bookDataNeg\n",
    "    bookDataYArt = bookDataYTrain + bookDataYValid + bookDataYNeg\n",
    "    print(\"# total training data: %d, # Neg: %d\" % (len(bookDataArt), len(bookDataNeg)) )\n",
    "    \n",
    "    for topK in range(8,13):\n",
    "        print(\"\\nRunning Top K: %d\" % (topK))\n",
    "        \n",
    "        # Data to Features [simItem, simUser, percentile]\n",
    "        bookFeaturesArt = getClassificationData3(bookDataArt, topK)\n",
    "        bookFeaturesValid = getClassificationData3(bookDataValid, topK)\n",
    "        print(min([x[0] for x in bookFeaturesArt]))\n",
    "        print(min([x[1] for x in bookFeaturesArt]))\n",
    "        print(min([x[2] for x in bookFeaturesArt]))\n",
    "        print(max([x[0] for x in bookFeaturesArt]))\n",
    "        print(max([x[1] for x in bookFeaturesArt]))\n",
    "        print(max([x[2] for x in bookFeaturesArt]))\n",
    "\n",
    "        for cVal in [0.005,0.01,0.05,0.1,0.5,1,5,10,50,100]:\n",
    "            model = linear_model.LogisticRegression(C=cVal, solver=\"liblinear\")\n",
    "            model.fit(bookFeaturesArt, bookDataYArt)\n",
    "\n",
    "            predBookDataYArt = model.predict(bookFeaturesArt)\n",
    "            mseTrain = MSE(predBookDataYArt, bookDataYArt)\n",
    "            predBookDataYValid = model.predict(bookFeaturesValid)\n",
    "            mseValid = MSE(predBookDataYValid, bookDataYValid)\n",
    "\n",
    "            writeOutClassificationPredWithFunction(model, \"numNeg_\"+str(numNeg)+\"_C_\"+str(cVal)+\"_topK_\"+str(topK), getClassificationData3, topK)\n",
    "\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYArt, bookDataYArt)\n",
    "            print(\"Training: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseTrain) )\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "            print(\"Validataion: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseValid) )\n",
    "            predBookResult.append((acc, TPR, TNR, mseValid, numNeg, cVal, topK))\n",
    "    \n",
    "predBookResult.sort(reverse = True)\n",
    "predBookResult[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running # Neg: 100168\n",
      "# total training data: 20000, # Neg: 100168\n",
      "\n",
      "Running Top K: 1\n",
      "0.0\n",
      "0.0\n",
      "[[0.]]\n",
      "0.09523809523809523\n",
      "0.13636363636363635\n",
      "[[0.22980099]]\n",
      "Training: C=0.001000, acc=0.719150, TPR=0.569000, TNR=0.869300, MSE=0.280850\n",
      "Validataion: C=0.001000, acc=0.719150, TPR=0.569000, TNR=0.869300, MSE=0.280850\n",
      "Training: C=0.010000, acc=0.734000, TPR=0.501600, TNR=0.966400, MSE=0.266000\n",
      "Validataion: C=0.010000, acc=0.734000, TPR=0.501600, TNR=0.966400, MSE=0.266000\n",
      "Training: C=0.100000, acc=0.720400, TPR=0.532900, TNR=0.907900, MSE=0.279600\n",
      "Validataion: C=0.100000, acc=0.720400, TPR=0.532900, TNR=0.907900, MSE=0.279600\n",
      "Training: C=1.000000, acc=0.714850, TPR=0.558100, TNR=0.871600, MSE=0.285150\n",
      "Validataion: C=1.000000, acc=0.714850, TPR=0.558100, TNR=0.871600, MSE=0.285150\n",
      "Training: C=10.000000, acc=0.722500, TPR=0.572800, TNR=0.872200, MSE=0.277500\n",
      "Validataion: C=10.000000, acc=0.722500, TPR=0.572800, TNR=0.872200, MSE=0.277500\n",
      "Training: C=100.000000, acc=0.722550, TPR=0.585000, TNR=0.860100, MSE=0.277450\n",
      "Validataion: C=100.000000, acc=0.722550, TPR=0.585000, TNR=0.860100, MSE=0.277450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.734, 0.5016, 0.9664, 0.266, 100168, 0.01, 1),\n",
       " (0.72255, 0.585, 0.8601, 0.27745, 100168, 100, 1),\n",
       " (0.7225, 0.5728, 0.8722, 0.2775, 100168, 10, 1),\n",
       " (0.7204, 0.5329, 0.9079, 0.2796, 100168, 0.1, 1),\n",
       " (0.71915, 0.569, 0.8693, 0.28085, 100168, 0.001, 1),\n",
       " (0.71485, 0.5581, 0.8716, 0.28515, 100168, 1, 1)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity => Use Train bookData\n",
    "#Includes Another Similarity feature [simItem, simUser, cosineSimItem, cosineSimUser, new percentile]\n",
    "numNegativeExamples = [100168]\n",
    "predBookResult = []\n",
    "\n",
    "for numNeg in numNegativeExamples:\n",
    "    print(\"\\nRunning # Neg: %d\" % (numNeg) )\n",
    "    #bookDataNeg, bookDataYNeg = getNegativeEntries(numNeg)\n",
    "    #bookDataArt = bookDataTrain + bookDataValid + bookDataNeg\n",
    "    #bookDataYArt = bookDataYTrain + bookDataYValid + bookDataYNeg\n",
    "    bookDataArt = bookDataValid\n",
    "    bookDataYArt = bookDataYValid\n",
    "    print(\"# total training data: %d, # Neg: %d\" % (len(bookDataArt), len(bookDataNeg)) )\n",
    "    \n",
    "    for topK in [1]:\n",
    "        print(\"\\nRunning Top K: %d\" % (topK))\n",
    "        \n",
    "        # Data to Features [simItem, simUser, percentile]\n",
    "        bookFeaturesArt = getClassificationData4(bookDataArt, topK)\n",
    "        bookFeaturesValid = getClassificationData4(bookDataValid, topK)\n",
    "        print(min([x[0] for x in bookFeaturesArt]))\n",
    "        print(min([x[1] for x in bookFeaturesArt]))\n",
    "        print(min([x[2] for x in bookFeaturesArt]))\n",
    "        print(max([x[0] for x in bookFeaturesArt]))\n",
    "        print(max([x[1] for x in bookFeaturesArt]))\n",
    "        print(max([x[2] for x in bookFeaturesArt]))\n",
    "\n",
    "        for cExp in range(-3,3):\n",
    "            cVal = pow(10,cExp)\n",
    "            model = linear_model.LogisticRegression(C=cVal, solver=\"liblinear\")\n",
    "            model.fit(bookFeaturesArt, bookDataYArt)\n",
    "\n",
    "            predBookDataYArt = model.predict(bookFeaturesArt)\n",
    "            mseTrain = MSE(predBookDataYArt, bookDataYArt)\n",
    "            predBookDataYValid = model.predict(bookFeaturesValid)\n",
    "            mseValid = MSE(predBookDataYValid, bookDataYValid)\n",
    "\n",
    "            writeOutClassificationPredWithFunction(model, \"numNeg_\"+str(numNeg)+\"_C_\"+str(cVal)+\"_topK_\"+str(topK)+\"_simOnTrain_CosineSim\", getClassificationData4, topK)\n",
    "\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYArt, bookDataYArt)\n",
    "            print(\"Training: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseTrain) )\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "            print(\"Validataion: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseValid) )\n",
    "            predBookResult.append((acc, TPR, TNR, mseValid, numNeg, cVal, topK))\n",
    "    \n",
    "predBookResult.sort(reverse = True)\n",
    "predBookResult[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running # Neg: 100168\n",
      "# total training data: 310168, # Neg: 100168\n",
      "\n",
      "Running Top K: 1\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.19047619047619047\n",
      "0.3076923076923077\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.874371, TPR=0.999525, TNR=0.647166, MSE=0.125629\n",
      "Validataion: C=0.010000, acc=0.799500, TPR=0.999100, TNR=0.599900, MSE=0.200500\n",
      "Training: C=0.100000, acc=0.941880, TPR=0.990580, TNR=0.853469, MSE=0.058120\n",
      "Validataion: C=0.100000, acc=0.934500, TPR=0.991500, TNR=0.877500, MSE=0.065500\n",
      "Training: C=1.000000, acc=0.951500, TPR=0.980635, TNR=0.898609, MSE=0.048500\n",
      "Validataion: C=1.000000, acc=0.947050, TPR=0.982200, TNR=0.911900, MSE=0.052950\n",
      "Training: C=10.000000, acc=0.951568, TPR=0.974940, TNR=0.909139, MSE=0.048432\n",
      "Validataion: C=10.000000, acc=0.947650, TPR=0.975400, TNR=0.919900, MSE=0.052350\n",
      "Training: C=100.000000, acc=0.951433, TPR=0.973680, TNR=0.911045, MSE=0.048567\n",
      "Validataion: C=100.000000, acc=0.947600, TPR=0.973800, TNR=0.921400, MSE=0.052400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.94765, 0.9754, 0.9199, 0.05235, 100168, 10, 1),\n",
       " (0.9476, 0.9738, 0.9214, 0.0524, 100168, 100, 1),\n",
       " (0.94705, 0.9822, 0.9119, 0.05295, 100168, 1, 1),\n",
       " (0.9345, 0.9915, 0.8775, 0.0655, 100168, 0.1, 1),\n",
       " (0.7995, 0.9991, 0.5999, 0.2005, 100168, 0.01, 1),\n",
       " (0.5, 1.0, 0.0, 0.5, 100168, 0.001, 1)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity => Use whole bookData to Train\n",
    "#Includes Another Similarity feature [simItem, simUser, new percentile]\n",
    "numNegativeExamples = [100168]\n",
    "predBookResult = []\n",
    "\n",
    "for numNeg in numNegativeExamples:\n",
    "    print(\"\\nRunning # Neg: %d\" % (numNeg) )\n",
    "    bookDataNeg, bookDataYNeg = getNegativeEntries(numNeg)\n",
    "    bookDataArt = bookDataTrain + bookDataValid + bookDataNeg\n",
    "    bookDataYArt = bookDataYTrain + bookDataYValid + bookDataYNeg\n",
    "    print(\"# total training data: %d, # Neg: %d\" % (len(bookDataArt), len(bookDataNeg)) )\n",
    "    \n",
    "    for topK in [1]:\n",
    "        print(\"\\nRunning Top K: %d\" % (topK))\n",
    "        \n",
    "        # Data to Features [simItem, simUser, percentile]\n",
    "        bookFeaturesArt = getClassificationData3(bookDataArt, topK)\n",
    "        bookFeaturesValid = getClassificationData3(bookDataValid, topK)\n",
    "        print(min([x[0] for x in bookFeaturesArt]))\n",
    "        print(min([x[1] for x in bookFeaturesArt]))\n",
    "        print(min([x[2] for x in bookFeaturesArt]))\n",
    "        print(max([x[0] for x in bookFeaturesArt]))\n",
    "        print(max([x[1] for x in bookFeaturesArt]))\n",
    "        print(max([x[2] for x in bookFeaturesArt]))\n",
    "\n",
    "        for cExp in range(-3,3):\n",
    "            cVal = pow(10,cExp)\n",
    "            model = linear_model.LogisticRegression(C=cVal, solver=\"liblinear\")\n",
    "            model.fit(bookFeaturesArt, bookDataYArt)\n",
    "\n",
    "            predBookDataYArt = model.predict(bookFeaturesArt)\n",
    "            mseTrain = MSE(predBookDataYArt, bookDataYArt)\n",
    "            predBookDataYValid = model.predict(bookFeaturesValid)\n",
    "            mseValid = MSE(predBookDataYValid, bookDataYValid)\n",
    "\n",
    "            writeOutClassificationPredWithFunction(model, \"numNeg_\"+str(numNeg)+\"_C_\"+str(cVal)+\"_topK_\"+str(topK)+\"_simOnAll\", getClassificationData3, topK)\n",
    "\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYArt, bookDataYArt)\n",
    "            print(\"Training: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseTrain) )\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "            print(\"Validataion: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseValid) )\n",
    "            predBookResult.append((acc, TPR, TNR, mseValid, numNeg, cVal, topK))\n",
    "    \n",
    "predBookResult.sort(reverse = True)\n",
    "predBookResult[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running # Neg: 100168\n",
      "# total training data: 310168, # Neg: 100168\n",
      "\n",
      "Running Top K: 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-a64d3dea34b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Data to Features [simItem, simUser, percentile]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mbookFeaturesArt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetClassificationData3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbookDataArt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mbookFeaturesValid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetClassificationData3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbookDataValid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbookFeaturesArt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-289bf3f0c84e>\u001b[0m in \u001b[0;36mgetClassificationData3\u001b[0;34m(Xdata, topK)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msim2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairSimilarityByUser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtopK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-144-8fbecceaa6f8>\u001b[0m in \u001b[0;36mpairSimilarityByUser\u001b[0;34m(u, b)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidateUsers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mu2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemsPerUser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-1d43a5daf4f4>\u001b[0m in \u001b[0;36mJaccard\u001b[0;34m(s1, s2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mJaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnumer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnumer\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Similarity => Use whole bookData to Train\n",
    "#Includes Another Similarity feature [simItem, simUser, new percentile]\n",
    "numNegativeExamples = [100168]\n",
    "predBookResult = []\n",
    "\n",
    "for numNeg in numNegativeExamples:\n",
    "    print(\"\\nRunning # Neg: %d\" % (numNeg) )\n",
    "    bookDataNeg, bookDataYNeg = getNegativeEntries(numNeg)\n",
    "    bookDataArt = bookDataTrain + bookDataValid + bookDataNeg\n",
    "    bookDataYArt = bookDataYTrain + bookDataYValid + bookDataYNeg\n",
    "    print(\"# total training data: %d, # Neg: %d\" % (len(bookDataArt), len(bookDataNeg)) )\n",
    "    \n",
    "    #for topK in range(1,11):\n",
    "    for topK in [5,8,9,10,11]:\n",
    "        print(\"\\nRunning Top K: %d\" % (topK))\n",
    "        \n",
    "        # Data to Features [simItem, simUser, percentile]\n",
    "        bookFeaturesArt = getClassificationData3(bookDataArt, topK)\n",
    "        bookFeaturesValid = getClassificationData3(bookDataValid, topK)\n",
    "        print(min([x[0] for x in bookFeaturesArt]))\n",
    "        print(min([x[1] for x in bookFeaturesArt]))\n",
    "        print(min([x[2] for x in bookFeaturesArt]))\n",
    "        print(max([x[0] for x in bookFeaturesArt]))\n",
    "        print(max([x[1] for x in bookFeaturesArt]))\n",
    "        print(max([x[2] for x in bookFeaturesArt]))\n",
    "\n",
    "        for cVal in [0.005,0.05]:\n",
    "            model = linear_model.LogisticRegression(C=cVal, solver=\"liblinear\")\n",
    "            model.fit(bookFeaturesArt, bookDataYArt)\n",
    "\n",
    "            predBookDataYArt = model.predict(bookFeaturesArt)\n",
    "            mseTrain = MSE(predBookDataYArt, bookDataYArt)\n",
    "            predBookDataYValid = model.predict(bookFeaturesValid)\n",
    "            mseValid = MSE(predBookDataYValid, bookDataYValid)\n",
    "\n",
    "            writeOutClassificationPredWithFunction(model, \"numNeg_\"+str(numNeg)+\"_C_\"+str(cVal)+\"_topK_\"+str(topK)+\"_simOnAll_123\", getClassificationData3, topK)\n",
    "\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYArt, bookDataYArt)\n",
    "            print(\"Training: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseTrain) )\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "            print(\"Validataion: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseValid) )\n",
    "            predBookResult.append((acc, TPR, TNR, mseValid, numNeg, cVal, topK))\n",
    "    \n",
    "predBookResult.sort(reverse = True)\n",
    "predBookResult[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running # Neg: 100168\n",
      "# total training data: 310168, # Neg: 100168\n",
      "\n",
      "Running Top K: 5\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.12277777777777778\n",
      "0.1638095238095238\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.905100, TPR=0.999990, TNR=0.732835, MSE=0.094900\n",
      "Validataion: C=0.010000, acc=0.840950, TPR=0.999900, TNR=0.682000, MSE=0.159050\n",
      "Training: C=0.100000, acc=0.968075, TPR=0.999875, TNR=0.910346, MSE=0.031925\n",
      "Validataion: C=0.100000, acc=0.963200, TPR=0.999900, TNR=0.926500, MSE=0.036800\n",
      "Training: C=1.000000, acc=0.984634, TPR=0.998740, TNR=0.959026, MSE=0.015366\n",
      "Validataion: C=1.000000, acc=0.977500, TPR=0.998900, TNR=0.956100, MSE=0.022500\n",
      "Training: C=10.000000, acc=0.989151, TPR=0.996785, TNR=0.975292, MSE=0.010849\n",
      "Validataion: C=10.000000, acc=0.983900, TPR=0.997700, TNR=0.970100, MSE=0.016100\n",
      "Training: C=100.000000, acc=0.990121, TPR=0.995395, TNR=0.980548, MSE=0.009879\n",
      "Validataion: C=100.000000, acc=0.984950, TPR=0.995700, TNR=0.974200, MSE=0.015050\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09720598845598845\n",
      "0.13780689468769963\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.910948, TPR=0.999990, TNR=0.749301, MSE=0.089052\n",
      "Validataion: C=0.010000, acc=0.871500, TPR=0.999900, TNR=0.743100, MSE=0.128500\n",
      "Training: C=0.100000, acc=0.980024, TPR=0.999990, TNR=0.943777, MSE=0.019976\n",
      "Validataion: C=0.100000, acc=0.988000, TPR=0.999900, TNR=0.976100, MSE=0.012000\n",
      "Training: C=1.000000, acc=0.991176, TPR=0.999765, TNR=0.975583, MSE=0.008824\n",
      "Validataion: C=1.000000, acc=0.991850, TPR=0.999400, TNR=0.984300, MSE=0.008150\n",
      "Training: C=10.000000, acc=0.994638, TPR=0.999125, TNR=0.986493, MSE=0.005362\n",
      "Validataion: C=10.000000, acc=0.992850, TPR=0.998800, TNR=0.986900, MSE=0.007150\n",
      "Training: C=100.000000, acc=0.996215, TPR=0.998670, TNR=0.991758, MSE=0.003785\n",
      "Validataion: C=100.000000, acc=0.993800, TPR=0.998200, TNR=0.989400, MSE=0.006200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.9938, 0.9982, 0.9894, 0.0062, 100168, 100, 10),\n",
       " (0.99285, 0.9988, 0.9869, 0.00715, 100168, 10, 10),\n",
       " (0.99185, 0.9994, 0.9843, 0.00815, 100168, 1, 10),\n",
       " (0.988, 0.9999, 0.9761, 0.012, 100168, 0.1, 10),\n",
       " (0.98495, 0.9957, 0.9742, 0.01505, 100168, 100, 5),\n",
       " (0.9839, 0.9977, 0.9701, 0.0161, 100168, 10, 5),\n",
       " (0.9775, 0.9989, 0.9561, 0.0225, 100168, 1, 5),\n",
       " (0.9632, 0.9999, 0.9265, 0.0368, 100168, 0.1, 5),\n",
       " (0.8715, 0.9999, 0.7431, 0.1285, 100168, 0.01, 10),\n",
       " (0.84095, 0.9999, 0.682, 0.15905, 100168, 0.01, 5)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity => Use whole bookData to Train\n",
    "#Includes Another Similarity feature [simItem, simUser, new percentile]\n",
    "numNegativeExamples = [100168]\n",
    "predBookResult = []\n",
    "\n",
    "for numNeg in numNegativeExamples:\n",
    "    print(\"\\nRunning # Neg: %d\" % (numNeg) )\n",
    "    bookDataNeg, bookDataYNeg = getNegativeEntries(numNeg)\n",
    "    bookDataArt = bookDataTrain + bookDataValid + bookDataNeg\n",
    "    bookDataYArt = bookDataYTrain + bookDataYValid + bookDataYNeg\n",
    "    print(\"# total training data: %d, # Neg: %d\" % (len(bookDataArt), len(bookDataNeg)) )\n",
    "    \n",
    "    #for topK in range(1,11):\n",
    "    for topK in [5,10]:\n",
    "        print(\"\\nRunning Top K: %d\" % (topK))\n",
    "        \n",
    "        # Data to Features [simItem, simUser, percentile]\n",
    "        bookFeaturesArt = getClassificationData3(bookDataArt, topK)\n",
    "        bookFeaturesValid = getClassificationData3(bookDataValid, topK)\n",
    "        print(min([x[0] for x in bookFeaturesArt]))\n",
    "        print(min([x[1] for x in bookFeaturesArt]))\n",
    "        print(min([x[2] for x in bookFeaturesArt]))\n",
    "        print(max([x[0] for x in bookFeaturesArt]))\n",
    "        print(max([x[1] for x in bookFeaturesArt]))\n",
    "        print(max([x[2] for x in bookFeaturesArt]))\n",
    "\n",
    "        for cExp in range(-3,3):\n",
    "            cVal = pow(10,cExp)\n",
    "            model = linear_model.LogisticRegression(C=cVal, solver=\"liblinear\")\n",
    "            model.fit(bookFeaturesArt, bookDataYArt)\n",
    "\n",
    "            predBookDataYArt = model.predict(bookFeaturesArt)\n",
    "            mseTrain = MSE(predBookDataYArt, bookDataYArt)\n",
    "            predBookDataYValid = model.predict(bookFeaturesValid)\n",
    "            mseValid = MSE(predBookDataYValid, bookDataYValid)\n",
    "\n",
    "            writeOutClassificationPredWithFunction(model, \"numNeg_\"+str(numNeg)+\"_C_\"+str(cVal)+\"_topK_\"+str(topK)+\"_simOnAll\", getClassificationData3, topK)\n",
    "\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYArt, bookDataYArt)\n",
    "            print(\"Training: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseTrain) )\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "            print(\"Validataion: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseValid) )\n",
    "            predBookResult.append((acc, TPR, TNR, mseValid, numNeg, cVal, topK))\n",
    "    \n",
    "predBookResult.sort(reverse = True)\n",
    "predBookResult[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running # Neg: 100777\n",
      "# total training data: 290777, # Neg: 100777\n",
      "\n",
      "Running Top K: 5\n",
      "x[0]: min: 0.000000, max 0.117547\n",
      "x[1]: min: 0.000000, max 0.163810\n",
      "x[2]: min: 0.000000, max 1.000000\n",
      "x[0]: min: -1.300082, max 6.337370\n",
      "x[1]: min: -1.445028, max 4.696226\n",
      "x[2]: min: -0.922947, max 7.081173\n",
      "Training: C=0.001000, acc=0.990477, TPR=0.998789, TNR=0.974806, MSE=0.009523\n",
      "Validataion: C=0.001000, acc=0.565450, TPR=0.165400, TNR=0.965500, MSE=0.434550\n",
      "Training: C=0.010000, acc=0.991987, TPR=0.997079, TNR=0.982387, MSE=0.008013\n",
      "Validataion: C=0.010000, acc=0.547350, TPR=0.123100, TNR=0.971600, MSE=0.452650\n",
      "Training: C=0.100000, acc=0.992176, TPR=0.996053, TNR=0.984868, MSE=0.007824\n",
      "Validataion: C=0.100000, acc=0.541500, TPR=0.110100, TNR=0.972900, MSE=0.458500\n",
      "Training: C=1.000000, acc=0.992180, TPR=0.995795, TNR=0.985364, MSE=0.007820\n",
      "Validataion: C=1.000000, acc=0.540350, TPR=0.107800, TNR=0.972900, MSE=0.459650\n",
      "Training: C=10.000000, acc=0.992152, TPR=0.995742, TNR=0.985384, MSE=0.007848\n",
      "Validataion: C=10.000000, acc=0.540300, TPR=0.107700, TNR=0.972900, MSE=0.459700\n",
      "Training: C=100.000000, acc=0.992152, TPR=0.995742, TNR=0.985384, MSE=0.007848\n",
      "Validataion: C=100.000000, acc=0.540350, TPR=0.107700, TNR=0.973000, MSE=0.459650\n",
      "Training: C=1000.000000, acc=0.992152, TPR=0.995742, TNR=0.985384, MSE=0.007848\n",
      "Validataion: C=1000.000000, acc=0.540350, TPR=0.107700, TNR=0.973000, MSE=0.459650\n",
      "Training: C=10000.000000, acc=0.992152, TPR=0.995742, TNR=0.985384, MSE=0.007848\n",
      "Validataion: C=10000.000000, acc=0.540350, TPR=0.107700, TNR=0.973000, MSE=0.459650\n",
      "\n",
      "Running Top K: 10\n",
      "x[0]: min: 0.000000, max 0.100981\n",
      "x[1]: min: 0.000000, max 0.140404\n",
      "x[2]: min: 0.000000, max 1.000000\n",
      "x[0]: min: -1.222423, max 6.454221\n",
      "x[1]: min: -1.348795, max 4.547096\n",
      "x[2]: min: -0.922947, max 7.081173\n",
      "Training: C=0.001000, acc=0.995742, TPR=0.999858, TNR=0.987983, MSE=0.004258\n",
      "Validataion: C=0.001000, acc=0.546100, TPR=0.103700, TNR=0.988500, MSE=0.453900\n",
      "Training: C=0.010000, acc=0.997190, TPR=0.999516, TNR=0.992806, MSE=0.002810\n",
      "Validataion: C=0.010000, acc=0.529350, TPR=0.069000, TNR=0.989700, MSE=0.470650\n",
      "Training: C=0.100000, acc=0.997462, TPR=0.998953, TNR=0.994652, MSE=0.002538\n",
      "Validataion: C=0.100000, acc=0.522050, TPR=0.052900, TNR=0.991200, MSE=0.477950\n",
      "Training: C=1.000000, acc=0.997531, TPR=0.998716, TNR=0.995297, MSE=0.002469\n",
      "Validataion: C=1.000000, acc=0.519900, TPR=0.048300, TNR=0.991500, MSE=0.480100\n",
      "Training: C=10.000000, acc=0.997527, TPR=0.998658, TNR=0.995396, MSE=0.002473\n",
      "Validataion: C=10.000000, acc=0.519750, TPR=0.048000, TNR=0.991500, MSE=0.480250\n",
      "Training: C=100.000000, acc=0.997527, TPR=0.998653, TNR=0.995406, MSE=0.002473\n",
      "Validataion: C=100.000000, acc=0.519750, TPR=0.048000, TNR=0.991500, MSE=0.480250\n",
      "Training: C=1000.000000, acc=0.997527, TPR=0.998653, TNR=0.995406, MSE=0.002473\n",
      "Validataion: C=1000.000000, acc=0.519750, TPR=0.048000, TNR=0.991500, MSE=0.480250\n",
      "Training: C=10000.000000, acc=0.997527, TPR=0.998653, TNR=0.995406, MSE=0.002473\n",
      "Validataion: C=10000.000000, acc=0.519750, TPR=0.048000, TNR=0.991500, MSE=0.480250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.56545, 0.1654, 0.9655, 0.43455, 100777, 0.001, 5),\n",
       " (0.54735, 0.1231, 0.9716, 0.45265, 100777, 0.01, 5),\n",
       " (0.5461, 0.1037, 0.9885, 0.4539, 100777, 0.001, 10),\n",
       " (0.5415, 0.1101, 0.9729, 0.4585, 100777, 0.1, 5),\n",
       " (0.54035, 0.1078, 0.9729, 0.45965, 100777, 1, 5),\n",
       " (0.54035, 0.1077, 0.973, 0.45965, 100777, 10000, 5),\n",
       " (0.54035, 0.1077, 0.973, 0.45965, 100777, 1000, 5),\n",
       " (0.54035, 0.1077, 0.973, 0.45965, 100777, 100, 5),\n",
       " (0.5403, 0.1077, 0.9729, 0.4597, 100777, 10, 5),\n",
       " (0.52935, 0.069, 0.9897, 0.47065, 100777, 0.01, 10)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression + Feature Scaling\n",
    "numNegativeExamples = [100777]\n",
    "predBookResult = []\n",
    "\n",
    "for numNeg in numNegativeExamples:\n",
    "    print(\"\\nRunning # Neg: %d\" % (numNeg) )\n",
    "    bookDataNeg, bookDataYNeg = getNegativeEntries(numNeg)\n",
    "    bookDataArt = bookDataTrain + bookDataNeg\n",
    "    bookDataYArt = bookDataYTrain + bookDataYNeg\n",
    "    print(\"# total training data: %d, # Neg: %d\" % (len(bookDataArt), len(bookDataNeg)) )    \n",
    "    \n",
    "    #for topK in range(4,13):\n",
    "    for topK in [5,10]:\n",
    "        print(\"\\nRunning Top K: %d\" % (topK))\n",
    "        \n",
    "        # Data to Features [simItem, simUser, percentile]\n",
    "        bookFeaturesArt = getClassificationData3(bookDataArt, topK)\n",
    "        bookFeaturesValid = getClassificationData3(bookDataValid, topK)\n",
    "        print(\"x[0]: min: %f, max %f\" % (min([x[0] for x in bookFeaturesArt]), max([x[0] for x in bookFeaturesArt])))\n",
    "        print(\"x[1]: min: %f, max %f\" % (min([x[1] for x in bookFeaturesArt]), max([x[1] for x in bookFeaturesArt])))\n",
    "        print(\"x[2]: min: %f, max %f\" % (min([x[2] for x in bookFeaturesArt]), max([x[2] for x in bookFeaturesArt])))\n",
    "        \n",
    "        # Feature Scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(bookFeaturesArt)\n",
    "        bookFeaturesArt = scaler.transform(bookFeaturesArt)\n",
    "        bookFeaturesValid = scaler.transform(bookFeaturesValid)\n",
    "        print(\"x[0]: min: %f, max %f\" % (min([x[0] for x in bookFeaturesArt]), max([x[0] for x in bookFeaturesArt])))\n",
    "        print(\"x[1]: min: %f, max %f\" % (min([x[1] for x in bookFeaturesArt]), max([x[1] for x in bookFeaturesArt])))\n",
    "        print(\"x[2]: min: %f, max %f\" % (min([x[2] for x in bookFeaturesArt]), max([x[2] for x in bookFeaturesArt])))\n",
    "        \n",
    "\n",
    "        for cExp in range(-3,5):\n",
    "            cVal = pow(10,cExp)\n",
    "            model = linear_model.LogisticRegression(C=cVal, solver=\"liblinear\")\n",
    "            model.fit(bookFeaturesArt, bookDataYArt)\n",
    "\n",
    "            predBookDataYArt = model.predict(bookFeaturesArt)\n",
    "            mseTrain = MSE(predBookDataYArt, bookDataYArt)\n",
    "            predBookDataYValid = model.predict(bookFeaturesValid)\n",
    "            mseValid = MSE(predBookDataYValid, bookDataYValid)\n",
    "\n",
    "            writeOutClassificationPredWithFunction(model, \"numNeg_\"+str(numNeg)+\"_C_\"+str(cVal)+\"_topK_\"+str(topK)+\"_FtScaling\", getClassificationData3, topK, scaler)\n",
    "\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYArt, bookDataYArt)\n",
    "            print(\"Training: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseTrain) )\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "            print(\"Validataion: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseValid) )\n",
    "            predBookResult.append((acc, TPR, TNR, mseValid, numNeg, cVal, topK))\n",
    "    \n",
    "predBookResult.sort(reverse = True)\n",
    "predBookResult[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running # Neg: 100168\n",
      "# total training data: 290168, # Neg: 100168\n",
      "\n",
      "Running Top K: 5\n",
      "x[0]: min: 0.000000, max 0.117547\n",
      "x[1]: min: 0.000000, max 0.163810\n",
      "x[2]: min: 0.000000, max 1.000000\n",
      "x[0]: min: -1.301944, max 6.334979\n",
      "x[1]: min: -1.447231, max 4.694284\n",
      "x[2]: min: -0.921960, max 7.069110\n",
      "Training: numNeighbors=1, acc=1.000000, TPR=1.000000, TNR=1.000000, MSE=0.000000\n",
      "Validataion: numNeighbors=1, acc=0.546650, TPR=0.112500, TNR=0.980800, MSE=0.453350\n",
      "Training: numNeighbors=2, acc=0.994803, TPR=0.992063, TNR=1.000000, MSE=0.005197\n",
      "Validataion: numNeighbors=2, acc=0.534800, TPR=0.084700, TNR=0.984900, MSE=0.465200\n",
      "Training: numNeighbors=3, acc=0.994848, TPR=0.997726, TNR=0.989388, MSE=0.005152\n",
      "Validataion: numNeighbors=3, acc=0.546600, TPR=0.111700, TNR=0.981500, MSE=0.453400\n",
      "Training: numNeighbors=4, acc=0.994214, TPR=0.995758, TNR=0.991285, MSE=0.005786\n",
      "Validataion: numNeighbors=4, acc=0.539600, TPR=0.095500, TNR=0.983700, MSE=0.460400\n",
      "Training: numNeighbors=5, acc=0.994162, TPR=0.997521, TNR=0.987791, MSE=0.005838\n",
      "Validataion: numNeighbors=5, acc=0.546450, TPR=0.111900, TNR=0.981000, MSE=0.453550\n",
      "Training: numNeighbors=6, acc=0.993938, TPR=0.996400, TNR=0.989268, MSE=0.006062\n",
      "Validataion: numNeighbors=6, acc=0.541550, TPR=0.101200, TNR=0.981900, MSE=0.458450\n",
      "Training: numNeighbors=7, acc=0.993883, TPR=0.997463, TNR=0.987092, MSE=0.006117\n",
      "Validataion: numNeighbors=7, acc=0.546350, TPR=0.112200, TNR=0.980500, MSE=0.453650\n",
      "Training: numNeighbors=8, acc=0.993769, TPR=0.996721, TNR=0.988170, MSE=0.006231\n",
      "Validataion: numNeighbors=8, acc=0.542550, TPR=0.103700, TNR=0.981400, MSE=0.457450\n",
      "Training: numNeighbors=9, acc=0.993755, TPR=0.997463, TNR=0.986722, MSE=0.006245\n",
      "Validataion: numNeighbors=9, acc=0.546350, TPR=0.112300, TNR=0.980400, MSE=0.453650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.54665, 0.1125, 0.9808, 0.45335, 100168, 10000, 5),\n",
       " (0.5466, 0.1117, 0.9815, 0.4534, 100168, 10000, 5),\n",
       " (0.54645, 0.1119, 0.981, 0.45355, 100168, 10000, 5),\n",
       " (0.54635, 0.1123, 0.9804, 0.45365, 100168, 10000, 5),\n",
       " (0.54635, 0.1122, 0.9805, 0.45365, 100168, 10000, 5),\n",
       " (0.54255, 0.1037, 0.9814, 0.45745, 100168, 10000, 5),\n",
       " (0.54155, 0.1012, 0.9819, 0.45845, 100168, 10000, 5),\n",
       " (0.5396, 0.0955, 0.9837, 0.4604, 100168, 10000, 5),\n",
       " (0.5348, 0.0847, 0.9849, 0.4652, 100168, 10000, 5)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN\n",
    "#Includes Another Similarity feature [simItem, simUser, new percentile]\n",
    "numNegativeExamples = [100168]\n",
    "predBookResult = []\n",
    "\n",
    "for numNeg in numNegativeExamples:\n",
    "    print(\"\\nRunning # Neg: %d\" % (numNeg) )\n",
    "    bookDataNeg, bookDataYNeg = getNegativeEntries(numNeg)\n",
    "    bookDataArt = bookDataTrain + bookDataNeg\n",
    "    bookDataYArt = bookDataYTrain + bookDataYNeg\n",
    "    print(\"# total training data: %d, # Neg: %d\" % (len(bookDataArt), len(bookDataNeg)) )    \n",
    "    \n",
    "    #for topK in range(4,13):\n",
    "    for topK in [5]:\n",
    "        print(\"\\nRunning Top K: %d\" % (topK))\n",
    "        \n",
    "        # Data to Features [simItem, simUser, percentile]\n",
    "        bookFeaturesArt = getClassificationData3(bookDataArt, topK)\n",
    "        bookFeaturesValid = getClassificationData3(bookDataValid, topK)\n",
    "        print(\"x[0]: min: %f, max %f\" % (min([x[0] for x in bookFeaturesArt]), max([x[0] for x in bookFeaturesArt])))\n",
    "        print(\"x[1]: min: %f, max %f\" % (min([x[1] for x in bookFeaturesArt]), max([x[1] for x in bookFeaturesArt])))\n",
    "        print(\"x[2]: min: %f, max %f\" % (min([x[2] for x in bookFeaturesArt]), max([x[2] for x in bookFeaturesArt])))\n",
    "        \n",
    "        # Feature Scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(bookFeaturesArt)\n",
    "        bookFeaturesArt = scaler.transform(bookFeaturesArt)\n",
    "        bookFeaturesValid = scaler.transform(bookFeaturesValid)\n",
    "        print(\"x[0]: min: %f, max %f\" % (min([x[0] for x in bookFeaturesArt]), max([x[0] for x in bookFeaturesArt])))\n",
    "        print(\"x[1]: min: %f, max %f\" % (min([x[1] for x in bookFeaturesArt]), max([x[1] for x in bookFeaturesArt])))\n",
    "        print(\"x[2]: min: %f, max %f\" % (min([x[2] for x in bookFeaturesArt]), max([x[2] for x in bookFeaturesArt])))\n",
    "        \n",
    "        for numNeighbors in range(1,10):\n",
    "            model = KNeighborsClassifier(n_neighbors=numNeighbors)\n",
    "            model.fit(bookFeaturesArt, bookDataYArt)\n",
    "\n",
    "            predBookDataYArt = model.predict(bookFeaturesArt)\n",
    "            mseTrain = MSE(predBookDataYArt, bookDataYArt)\n",
    "            predBookDataYValid = model.predict(bookFeaturesValid)\n",
    "            mseValid = MSE(predBookDataYValid, bookDataYValid)\n",
    "\n",
    "            #writeOutClassificationPredWithFunction(model, \"numNeg_\"+str(numNeg)+\"_C_\"+str(cVal)+\"_topK_\"+str(topK), getClassificationData3, topK)\n",
    "\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYArt, bookDataYArt)\n",
    "            print(\"Training: numNeighbors=%d, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (numNeighbors, acc, TPR, TNR, mseTrain) )\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "            print(\"Validataion: numNeighbors=%d, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (numNeighbors, acc, TPR, TNR, mseValid) )\n",
    "            predBookResult.append((acc, TPR, TNR, mseValid, numNeg, cVal, topK))\n",
    "    \n",
    "predBookResult.sort(reverse = True)\n",
    "predBookResult[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running # Neg: 100168\n",
      "# total training data: 310168, # Neg: 100168\n",
      "\n",
      "Running Top K: 1\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.19047619047619047\n",
      "0.36363636363636365\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.858538, TPR=0.986215, TNR=0.626752, MSE=0.141462\n",
      "Validataion: C=0.010000, acc=0.642350, TPR=0.727100, TNR=0.557600, MSE=0.357650\n",
      "Training: C=0.100000, acc=0.920408, TPR=0.969905, TNR=0.830550, MSE=0.079592\n",
      "Validataion: C=0.100000, acc=0.668750, TPR=0.483500, TNR=0.854000, MSE=0.331250\n",
      "Training: C=1.000000, acc=0.930925, TPR=0.961570, TNR=0.875290, MSE=0.069075\n",
      "Validataion: C=1.000000, acc=0.637250, TPR=0.386400, TNR=0.888100, MSE=0.362750\n",
      "Training: C=10.000000, acc=0.932214, TPR=0.959160, TNR=0.883296, MSE=0.067786\n",
      "Validataion: C=10.000000, acc=0.630400, TPR=0.366700, TNR=0.894100, MSE=0.369600\n",
      "Training: C=100.000000, acc=0.932472, TPR=0.958875, TNR=0.884540, MSE=0.067528\n",
      "Validataion: C=100.000000, acc=0.630400, TPR=0.365100, TNR=0.895700, MSE=0.369600\n",
      "Training: C=1000.000000, acc=0.932511, TPR=0.958825, TNR=0.884740, MSE=0.067489\n",
      "Validataion: C=1000.000000, acc=0.630400, TPR=0.364700, TNR=0.896100, MSE=0.369600\n",
      "Training: C=10000.000000, acc=0.932508, TPR=0.958825, TNR=0.884731, MSE=0.067492\n",
      "Validataion: C=10000.000000, acc=0.630400, TPR=0.364700, TNR=0.896100, MSE=0.369600\n",
      "\n",
      "Running Top K: 2\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.14583333333333331\n",
      "0.24064171122994654\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.870167, TPR=0.985650, TNR=0.660518, MSE=0.129833\n",
      "Validataion: C=0.010000, acc=0.638100, TPR=0.713400, TNR=0.562800, MSE=0.361900\n",
      "Training: C=0.100000, acc=0.930847, TPR=0.972695, TNR=0.854876, MSE=0.069153\n",
      "Validataion: C=0.100000, acc=0.667200, TPR=0.468000, TNR=0.866400, MSE=0.332800\n",
      "Training: C=1.000000, acc=0.943769, TPR=0.965710, TNR=0.903938, MSE=0.056231\n",
      "Validataion: C=1.000000, acc=0.626650, TPR=0.353300, TNR=0.900000, MSE=0.373350\n",
      "Training: C=10.000000, acc=0.946394, TPR=0.964090, TNR=0.914267, MSE=0.053606\n",
      "Validataion: C=10.000000, acc=0.618750, TPR=0.329500, TNR=0.908000, MSE=0.381250\n",
      "Training: C=100.000000, acc=0.946716, TPR=0.963800, TNR=0.915701, MSE=0.053284\n",
      "Validataion: C=100.000000, acc=0.616900, TPR=0.324800, TNR=0.909000, MSE=0.383100\n",
      "Training: C=1000.000000, acc=0.946777, TPR=0.963790, TNR=0.915892, MSE=0.053223\n",
      "Validataion: C=1000.000000, acc=0.616750, TPR=0.324500, TNR=0.909000, MSE=0.383250\n",
      "Training: C=10000.000000, acc=0.946768, TPR=0.963790, TNR=0.915865, MSE=0.053232\n",
      "Validataion: C=10000.000000, acc=0.616600, TPR=0.324500, TNR=0.908700, MSE=0.383400\n",
      "\n",
      "Running Top K: 3\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.13227513227513227\n",
      "0.19158249158249158\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.880784, TPR=0.984360, TNR=0.692751, MSE=0.119216\n",
      "Validataion: C=0.010000, acc=0.646800, TPR=0.687300, TNR=0.606300, MSE=0.353200\n",
      "Training: C=0.100000, acc=0.936064, TPR=0.972570, TNR=0.869790, MSE=0.063936\n",
      "Validataion: C=0.100000, acc=0.664850, TPR=0.454700, TNR=0.875000, MSE=0.335150\n",
      "Training: C=1.000000, acc=0.948621, TPR=0.966265, TNR=0.916591, MSE=0.051379\n",
      "Validataion: C=1.000000, acc=0.623950, TPR=0.336300, TNR=0.911600, MSE=0.376050\n",
      "Training: C=10.000000, acc=0.951301, TPR=0.964870, TNR=0.926667, MSE=0.048699\n",
      "Validataion: C=10.000000, acc=0.612200, TPR=0.311100, TNR=0.913300, MSE=0.387800\n",
      "Training: C=100.000000, acc=0.951729, TPR=0.964675, TNR=0.928228, MSE=0.048271\n",
      "Validataion: C=100.000000, acc=0.610550, TPR=0.307500, TNR=0.913600, MSE=0.389450\n",
      "Training: C=1000.000000, acc=0.951778, TPR=0.964650, TNR=0.928409, MSE=0.048222\n",
      "Validataion: C=1000.000000, acc=0.610450, TPR=0.307000, TNR=0.913900, MSE=0.389550\n",
      "Training: C=10000.000000, acc=0.951771, TPR=0.964655, TNR=0.928382, MSE=0.048229\n",
      "Validataion: C=10000.000000, acc=0.610400, TPR=0.307100, TNR=0.913700, MSE=0.389600\n",
      "\n",
      "Running Top K: 4\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.12420634920634921\n",
      "0.17045454545454547\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.888664, TPR=0.983215, TNR=0.717014, MSE=0.111336\n",
      "Validataion: C=0.010000, acc=0.657950, TPR=0.664400, TNR=0.651500, MSE=0.342050\n",
      "Training: C=0.100000, acc=0.940284, TPR=0.971940, TNR=0.882815, MSE=0.059716\n",
      "Validataion: C=0.100000, acc=0.666350, TPR=0.439700, TNR=0.893000, MSE=0.333650\n",
      "Training: C=1.000000, acc=0.951165, TPR=0.965985, TNR=0.924261, MSE=0.048835\n",
      "Validataion: C=1.000000, acc=0.618750, TPR=0.323800, TNR=0.913700, MSE=0.381250\n",
      "Training: C=10.000000, acc=0.953867, TPR=0.964700, TNR=0.934200, MSE=0.046133\n",
      "Validataion: C=10.000000, acc=0.605400, TPR=0.298000, TNR=0.912800, MSE=0.394600\n",
      "Training: C=100.000000, acc=0.954122, TPR=0.964575, TNR=0.935145, MSE=0.045878\n",
      "Validataion: C=100.000000, acc=0.602350, TPR=0.295400, TNR=0.909300, MSE=0.397650\n",
      "Training: C=1000.000000, acc=0.954144, TPR=0.964565, TNR=0.935226, MSE=0.045856\n",
      "Validataion: C=1000.000000, acc=0.602150, TPR=0.295200, TNR=0.909100, MSE=0.397850\n",
      "Training: C=10000.000000, acc=0.954157, TPR=0.964565, TNR=0.935263, MSE=0.045843\n",
      "Validataion: C=10000.000000, acc=0.602150, TPR=0.295200, TNR=0.909100, MSE=0.397850\n",
      "\n",
      "Running Top K: 5\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.11754689754689754\n",
      "0.1638095238095238\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.893664, TPR=0.982345, TNR=0.732672, MSE=0.106336\n",
      "Validataion: C=0.010000, acc=0.666450, TPR=0.647000, TNR=0.685900, MSE=0.333550\n",
      "Training: C=0.100000, acc=0.944211, TPR=0.971035, TNR=0.895514, MSE=0.055789\n",
      "Validataion: C=0.100000, acc=0.664350, TPR=0.421000, TNR=0.907700, MSE=0.335650\n",
      "Training: C=1.000000, acc=0.953474, TPR=0.965610, TNR=0.931441, MSE=0.046526\n",
      "Validataion: C=1.000000, acc=0.617850, TPR=0.313500, TNR=0.922200, MSE=0.382150\n",
      "Training: C=10.000000, acc=0.955595, TPR=0.964440, TNR=0.939538, MSE=0.044405\n",
      "Validataion: C=10.000000, acc=0.604300, TPR=0.290000, TNR=0.918600, MSE=0.395700\n",
      "Training: C=100.000000, acc=0.955840, TPR=0.964335, TNR=0.940418, MSE=0.044160\n",
      "Validataion: C=100.000000, acc=0.602550, TPR=0.288100, TNR=0.917000, MSE=0.397450\n",
      "Training: C=1000.000000, acc=0.955801, TPR=0.964330, TNR=0.940318, MSE=0.044199\n",
      "Validataion: C=1000.000000, acc=0.601600, TPR=0.288000, TNR=0.915200, MSE=0.398400\n",
      "Training: C=10000.000000, acc=0.955814, TPR=0.964335, TNR=0.940346, MSE=0.044186\n",
      "Validataion: C=10000.000000, acc=0.601650, TPR=0.288100, TNR=0.915200, MSE=0.398350\n",
      "\n",
      "Running Top K: 6\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.1131072631072631\n",
      "0.15873015873015872\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.896027, TPR=0.981800, TNR=0.740315, MSE=0.103973\n",
      "Validataion: C=0.010000, acc=0.671400, TPR=0.636100, TNR=0.706700, MSE=0.328600\n",
      "Training: C=0.100000, acc=0.947703, TPR=0.969930, TNR=0.907351, MSE=0.052297\n",
      "Validataion: C=0.100000, acc=0.660300, TPR=0.398900, TNR=0.921700, MSE=0.339700\n",
      "Training: C=1.000000, acc=0.955385, TPR=0.964805, TNR=0.938285, MSE=0.044615\n",
      "Validataion: C=1.000000, acc=0.614700, TPR=0.296800, TNR=0.932600, MSE=0.385300\n",
      "Training: C=10.000000, acc=0.957043, TPR=0.963660, TNR=0.945029, MSE=0.042957\n",
      "Validataion: C=10.000000, acc=0.601350, TPR=0.273900, TNR=0.928800, MSE=0.398650\n",
      "Training: C=100.000000, acc=0.957272, TPR=0.963835, TNR=0.945356, MSE=0.042728\n",
      "Validataion: C=100.000000, acc=0.599850, TPR=0.277400, TNR=0.922300, MSE=0.400150\n",
      "Training: C=1000.000000, acc=0.957255, TPR=0.963835, TNR=0.945311, MSE=0.042745\n",
      "Validataion: C=1000.000000, acc=0.599800, TPR=0.277400, TNR=0.922200, MSE=0.400200\n",
      "Training: C=10000.000000, acc=0.957259, TPR=0.963840, TNR=0.945311, MSE=0.042741\n",
      "Validataion: C=10000.000000, acc=0.599700, TPR=0.277500, TNR=0.921900, MSE=0.400300\n",
      "\n",
      "Running Top K: 7\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10993609565038136\n",
      "0.15391156462585034\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.897223, TPR=0.981525, TNR=0.744182, MSE=0.102777\n",
      "Validataion: C=0.010000, acc=0.675400, TPR=0.630600, TNR=0.720200, MSE=0.324600\n",
      "Training: C=0.100000, acc=0.950772, TPR=0.969005, TNR=0.917671, MSE=0.049228\n",
      "Validataion: C=0.100000, acc=0.658950, TPR=0.380200, TNR=0.937700, MSE=0.341050\n",
      "Training: C=1.000000, acc=0.957317, TPR=0.964035, TNR=0.945120, MSE=0.042683\n",
      "Validataion: C=1.000000, acc=0.613600, TPR=0.281100, TNR=0.946100, MSE=0.386400\n",
      "Training: C=10.000000, acc=0.958516, TPR=0.963075, TNR=0.950240, MSE=0.041484\n",
      "Validataion: C=10.000000, acc=0.601200, TPR=0.261800, TNR=0.940600, MSE=0.398800\n",
      "Training: C=100.000000, acc=0.958532, TPR=0.963260, TNR=0.949949, MSE=0.041468\n",
      "Validataion: C=100.000000, acc=0.600100, TPR=0.265600, TNR=0.934600, MSE=0.399900\n",
      "Training: C=1000.000000, acc=0.958539, TPR=0.963315, TNR=0.949867, MSE=0.041461\n",
      "Validataion: C=1000.000000, acc=0.600350, TPR=0.266700, TNR=0.934000, MSE=0.399650\n",
      "Training: C=10000.000000, acc=0.958548, TPR=0.963315, TNR=0.949895, MSE=0.041452\n",
      "Validataion: C=10000.000000, acc=0.600350, TPR=0.266700, TNR=0.934000, MSE=0.399650\n",
      "\n",
      "Running Top K: 8\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10661075036075036\n",
      "0.14856150793650794\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.897140, TPR=0.981250, TNR=0.744445, MSE=0.102860\n",
      "Validataion: C=0.010000, acc=0.675950, TPR=0.625100, TNR=0.726800, MSE=0.324050\n",
      "Training: C=0.100000, acc=0.953261, TPR=0.968025, TNR=0.926458, MSE=0.046739\n",
      "Validataion: C=0.100000, acc=0.656650, TPR=0.360600, TNR=0.952700, MSE=0.343350\n",
      "Training: C=1.000000, acc=0.959129, TPR=0.963375, TNR=0.951420, MSE=0.040871\n",
      "Validataion: C=1.000000, acc=0.612800, TPR=0.267700, TNR=0.957900, MSE=0.387200\n",
      "Training: C=10.000000, acc=0.959825, TPR=0.962575, TNR=0.954833, MSE=0.040175\n",
      "Validataion: C=10.000000, acc=0.600900, TPR=0.251800, TNR=0.950000, MSE=0.399100\n",
      "Training: C=100.000000, acc=0.959831, TPR=0.962715, TNR=0.954597, MSE=0.040169\n",
      "Validataion: C=100.000000, acc=0.599800, TPR=0.254500, TNR=0.945100, MSE=0.400200\n",
      "Training: C=1000.000000, acc=0.959815, TPR=0.962755, TNR=0.954479, MSE=0.040185\n",
      "Validataion: C=1000.000000, acc=0.599700, TPR=0.255300, TNR=0.944100, MSE=0.400300\n",
      "Training: C=10000.000000, acc=0.959802, TPR=0.962755, TNR=0.954442, MSE=0.040198\n",
      "Validataion: C=10000.000000, acc=0.599650, TPR=0.255300, TNR=0.944000, MSE=0.400350\n",
      "\n",
      "Running Top K: 9\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10365400032066699\n",
      "0.14375058015408892\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.896095, TPR=0.981235, TNR=0.741531, MSE=0.103905\n",
      "Validataion: C=0.010000, acc=0.676100, TPR=0.624800, TNR=0.727400, MSE=0.323900\n",
      "Training: C=0.100000, acc=0.955140, TPR=0.967055, TNR=0.933511, MSE=0.044860\n",
      "Validataion: C=0.100000, acc=0.651650, TPR=0.341200, TNR=0.962100, MSE=0.348350\n",
      "Training: C=1.000000, acc=0.960421, TPR=0.962610, TNR=0.956448, MSE=0.039579\n",
      "Validataion: C=1.000000, acc=0.608150, TPR=0.252400, TNR=0.963900, MSE=0.391850\n",
      "Training: C=10.000000, acc=0.960934, TPR=0.961950, TNR=0.959090, MSE=0.039066\n",
      "Validataion: C=10.000000, acc=0.598000, TPR=0.239300, TNR=0.956700, MSE=0.402000\n",
      "Training: C=100.000000, acc=0.960915, TPR=0.962145, TNR=0.958681, MSE=0.039085\n",
      "Validataion: C=100.000000, acc=0.598150, TPR=0.243000, TNR=0.953300, MSE=0.401850\n",
      "Training: C=1000.000000, acc=0.960882, TPR=0.962215, TNR=0.958463, MSE=0.039118\n",
      "Validataion: C=1000.000000, acc=0.598000, TPR=0.244400, TNR=0.951600, MSE=0.402000\n",
      "Training: C=10000.000000, acc=0.960879, TPR=0.962230, TNR=0.958427, MSE=0.039121\n",
      "Validataion: C=10000.000000, acc=0.597950, TPR=0.244700, TNR=0.951200, MSE=0.402050\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.894883, TPR=0.981320, TNR=0.737964, MSE=0.105117\n",
      "Validataion: C=0.010000, acc=0.675750, TPR=0.626500, TNR=0.725000, MSE=0.324250\n",
      "Training: C=0.100000, acc=0.956611, TPR=0.966365, TNR=0.938902, MSE=0.043389\n",
      "Validataion: C=0.100000, acc=0.647600, TPR=0.327400, TNR=0.967800, MSE=0.352400\n",
      "Training: C=1.000000, acc=0.961569, TPR=0.961965, TNR=0.960851, MSE=0.038431\n",
      "Validataion: C=1.000000, acc=0.604400, TPR=0.239500, TNR=0.969300, MSE=0.395600\n",
      "Training: C=10.000000, acc=0.961769, TPR=0.961290, TNR=0.962639, MSE=0.038231\n",
      "Validataion: C=10.000000, acc=0.594400, TPR=0.225900, TNR=0.962900, MSE=0.405600\n",
      "Training: C=100.000000, acc=0.961830, TPR=0.961565, TNR=0.962312, MSE=0.038170\n",
      "Validataion: C=100.000000, acc=0.594800, TPR=0.231400, TNR=0.958200, MSE=0.405200\n",
      "Training: C=1000.000000, acc=0.961814, TPR=0.961610, TNR=0.962185, MSE=0.038186\n",
      "Validataion: C=1000.000000, acc=0.594850, TPR=0.232300, TNR=0.957400, MSE=0.405150\n",
      "Training: C=10000.000000, acc=0.961814, TPR=0.961610, TNR=0.962185, MSE=0.038186\n",
      "Validataion: C=10000.000000, acc=0.594750, TPR=0.232300, TNR=0.957200, MSE=0.405250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.6761, 0.6248, 0.7274, 0.3239, 100168, 0.01, 9),\n",
       " (0.67595, 0.6251, 0.7268, 0.32405, 100168, 0.01, 8),\n",
       " (0.67575, 0.6265, 0.725, 0.32425, 100168, 0.01, 10),\n",
       " (0.6754, 0.6306, 0.7202, 0.3246, 100168, 0.01, 7),\n",
       " (0.6714, 0.6361, 0.7067, 0.3286, 100168, 0.01, 6),\n",
       " (0.66875, 0.4835, 0.854, 0.33125, 100168, 0.1, 1),\n",
       " (0.6672, 0.468, 0.8664, 0.3328, 100168, 0.1, 2),\n",
       " (0.66645, 0.647, 0.6859, 0.33355, 100168, 0.01, 5),\n",
       " (0.66635, 0.4397, 0.893, 0.33365, 100168, 0.1, 4),\n",
       " (0.66485, 0.4547, 0.875, 0.33515, 100168, 0.1, 3)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Includes Another Similarity feature [simItem, simUser, new percentile]\n",
    "numNegativeExamples = [100168]\n",
    "predBookResult = []\n",
    "\n",
    "for numNeg in numNegativeExamples:\n",
    "    print(\"\\nRunning # Neg: %d\" % (numNeg) )\n",
    "    bookDataNeg, bookDataYNeg = getNegativeEntries(numNeg)\n",
    "    bookDataArt = bookDataTrain + bookDataValid + bookDataNeg\n",
    "    bookDataYArt = bookDataYTrain + bookDataYValid + bookDataYNeg\n",
    "    print(\"# total training data: %d, # Neg: %d\" % (len(bookDataArt), len(bookDataNeg)) )\n",
    "    \n",
    "    for topK in range(1,11):\n",
    "        print(\"\\nRunning Top K: %d\" % (topK))\n",
    "        \n",
    "        # Data to Features [simItem, simUser, percentile]\n",
    "        bookFeaturesArt = getClassificationData3(bookDataArt, topK)\n",
    "        bookFeaturesValid = getClassificationData3(bookDataValid, topK)\n",
    "        print(min([x[0] for x in bookFeaturesArt]))\n",
    "        print(min([x[1] for x in bookFeaturesArt]))\n",
    "        print(min([x[2] for x in bookFeaturesArt]))\n",
    "        print(max([x[0] for x in bookFeaturesArt]))\n",
    "        print(max([x[1] for x in bookFeaturesArt]))\n",
    "        print(max([x[2] for x in bookFeaturesArt]))\n",
    "\n",
    "        for cExp in range(-3,5):\n",
    "            cVal = pow(10,cExp)\n",
    "            model = linear_model.LogisticRegression(C=cVal, solver=\"liblinear\")\n",
    "            model.fit(bookFeaturesArt, bookDataYArt)\n",
    "\n",
    "            predBookDataYArt = model.predict(bookFeaturesArt)\n",
    "            mseTrain = MSE(predBookDataYArt, bookDataYArt)\n",
    "            predBookDataYValid = model.predict(bookFeaturesValid)\n",
    "            mseValid = MSE(predBookDataYValid, bookDataYValid)\n",
    "\n",
    "            writeOutClassificationPredWithFunction(model, \"numNeg_\"+str(numNeg)+\"_C_\"+str(cVal)+\"_topK_\"+str(topK), getClassificationData3, topK)\n",
    "\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYArt, bookDataYArt)\n",
    "            print(\"Training: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseTrain) )\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "            print(\"Validataion: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseValid) )\n",
    "            predBookResult.append((acc, TPR, TNR, mseValid, numNeg, cVal, topK))\n",
    "    \n",
    "predBookResult.sort(reverse = True)\n",
    "predBookResult[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running # Neg: 100168\n",
      "# total training data: 310168, # Neg: 100168\n",
      "\n",
      "Running Top K: 10\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.10098090798090797\n",
      "0.1404040404040404\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.895605, TPR=0.981325, TNR=0.739988, MSE=0.104395\n",
      "Validataion: C=0.010000, acc=0.675600, TPR=0.626600, TNR=0.724600, MSE=0.324400\n",
      "Training: C=0.100000, acc=0.956814, TPR=0.966380, TNR=0.939447, MSE=0.043186\n",
      "Validataion: C=0.100000, acc=0.647650, TPR=0.327700, TNR=0.967600, MSE=0.352350\n",
      "Training: C=1.000000, acc=0.961708, TPR=0.962010, TNR=0.961159, MSE=0.038292\n",
      "Validataion: C=1.000000, acc=0.604850, TPR=0.240400, TNR=0.969300, MSE=0.395150\n",
      "Training: C=10.000000, acc=0.962024, TPR=0.961350, TNR=0.963247, MSE=0.037976\n",
      "Validataion: C=10.000000, acc=0.595000, TPR=0.227100, TNR=0.962900, MSE=0.405000\n",
      "Training: C=100.000000, acc=0.962033, TPR=0.961605, TNR=0.962811, MSE=0.037967\n",
      "Validataion: C=100.000000, acc=0.595150, TPR=0.232200, TNR=0.958100, MSE=0.404850\n",
      "Training: C=1000.000000, acc=0.962088, TPR=0.961655, TNR=0.962875, MSE=0.037912\n",
      "Validataion: C=1000.000000, acc=0.595400, TPR=0.233200, TNR=0.957600, MSE=0.404600\n",
      "Training: C=10000.000000, acc=0.962079, TPR=0.961655, TNR=0.962848, MSE=0.037921\n",
      "Validataion: C=10000.000000, acc=0.595400, TPR=0.233200, TNR=0.957600, MSE=0.404600\n",
      "\n",
      "Running Top K: 11\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09829433193069556\n",
      "0.1367309458218549\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.894273, TPR=0.981340, TNR=0.736212, MSE=0.105727\n",
      "Validataion: C=0.010000, acc=0.672400, TPR=0.626900, TNR=0.717900, MSE=0.327600\n",
      "Training: C=0.100000, acc=0.957910, TPR=0.965700, TNR=0.943768, MSE=0.042090\n",
      "Validataion: C=0.100000, acc=0.644400, TPR=0.314100, TNR=0.974700, MSE=0.355600\n",
      "Training: C=1.000000, acc=0.962652, TPR=0.961310, TNR=0.965090, MSE=0.037348\n",
      "Validataion: C=1.000000, acc=0.601300, TPR=0.226300, TNR=0.976300, MSE=0.398700\n",
      "Training: C=10.000000, acc=0.962927, TPR=0.960805, TNR=0.966778, MSE=0.037073\n",
      "Validataion: C=10.000000, acc=0.591500, TPR=0.216200, TNR=0.966800, MSE=0.408500\n",
      "Training: C=100.000000, acc=0.962907, TPR=0.961100, TNR=0.966188, MSE=0.037093\n",
      "Validataion: C=100.000000, acc=0.592500, TPR=0.222000, TNR=0.963000, MSE=0.407500\n",
      "Training: C=1000.000000, acc=0.962914, TPR=0.961200, TNR=0.966025, MSE=0.037086\n",
      "Validataion: C=1000.000000, acc=0.593100, TPR=0.224000, TNR=0.962200, MSE=0.406900\n",
      "Training: C=10000.000000, acc=0.962910, TPR=0.961200, TNR=0.966016, MSE=0.037090\n",
      "Validataion: C=10000.000000, acc=0.593100, TPR=0.224000, TNR=0.962200, MSE=0.406900\n",
      "\n",
      "Running Top K: 12\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09605551855551855\n",
      "0.13367003367003366\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.892503, TPR=0.981425, TNR=0.731074, MSE=0.107497\n",
      "Validataion: C=0.010000, acc=0.668300, TPR=0.628600, TNR=0.708000, MSE=0.331700\n",
      "Training: C=0.100000, acc=0.958903, TPR=0.965115, TNR=0.947625, MSE=0.041097\n",
      "Validataion: C=0.100000, acc=0.640950, TPR=0.302400, TNR=0.979500, MSE=0.359050\n",
      "Training: C=1.000000, acc=0.963475, TPR=0.960740, TNR=0.968439, MSE=0.036525\n",
      "Validataion: C=1.000000, acc=0.597650, TPR=0.214900, TNR=0.980400, MSE=0.402350\n",
      "Training: C=10.000000, acc=0.963633, TPR=0.960240, TNR=0.969792, MSE=0.036367\n",
      "Validataion: C=10.000000, acc=0.589200, TPR=0.204800, TNR=0.973600, MSE=0.410800\n",
      "Training: C=100.000000, acc=0.963649, TPR=0.960565, TNR=0.969247, MSE=0.036351\n",
      "Validataion: C=100.000000, acc=0.589400, TPR=0.211300, TNR=0.967500, MSE=0.410600\n",
      "Training: C=1000.000000, acc=0.963642, TPR=0.960655, TNR=0.969065, MSE=0.036358\n",
      "Validataion: C=1000.000000, acc=0.589950, TPR=0.213100, TNR=0.966800, MSE=0.410050\n",
      "Training: C=10000.000000, acc=0.963629, TPR=0.960670, TNR=0.969002, MSE=0.036371\n",
      "Validataion: C=10000.000000, acc=0.589900, TPR=0.213400, TNR=0.966400, MSE=0.410100\n",
      "\n",
      "Running Top K: 13\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09379483764099149\n",
      "0.13157724628312864\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.890579, TPR=0.981510, TNR=0.725501, MSE=0.109421\n",
      "Validataion: C=0.010000, acc=0.662800, TPR=0.630300, TNR=0.695300, MSE=0.337200\n",
      "Training: C=0.100000, acc=0.959670, TPR=0.964630, TNR=0.950666, MSE=0.040330\n",
      "Validataion: C=0.100000, acc=0.638600, TPR=0.292700, TNR=0.984500, MSE=0.361400\n",
      "Training: C=1.000000, acc=0.964139, TPR=0.960230, TNR=0.971235, MSE=0.035861\n",
      "Validataion: C=1.000000, acc=0.595000, TPR=0.204700, TNR=0.985300, MSE=0.405000\n",
      "Training: C=10.000000, acc=0.964248, TPR=0.959745, TNR=0.972424, MSE=0.035752\n",
      "Validataion: C=10.000000, acc=0.586550, TPR=0.194900, TNR=0.978200, MSE=0.413450\n",
      "Training: C=100.000000, acc=0.964226, TPR=0.960040, TNR=0.971825, MSE=0.035774\n",
      "Validataion: C=100.000000, acc=0.586550, TPR=0.200800, TNR=0.972300, MSE=0.413450\n",
      "Training: C=1000.000000, acc=0.964203, TPR=0.960130, TNR=0.971598, MSE=0.035797\n",
      "Validataion: C=1000.000000, acc=0.587100, TPR=0.202600, TNR=0.971600, MSE=0.412900\n",
      "Training: C=10000.000000, acc=0.964184, TPR=0.960135, TNR=0.971534, MSE=0.035816\n",
      "Validataion: C=10000.000000, acc=0.586950, TPR=0.202700, TNR=0.971200, MSE=0.413050\n",
      "\n",
      "Running Top K: 14\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.09155949209520638\n",
      "0.13011537948512739\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.888622, TPR=0.981635, TNR=0.719764, MSE=0.111378\n",
      "Validataion: C=0.010000, acc=0.656000, TPR=0.632800, TNR=0.679200, MSE=0.344000\n",
      "Training: C=0.100000, acc=0.960183, TPR=0.964210, TNR=0.952872, MSE=0.039817\n",
      "Validataion: C=0.100000, acc=0.636200, TPR=0.284300, TNR=0.988100, MSE=0.363800\n",
      "Training: C=1.000000, acc=0.964687, TPR=0.959740, TNR=0.973667, MSE=0.035313\n",
      "Validataion: C=1.000000, acc=0.591600, TPR=0.194900, TNR=0.988300, MSE=0.408400\n",
      "Training: C=10.000000, acc=0.964842, TPR=0.959275, TNR=0.974947, MSE=0.035158\n",
      "Validataion: C=10.000000, acc=0.584100, TPR=0.185500, TNR=0.982700, MSE=0.415900\n",
      "Training: C=100.000000, acc=0.964758, TPR=0.959700, TNR=0.973940, MSE=0.035242\n",
      "Validataion: C=100.000000, acc=0.585000, TPR=0.194000, TNR=0.976000, MSE=0.415000\n",
      "Training: C=1000.000000, acc=0.964610, TPR=0.959745, TNR=0.973441, MSE=0.035390\n",
      "Validataion: C=1000.000000, acc=0.584350, TPR=0.194900, TNR=0.973800, MSE=0.415650\n",
      "Training: C=10000.000000, acc=0.964610, TPR=0.959750, TNR=0.973431, MSE=0.035390\n",
      "Validataion: C=10000.000000, acc=0.584450, TPR=0.195000, TNR=0.973900, MSE=0.415550\n",
      "\n",
      "Running Top K: 15\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.08962219262219262\n",
      "0.12884842826019297\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.886339, TPR=0.981815, TNR=0.713011, MSE=0.113661\n",
      "Validataion: C=0.010000, acc=0.648750, TPR=0.636400, TNR=0.661100, MSE=0.351250\n",
      "Training: C=0.100000, acc=0.960592, TPR=0.963805, TNR=0.954760, MSE=0.039408\n",
      "Validataion: C=0.100000, acc=0.633700, TPR=0.276200, TNR=0.991200, MSE=0.366300\n",
      "Training: C=1.000000, acc=0.965122, TPR=0.959360, TNR=0.975583, MSE=0.034878\n",
      "Validataion: C=1.000000, acc=0.589400, TPR=0.187300, TNR=0.991500, MSE=0.410600\n",
      "Training: C=10.000000, acc=0.965225, TPR=0.958915, TNR=0.976681, MSE=0.034775\n",
      "Validataion: C=10.000000, acc=0.581850, TPR=0.178300, TNR=0.985400, MSE=0.418150\n",
      "Training: C=100.000000, acc=0.965109, TPR=0.959255, TNR=0.975737, MSE=0.034891\n",
      "Validataion: C=100.000000, acc=0.582550, TPR=0.185100, TNR=0.980000, MSE=0.417450\n",
      "Training: C=1000.000000, acc=0.965064, TPR=0.959375, TNR=0.975392, MSE=0.034936\n",
      "Validataion: C=1000.000000, acc=0.582550, TPR=0.187500, TNR=0.977600, MSE=0.417450\n",
      "Training: C=10000.000000, acc=0.965013, TPR=0.959375, TNR=0.975247, MSE=0.034987\n",
      "Validataion: C=10000.000000, acc=0.582050, TPR=0.187500, TNR=0.976600, MSE=0.417950\n",
      "\n",
      "Running Top K: 16\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.08769727617154088\n",
      "0.12773984593837534\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.884659, TPR=0.981955, TNR=0.708028, MSE=0.115341\n",
      "Validataion: C=0.010000, acc=0.639100, TPR=0.639200, TNR=0.639000, MSE=0.360900\n",
      "Training: C=0.100000, acc=0.960947, TPR=0.963475, TNR=0.956358, MSE=0.039053\n",
      "Validataion: C=0.100000, acc=0.631650, TPR=0.269600, TNR=0.993700, MSE=0.368350\n",
      "Training: C=1.000000, acc=0.965477, TPR=0.958975, TNR=0.977280, MSE=0.034523\n",
      "Validataion: C=1.000000, acc=0.586750, TPR=0.179600, TNR=0.993900, MSE=0.413250\n",
      "Training: C=10.000000, acc=0.965515, TPR=0.958480, TNR=0.978288, MSE=0.034485\n",
      "Validataion: C=10.000000, acc=0.578750, TPR=0.169600, TNR=0.987900, MSE=0.421250\n",
      "Training: C=100.000000, acc=0.965435, TPR=0.958875, TNR=0.977344, MSE=0.034565\n",
      "Validataion: C=100.000000, acc=0.579650, TPR=0.177500, TNR=0.981800, MSE=0.420350\n",
      "Training: C=1000.000000, acc=0.965383, TPR=0.958970, TNR=0.977026, MSE=0.034617\n",
      "Validataion: C=1000.000000, acc=0.580100, TPR=0.179400, TNR=0.980800, MSE=0.419900\n",
      "Training: C=10000.000000, acc=0.965387, TPR=0.958980, TNR=0.977017, MSE=0.034613\n",
      "Validataion: C=10000.000000, acc=0.579850, TPR=0.179600, TNR=0.980100, MSE=0.420150\n",
      "\n",
      "Running Top K: 17\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.08599882047978934\n",
      "0.12676168506618332\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.882622, TPR=0.982060, TNR=0.702100, MSE=0.117378\n",
      "Validataion: C=0.010000, acc=0.631100, TPR=0.641300, TNR=0.620900, MSE=0.368900\n",
      "Training: C=0.100000, acc=0.961121, TPR=0.963225, TNR=0.957302, MSE=0.038879\n",
      "Validataion: C=0.100000, acc=0.629650, TPR=0.264600, TNR=0.994700, MSE=0.370350\n",
      "Training: C=1.000000, acc=0.965799, TPR=0.958680, TNR=0.978723, MSE=0.034201\n",
      "Validataion: C=1.000000, acc=0.584200, TPR=0.173700, TNR=0.994700, MSE=0.415800\n",
      "Training: C=10.000000, acc=0.965844, TPR=0.958170, TNR=0.979776, MSE=0.034156\n",
      "Validataion: C=10.000000, acc=0.576750, TPR=0.163400, TNR=0.990100, MSE=0.423250\n",
      "Training: C=100.000000, acc=0.965664, TPR=0.958430, TNR=0.978796, MSE=0.034336\n",
      "Validataion: C=100.000000, acc=0.576200, TPR=0.168600, TNR=0.983800, MSE=0.423800\n",
      "Training: C=1000.000000, acc=0.965596, TPR=0.958565, TNR=0.978360, MSE=0.034404\n",
      "Validataion: C=1000.000000, acc=0.576550, TPR=0.171300, TNR=0.981800, MSE=0.423450\n",
      "Training: C=10000.000000, acc=0.965583, TPR=0.958570, TNR=0.978315, MSE=0.034417\n",
      "Validataion: C=10000.000000, acc=0.576600, TPR=0.171400, TNR=0.981800, MSE=0.423400\n",
      "\n",
      "Running Top K: 18\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.0844890820871213\n",
      "0.12589220873534598\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.880545, TPR=0.982185, TNR=0.696028, MSE=0.119455\n",
      "Validataion: C=0.010000, acc=0.620400, TPR=0.643800, TNR=0.597000, MSE=0.379600\n",
      "Training: C=0.100000, acc=0.961373, TPR=0.963095, TNR=0.958246, MSE=0.038627\n",
      "Validataion: C=0.100000, acc=0.629050, TPR=0.262000, TNR=0.996100, MSE=0.370950\n",
      "Training: C=1.000000, acc=0.965970, TPR=0.958355, TNR=0.979794, MSE=0.034030\n",
      "Validataion: C=1.000000, acc=0.581700, TPR=0.167200, TNR=0.996200, MSE=0.418300\n",
      "Training: C=10.000000, acc=0.966086, TPR=0.957915, TNR=0.980920, MSE=0.033914\n",
      "Validataion: C=10.000000, acc=0.575200, TPR=0.158300, TNR=0.992100, MSE=0.424800\n",
      "Training: C=100.000000, acc=0.965957, TPR=0.958155, TNR=0.980121, MSE=0.034043\n",
      "Validataion: C=100.000000, acc=0.574650, TPR=0.163100, TNR=0.986200, MSE=0.425350\n",
      "Training: C=1000.000000, acc=0.965831, TPR=0.958290, TNR=0.979522, MSE=0.034169\n",
      "Validataion: C=1000.000000, acc=0.574900, TPR=0.165800, TNR=0.984000, MSE=0.425100\n",
      "Training: C=10000.000000, acc=0.965793, TPR=0.958295, TNR=0.979404, MSE=0.034207\n",
      "Validataion: C=10000.000000, acc=0.574550, TPR=0.165900, TNR=0.983200, MSE=0.425450\n",
      "\n",
      "Running Top K: 19\n",
      "0\n",
      "0\n",
      "0.0\n",
      "0.08313826352526042\n",
      "0.1251142562288073\n",
      "1.0\n",
      "Training: C=0.001000, acc=0.644812, TPR=1.000000, TNR=0.000000, MSE=0.355188\n",
      "Validataion: C=0.001000, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.010000, acc=0.878395, TPR=0.982390, TNR=0.689601, MSE=0.121605\n",
      "Validataion: C=0.010000, acc=0.609500, TPR=0.647900, TNR=0.571100, MSE=0.390500\n",
      "Training: C=0.100000, acc=0.961492, TPR=0.962920, TNR=0.958899, MSE=0.038508\n",
      "Validataion: C=0.100000, acc=0.627550, TPR=0.258500, TNR=0.996600, MSE=0.372450\n",
      "Training: C=1.000000, acc=0.966073, TPR=0.958080, TNR=0.980584, MSE=0.033927\n",
      "Validataion: C=1.000000, acc=0.579150, TPR=0.161700, TNR=0.996600, MSE=0.420850\n",
      "Training: C=10.000000, acc=0.966247, TPR=0.957655, TNR=0.981846, MSE=0.033753\n",
      "Validataion: C=10.000000, acc=0.573450, TPR=0.153100, TNR=0.993800, MSE=0.426550\n",
      "Training: C=100.000000, acc=0.966089, TPR=0.957840, TNR=0.981065, MSE=0.033911\n",
      "Validataion: C=100.000000, acc=0.572400, TPR=0.156800, TNR=0.988000, MSE=0.427600\n",
      "Training: C=1000.000000, acc=0.965980, TPR=0.957945, TNR=0.980566, MSE=0.034020\n",
      "Validataion: C=1000.000000, acc=0.572500, TPR=0.158900, TNR=0.986100, MSE=0.427500\n",
      "Training: C=10000.000000, acc=0.965970, TPR=0.957965, TNR=0.980503, MSE=0.034030\n",
      "Validataion: C=10000.000000, acc=0.572650, TPR=0.159300, TNR=0.986000, MSE=0.427350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.6756, 0.6266, 0.7246, 0.3244, 100168, 0.01, 10),\n",
       " (0.6724, 0.6269, 0.7179, 0.3276, 100168, 0.01, 11),\n",
       " (0.6683, 0.6286, 0.708, 0.3317, 100168, 0.01, 12),\n",
       " (0.6628, 0.6303, 0.6953, 0.3372, 100168, 0.01, 13),\n",
       " (0.656, 0.6328, 0.6792, 0.344, 100168, 0.01, 14),\n",
       " (0.64875, 0.6364, 0.6611, 0.35125, 100168, 0.01, 15),\n",
       " (0.64765, 0.3277, 0.9676, 0.35235, 100168, 0.1, 10),\n",
       " (0.6444, 0.3141, 0.9747, 0.3556, 100168, 0.1, 11),\n",
       " (0.64095, 0.3024, 0.9795, 0.35905, 100168, 0.1, 12),\n",
       " (0.6391, 0.6392, 0.639, 0.3609, 100168, 0.01, 16)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Includes Another Similarity feature [simItem, simUser, new percentile]\n",
    "numNegativeExamples = [100168]\n",
    "predBookResult = []\n",
    "\n",
    "for numNeg in numNegativeExamples:\n",
    "    print(\"\\nRunning # Neg: %d\" % (numNeg) )\n",
    "    bookDataNeg, bookDataYNeg = getNegativeEntries(numNeg)\n",
    "    bookDataArt = bookDataTrain + bookDataValid + bookDataNeg\n",
    "    bookDataYArt = bookDataYTrain + bookDataYValid + bookDataYNeg\n",
    "    print(\"# total training data: %d, # Neg: %d\" % (len(bookDataArt), len(bookDataNeg)) )\n",
    "    \n",
    "    for topK in range(10,20):\n",
    "        print(\"\\nRunning Top K: %d\" % (topK))\n",
    "        \n",
    "        # Data to Features [simItem, simUser, percentile]\n",
    "        bookFeaturesArt = getClassificationData3(bookDataArt, topK)\n",
    "        bookFeaturesValid = getClassificationData3(bookDataValid, topK)\n",
    "        print(min([x[0] for x in bookFeaturesArt]))\n",
    "        print(min([x[1] for x in bookFeaturesArt]))\n",
    "        print(min([x[2] for x in bookFeaturesArt]))\n",
    "        print(max([x[0] for x in bookFeaturesArt]))\n",
    "        print(max([x[1] for x in bookFeaturesArt]))\n",
    "        print(max([x[2] for x in bookFeaturesArt]))\n",
    "\n",
    "        for cExp in range(-3,5):\n",
    "            cVal = pow(10,cExp)\n",
    "            model = linear_model.LogisticRegression(C=cVal, solver=\"liblinear\")\n",
    "            model.fit(bookFeaturesArt, bookDataYArt)\n",
    "\n",
    "            predBookDataYArt = model.predict(bookFeaturesArt)\n",
    "            mseTrain = MSE(predBookDataYArt, bookDataYArt)\n",
    "            predBookDataYValid = model.predict(bookFeaturesValid)\n",
    "            mseValid = MSE(predBookDataYValid, bookDataYValid)\n",
    "\n",
    "            writeOutClassificationPredWithFunction(model, \"numNeg_\"+str(numNeg)+\"_C_\"+str(cVal)+\"_topK_\"+str(topK), getClassificationData3, topK)\n",
    "\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYArt, bookDataYArt)\n",
    "            print(\"Training: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseTrain) )\n",
    "            acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "            print(\"Validataion: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseValid) )\n",
    "            predBookResult.append((acc, TPR, TNR, mseValid, numNeg, cVal, topK))\n",
    "    \n",
    "predBookResult.sort(reverse = True)\n",
    "predBookResult[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running # Neg: 70000\n",
      "# total trainging data: 280000, # Neg: 70000\n",
      "Training: C=0.000100, acc=0.714286, TPR=1.000000, TNR=0.000000, MSE=0.285714\n",
      "Validataion: C=0.000100, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.001000, acc=0.724993, TPR=0.999695, TNR=0.038238, MSE=0.275007\n",
      "Validataion: C=0.001000, acc=0.496950, TPR=0.993900, TNR=0.000000, MSE=0.503050\n",
      "Training: C=0.010000, acc=0.836514, TPR=0.991140, TNR=0.449950, MSE=0.163486\n",
      "Validataion: C=0.010000, acc=0.512250, TPR=0.832700, TNR=0.191800, MSE=0.487750\n",
      "Training: C=0.100000, acc=0.911889, TPR=0.980530, TNR=0.740287, MSE=0.088111\n",
      "Validataion: C=0.100000, acc=0.671350, TPR=0.622300, TNR=0.720400, MSE=0.328650\n",
      "Training: C=1.000000, acc=0.934425, TPR=0.971515, TNR=0.841700, MSE=0.065575\n",
      "Validataion: C=1.000000, acc=0.656550, TPR=0.473900, TNR=0.839200, MSE=0.343450\n",
      "Training: C=10.000000, acc=0.937775, TPR=0.969030, TNR=0.859638, MSE=0.062225\n",
      "Validataion: C=10.000000, acc=0.648700, TPR=0.438700, TNR=0.858700, MSE=0.351300\n",
      "Training: C=100.000000, acc=0.938132, TPR=0.968640, TNR=0.861862, MSE=0.061868\n",
      "Validataion: C=100.000000, acc=0.647150, TPR=0.433900, TNR=0.860400, MSE=0.352850\n",
      "Training: C=1000.000000, acc=0.938168, TPR=0.968615, TNR=0.862050, MSE=0.061832\n",
      "Validataion: C=1000.000000, acc=0.647000, TPR=0.433500, TNR=0.860500, MSE=0.353000\n",
      "Training: C=10000.000000, acc=0.938175, TPR=0.968620, TNR=0.862062, MSE=0.061825\n",
      "Validataion: C=10000.000000, acc=0.647050, TPR=0.433600, TNR=0.860500, MSE=0.352950\n",
      "\n",
      "Running # Neg: 75000\n",
      "# total trainging data: 285000, # Neg: 75000\n",
      "Training: C=0.000100, acc=0.701754, TPR=1.000000, TNR=0.000000, MSE=0.298246\n",
      "Validataion: C=0.000100, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.001000, acc=0.732344, TPR=0.998735, TNR=0.105541, MSE=0.267656\n",
      "Validataion: C=0.001000, acc=0.487650, TPR=0.974800, TNR=0.000500, MSE=0.512350\n",
      "Training: C=0.010000, acc=0.838119, TPR=0.989200, TNR=0.482635, MSE=0.161881\n",
      "Validataion: C=0.010000, acc=0.501050, TPR=0.810300, TNR=0.191800, MSE=0.498950\n",
      "Training: C=0.100000, acc=0.912519, TPR=0.979375, TNR=0.755212, MSE=0.087481\n",
      "Validataion: C=0.100000, acc=0.675200, TPR=0.603800, TNR=0.746600, MSE=0.324800\n",
      "Training: C=1.000000, acc=0.933579, TPR=0.970410, TNR=0.846918, MSE=0.066421\n",
      "Validataion: C=1.000000, acc=0.655100, TPR=0.461400, TNR=0.848800, MSE=0.344900\n",
      "Training: C=10.000000, acc=0.936993, TPR=0.967975, TNR=0.864094, MSE=0.063007\n",
      "Validataion: C=10.000000, acc=0.645000, TPR=0.427700, TNR=0.862300, MSE=0.355000\n",
      "Training: C=100.000000, acc=0.937453, TPR=0.967655, TNR=0.866388, MSE=0.062547\n",
      "Validataion: C=100.000000, acc=0.644200, TPR=0.423600, TNR=0.864800, MSE=0.355800\n",
      "Training: C=1000.000000, acc=0.937498, TPR=0.967650, TNR=0.866553, MSE=0.062502\n",
      "Validataion: C=1000.000000, acc=0.644100, TPR=0.423400, TNR=0.864800, MSE=0.355900\n",
      "Training: C=10000.000000, acc=0.937495, TPR=0.967645, TNR=0.866553, MSE=0.062505\n",
      "Validataion: C=10000.000000, acc=0.644050, TPR=0.423300, TNR=0.864800, MSE=0.355950\n",
      "\n",
      "Running # Neg: 80000\n",
      "# total trainging data: 290000, # Neg: 80000\n",
      "Training: C=0.000100, acc=0.689655, TPR=1.000000, TNR=0.000000, MSE=0.310345\n",
      "Validataion: C=0.000100, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.001000, acc=0.742617, TPR=0.996345, TNR=0.178778, MSE=0.257383\n",
      "Validataion: C=0.001000, acc=0.473950, TPR=0.947100, TNR=0.000800, MSE=0.526050\n",
      "Training: C=0.010000, acc=0.839603, TPR=0.986865, TNR=0.512356, MSE=0.160397\n",
      "Validataion: C=0.010000, acc=0.491750, TPR=0.791700, TNR=0.191800, MSE=0.508250\n",
      "Training: C=0.100000, acc=0.914286, TPR=0.978005, TNR=0.772689, MSE=0.085714\n",
      "Validataion: C=0.100000, acc=0.674500, TPR=0.584800, TNR=0.764200, MSE=0.325500\n",
      "Training: C=1.000000, acc=0.934197, TPR=0.969210, TNR=0.856389, MSE=0.065803\n",
      "Validataion: C=1.000000, acc=0.650950, TPR=0.447300, TNR=0.854600, MSE=0.349050\n",
      "Training: C=10.000000, acc=0.937024, TPR=0.966905, TNR=0.870622, MSE=0.062976\n",
      "Validataion: C=10.000000, acc=0.642300, TPR=0.416600, TNR=0.868000, MSE=0.357700\n",
      "Training: C=100.000000, acc=0.937307, TPR=0.966510, TNR=0.872411, MSE=0.062693\n",
      "Validataion: C=100.000000, acc=0.640050, TPR=0.412100, TNR=0.868000, MSE=0.359950\n",
      "Training: C=1000.000000, acc=0.937334, TPR=0.966490, TNR=0.872544, MSE=0.062666\n",
      "Validataion: C=1000.000000, acc=0.639850, TPR=0.411800, TNR=0.867900, MSE=0.360150\n",
      "Training: C=10000.000000, acc=0.937331, TPR=0.966485, TNR=0.872544, MSE=0.062669\n",
      "Validataion: C=10000.000000, acc=0.639850, TPR=0.411800, TNR=0.867900, MSE=0.360150\n",
      "\n",
      "Running # Neg: 85000\n",
      "# total trainging data: 295000, # Neg: 85000\n",
      "Training: C=0.000100, acc=0.677966, TPR=1.000000, TNR=0.000000, MSE=0.322034\n",
      "Validataion: C=0.000100, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.001000, acc=0.741729, TPR=0.982160, TNR=0.235558, MSE=0.258271\n",
      "Validataion: C=0.001000, acc=0.461400, TPR=0.920900, TNR=0.001900, MSE=0.538600\n",
      "Training: C=0.010000, acc=0.838949, TPR=0.983870, TNR=0.533853, MSE=0.161051\n",
      "Validataion: C=0.010000, acc=0.488850, TPR=0.774700, TNR=0.203000, MSE=0.511150\n",
      "Training: C=0.100000, acc=0.914908, TPR=0.976640, TNR=0.784947, MSE=0.085092\n",
      "Validataion: C=0.100000, acc=0.673900, TPR=0.566300, TNR=0.781500, MSE=0.326100\n",
      "Training: C=1.000000, acc=0.933234, TPR=0.968050, TNR=0.859937, MSE=0.066766\n",
      "Validataion: C=1.000000, acc=0.648950, TPR=0.435700, TNR=0.862200, MSE=0.351050\n",
      "Training: C=10.000000, acc=0.935966, TPR=0.965710, TNR=0.873347, MSE=0.064034\n",
      "Validataion: C=10.000000, acc=0.639250, TPR=0.405500, TNR=0.873000, MSE=0.360750\n",
      "Training: C=100.000000, acc=0.936241, TPR=0.965395, TNR=0.874863, MSE=0.063759\n",
      "Validataion: C=100.000000, acc=0.637850, TPR=0.401700, TNR=0.874000, MSE=0.362150\n",
      "Training: C=1000.000000, acc=0.936227, TPR=0.965345, TNR=0.874926, MSE=0.063773\n",
      "Validataion: C=1000.000000, acc=0.637700, TPR=0.401400, TNR=0.874000, MSE=0.362300\n",
      "Training: C=10000.000000, acc=0.936231, TPR=0.965340, TNR=0.874947, MSE=0.063769\n",
      "Validataion: C=10000.000000, acc=0.637700, TPR=0.401400, TNR=0.874000, MSE=0.362300\n",
      "\n",
      "Running # Neg: 90000\n",
      "# total trainging data: 300000, # Neg: 90000\n",
      "Training: C=0.000100, acc=0.666667, TPR=1.000000, TNR=0.000000, MSE=0.333333\n",
      "Validataion: C=0.000100, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.001000, acc=0.735430, TPR=0.953380, TNR=0.299530, MSE=0.264570\n",
      "Validataion: C=0.001000, acc=0.445600, TPR=0.889200, TNR=0.002000, MSE=0.554400\n",
      "Training: C=0.010000, acc=0.840990, TPR=0.978725, TNR=0.565520, MSE=0.159010\n",
      "Validataion: C=0.010000, acc=0.492150, TPR=0.755000, TNR=0.229300, MSE=0.507850\n",
      "Training: C=0.100000, acc=0.916010, TPR=0.975500, TNR=0.797030, MSE=0.083990\n",
      "Validataion: C=0.100000, acc=0.674000, TPR=0.553800, TNR=0.794200, MSE=0.326000\n",
      "Training: C=1.000000, acc=0.933717, TPR=0.967165, TNR=0.866820, MSE=0.066283\n",
      "Validataion: C=1.000000, acc=0.647400, TPR=0.428600, TNR=0.866200, MSE=0.352600\n",
      "Training: C=10.000000, acc=0.936420, TPR=0.964920, TNR=0.879420, MSE=0.063580\n",
      "Validataion: C=10.000000, acc=0.637800, TPR=0.399500, TNR=0.876100, MSE=0.362200\n",
      "Training: C=100.000000, acc=0.936943, TPR=0.964630, TNR=0.881570, MSE=0.063057\n",
      "Validataion: C=100.000000, acc=0.637750, TPR=0.397200, TNR=0.878300, MSE=0.362250\n",
      "Training: C=1000.000000, acc=0.936960, TPR=0.964570, TNR=0.881740, MSE=0.063040\n",
      "Validataion: C=1000.000000, acc=0.637850, TPR=0.396700, TNR=0.879000, MSE=0.362150\n",
      "Training: C=10000.000000, acc=0.936957, TPR=0.964565, TNR=0.881740, MSE=0.063043\n",
      "Validataion: C=10000.000000, acc=0.637850, TPR=0.396700, TNR=0.879000, MSE=0.362150\n",
      "\n",
      "Running # Neg: 95000\n",
      "# total trainging data: 305000, # Neg: 95000\n",
      "Training: C=0.000100, acc=0.655738, TPR=1.000000, TNR=0.000000, MSE=0.344262\n",
      "Validataion: C=0.000100, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.001000, acc=0.726990, TPR=0.931805, TNR=0.336867, MSE=0.273010\n",
      "Validataion: C=0.001000, acc=0.434700, TPR=0.867400, TNR=0.002000, MSE=0.565300\n",
      "Training: C=0.010000, acc=0.841554, TPR=0.974440, TNR=0.588438, MSE=0.158446\n",
      "Validataion: C=0.010000, acc=0.513900, TPR=0.738600, TNR=0.289200, MSE=0.486100\n",
      "Training: C=0.100000, acc=0.916272, TPR=0.973850, TNR=0.806600, MSE=0.083728\n",
      "Validataion: C=0.100000, acc=0.672700, TPR=0.535600, TNR=0.809800, MSE=0.327300\n",
      "Training: C=1.000000, acc=0.932475, TPR=0.965655, TNR=0.869276, MSE=0.067525\n",
      "Validataion: C=1.000000, acc=0.643250, TPR=0.414700, TNR=0.871800, MSE=0.356750\n",
      "Training: C=10.000000, acc=0.934944, TPR=0.963445, TNR=0.880657, MSE=0.065056\n",
      "Validataion: C=10.000000, acc=0.635000, TPR=0.389500, TNR=0.880500, MSE=0.365000\n",
      "Training: C=100.000000, acc=0.935380, TPR=0.963200, TNR=0.882390, MSE=0.064620\n",
      "Validataion: C=100.000000, acc=0.635050, TPR=0.387300, TNR=0.882800, MSE=0.364950\n",
      "Training: C=1000.000000, acc=0.935377, TPR=0.963180, TNR=0.882419, MSE=0.064623\n",
      "Validataion: C=1000.000000, acc=0.634950, TPR=0.387100, TNR=0.882800, MSE=0.365050\n",
      "Training: C=10000.000000, acc=0.935380, TPR=0.963175, TNR=0.882438, MSE=0.064620\n",
      "Validataion: C=10000.000000, acc=0.634950, TPR=0.387100, TNR=0.882800, MSE=0.365050\n",
      "\n",
      "Running # Neg: 100000\n",
      "# total trainging data: 310000, # Neg: 100000\n",
      "Training: C=0.000100, acc=0.645161, TPR=1.000000, TNR=0.000000, MSE=0.354839\n",
      "Validataion: C=0.000100, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.001000, acc=0.720094, TPR=0.907180, TNR=0.379936, MSE=0.279906\n",
      "Validataion: C=0.001000, acc=0.422650, TPR=0.843300, TNR=0.002000, MSE=0.577350\n",
      "Training: C=0.010000, acc=0.842529, TPR=0.968195, TNR=0.614045, MSE=0.157471\n",
      "Validataion: C=0.010000, acc=0.529750, TPR=0.722100, TNR=0.337400, MSE=0.470250\n",
      "Training: C=0.100000, acc=0.917165, TPR=0.972370, TNR=0.816791, MSE=0.082835\n",
      "Validataion: C=0.100000, acc=0.669700, TPR=0.521100, TNR=0.818300, MSE=0.330300\n",
      "Training: C=1.000000, acc=0.932855, TPR=0.964615, TNR=0.875109, MSE=0.067145\n",
      "Validataion: C=1.000000, acc=0.641100, TPR=0.405900, TNR=0.876300, MSE=0.358900\n",
      "Training: C=10.000000, acc=0.935181, TPR=0.962560, TNR=0.885400, MSE=0.064819\n",
      "Validataion: C=10.000000, acc=0.633950, TPR=0.382900, TNR=0.885000, MSE=0.366050\n",
      "Training: C=100.000000, acc=0.935587, TPR=0.962295, TNR=0.887027, MSE=0.064413\n",
      "Validataion: C=100.000000, acc=0.632800, TPR=0.379900, TNR=0.885700, MSE=0.367200\n",
      "Training: C=1000.000000, acc=0.935600, TPR=0.962275, TNR=0.887100, MSE=0.064400\n",
      "Validataion: C=1000.000000, acc=0.632950, TPR=0.379900, TNR=0.886000, MSE=0.367050\n",
      "Training: C=10000.000000, acc=0.935581, TPR=0.962275, TNR=0.887045, MSE=0.064419\n",
      "Validataion: C=10000.000000, acc=0.632650, TPR=0.379900, TNR=0.885400, MSE=0.367350\n",
      "\n",
      "Running # Neg: 105000\n",
      "# total trainging data: 315000, # Neg: 105000\n",
      "Training: C=0.000100, acc=0.634921, TPR=1.000000, TNR=0.000000, MSE=0.365079\n",
      "Validataion: C=0.000100, acc=0.500000, TPR=1.000000, TNR=0.000000, MSE=0.500000\n",
      "Training: C=0.001000, acc=0.713232, TPR=0.886735, TNR=0.411487, MSE=0.286768\n",
      "Validataion: C=0.001000, acc=0.412200, TPR=0.822400, TNR=0.002000, MSE=0.587800\n",
      "Training: C=0.010000, acc=0.842908, TPR=0.962610, TNR=0.634730, MSE=0.157092\n",
      "Validataion: C=0.010000, acc=0.548800, TPR=0.705700, TNR=0.391900, MSE=0.451200\n",
      "Training: C=0.100000, acc=0.917260, TPR=0.970730, TNR=0.824270, MSE=0.082740\n",
      "Validataion: C=0.100000, acc=0.669500, TPR=0.506100, TNR=0.832900, MSE=0.330500\n",
      "Training: C=1.000000, acc=0.932333, TPR=0.963310, TNR=0.878461, MSE=0.067667\n",
      "Validataion: C=1.000000, acc=0.639100, TPR=0.395000, TNR=0.883200, MSE=0.360900\n",
      "Training: C=10.000000, acc=0.934533, TPR=0.961310, TNR=0.887965, MSE=0.065467\n",
      "Validataion: C=10.000000, acc=0.632400, TPR=0.373600, TNR=0.891200, MSE=0.367600\n",
      "Training: C=100.000000, acc=0.934762, TPR=0.960955, TNR=0.889209, MSE=0.065238\n",
      "Validataion: C=100.000000, acc=0.631100, TPR=0.370600, TNR=0.891600, MSE=0.368900\n",
      "Training: C=1000.000000, acc=0.934762, TPR=0.960900, TNR=0.889304, MSE=0.065238\n",
      "Validataion: C=1000.000000, acc=0.631150, TPR=0.370200, TNR=0.892100, MSE=0.368850\n",
      "Training: C=10000.000000, acc=0.934752, TPR=0.960885, TNR=0.889304, MSE=0.065248\n",
      "Validataion: C=10000.000000, acc=0.631100, TPR=0.370100, TNR=0.892100, MSE=0.368900\n",
      "\n",
      "Running # Neg: 110000\n",
      "# total trainging data: 320000, # Neg: 110000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-6a4aa1331160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Data to Features [simItem, simUser, percentile]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mbookFeaturesArt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetClassificationData2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbookDataArt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mbookFeaturesValid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetClassificationData2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbookDataValid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-05b7ce96030a>\u001b[0m in \u001b[0;36mgetClassificationData2\u001b[0;34m(Xdata)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msim2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairSimilarityByUser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-8fbecceaa6f8>\u001b[0m in \u001b[0;36mpairSimilarityByUser\u001b[0;34m(u, b)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidateUsers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mu2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemsPerUser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-1d43a5daf4f4>\u001b[0m in \u001b[0;36mJaccard\u001b[0;34m(s1, s2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mJaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnumer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnumer\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Includes Another Similarity feature [simItem, simUser, new percentile]\n",
    "numNegativeExamples = range(70000, 190000, 5000)\n",
    "predBookResult = []\n",
    "\n",
    "for numNeg in numNegativeExamples:\n",
    "    print(\"\\nRunning # Neg: %d\" % (numNeg) )\n",
    "    bookDataNeg, bookDataYNeg = getNegativeEntries(numNeg)\n",
    "    bookDataArt = bookDataTrain + bookDataValid + bookDataNeg\n",
    "    bookDataYArt = bookDataYTrain + bookDataYValid + bookDataYNeg\n",
    "    print(\"# total trainging data: %d, # Neg: %d\" % (len(bookDataArt), len(bookDataNeg)) )\n",
    "    \n",
    "    # Data to Features [simItem, simUser, percentile]\n",
    "    bookFeaturesArt = getClassificationData2(bookDataArt)\n",
    "    bookFeaturesValid = getClassificationData2(bookDataValid)\n",
    "    \n",
    "    for cExp in range(-3,5):\n",
    "        cVal = pow(10,cExp)\n",
    "        model = linear_model.LogisticRegression(C=cVal, solver=\"liblinear\")\n",
    "        model.fit(bookFeaturesArt, bookDataYArt)\n",
    "\n",
    "        predBookDataYArt = model.predict(bookFeaturesArt)\n",
    "        mseTrain = MSE(predBookDataYArt, bookDataYArt)\n",
    "        predBookDataYValid = model.predict(bookFeaturesValid)\n",
    "        mseValid = MSE(predBookDataYValid, bookDataYValid)\n",
    "\n",
    "        writeOutClassificationPred2(model, \"numNeg_\"+str(numNeg)+\"_C_\"+str(cVal))\n",
    "\n",
    "        acc, TPR, TNR = getMetrics(predBookDataYArt, bookDataYArt)\n",
    "        print(\"Training: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseTrain) )\n",
    "        acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "        print(\"Validataion: C=%f, acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (cVal, acc, TPR, TNR, mseValid) )\n",
    "        predBookResult.append((acc, TPR, TNR, mseValid, numNeg, cVal))\n",
    "    \n",
    "predBookResult.sort(reverse = True)\n",
    "predBookResult[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running # Neg: 5000\n",
      "# total trainging data: 195000, # Neg: 5000\n",
      "Training: acc=0.980626, TPR=0.999995, TNR=0.244600, MSE=0.019374\n",
      "Validataion: acc=0.471350, TPR=0.942200, TNR=0.000500, MSE=0.528650\n",
      "\n",
      "Running # Neg: 10000\n",
      "# total trainging data: 200000, # Neg: 10000\n",
      "Training: acc=0.971860, TPR=0.999879, TNR=0.439500, MSE=0.028140\n",
      "Validataion: acc=0.531900, TPR=0.872800, TNR=0.191000, MSE=0.468100\n",
      "\n",
      "Running # Neg: 15000\n",
      "# total trainging data: 205000, # Neg: 15000\n",
      "Training: acc=0.965210, TPR=0.999568, TNR=0.530000, MSE=0.034790\n",
      "Validataion: acc=0.560550, TPR=0.828000, TNR=0.293100, MSE=0.439450\n",
      "\n",
      "Running # Neg: 20000\n",
      "# total trainging data: 210000, # Neg: 20000\n",
      "Training: acc=0.958614, TPR=0.999184, TNR=0.573200, MSE=0.041386\n",
      "Validataion: acc=0.588200, TPR=0.798100, TNR=0.378300, MSE=0.411800\n",
      "\n",
      "Running # Neg: 25000\n",
      "# total trainging data: 215000, # Neg: 25000\n",
      "Training: acc=0.953637, TPR=0.998689, TNR=0.611240, MSE=0.046363\n",
      "Validataion: acc=0.609250, TPR=0.770800, TNR=0.447700, MSE=0.390750\n",
      "\n",
      "Running # Neg: 30000\n",
      "# total trainging data: 220000, # Neg: 30000\n",
      "Training: acc=0.948718, TPR=0.998026, TNR=0.636433, MSE=0.051282\n",
      "Validataion: acc=0.618850, TPR=0.750000, TNR=0.487700, MSE=0.381150\n",
      "\n",
      "Running # Neg: 35000\n",
      "# total trainging data: 225000, # Neg: 35000\n",
      "Training: acc=0.944578, TPR=0.997495, TNR=0.657314, MSE=0.055422\n",
      "Validataion: acc=0.624850, TPR=0.731700, TNR=0.518000, MSE=0.375150\n",
      "\n",
      "Running # Neg: 40000\n",
      "# total trainging data: 230000, # Neg: 40000\n",
      "Training: acc=0.941291, TPR=0.996847, TNR=0.677400, MSE=0.058709\n",
      "Validataion: acc=0.631450, TPR=0.714300, TNR=0.548600, MSE=0.368550\n",
      "\n",
      "Running # Neg: 45000\n",
      "# total trainging data: 235000, # Neg: 45000\n",
      "Training: acc=0.938970, TPR=0.996263, TNR=0.697067, MSE=0.061030\n",
      "Validataion: acc=0.635850, TPR=0.697100, TNR=0.574600, MSE=0.364150\n",
      "\n",
      "Running # Neg: 50000\n",
      "# total trainging data: 240000, # Neg: 50000\n",
      "Training: acc=0.935517, TPR=0.995484, TNR=0.707640, MSE=0.064483\n",
      "Validataion: acc=0.638850, TPR=0.681900, TNR=0.595800, MSE=0.361150\n",
      "\n",
      "Running # Neg: 55000\n",
      "# total trainging data: 245000, # Neg: 55000\n",
      "Training: acc=0.934041, TPR=0.994800, TNR=0.724145, MSE=0.065959\n",
      "Validataion: acc=0.646650, TPR=0.670400, TNR=0.622900, MSE=0.353350\n",
      "\n",
      "Running # Neg: 60000\n",
      "# total trainging data: 250000, # Neg: 60000\n",
      "Training: acc=0.931916, TPR=0.993800, TNR=0.735950, MSE=0.068084\n",
      "Validataion: acc=0.652100, TPR=0.656300, TNR=0.647900, MSE=0.347900\n",
      "\n",
      "Running # Neg: 65000\n",
      "# total trainging data: 255000, # Neg: 65000\n",
      "Training: acc=0.930686, TPR=0.993005, TNR=0.748523, MSE=0.069314\n",
      "Validataion: acc=0.652150, TPR=0.644900, TNR=0.659400, MSE=0.347850\n",
      "\n",
      "Running # Neg: 70000\n",
      "# total trainging data: 260000, # Neg: 70000\n",
      "Training: acc=0.928750, TPR=0.992058, TNR=0.756914, MSE=0.071250\n",
      "Validataion: acc=0.655150, TPR=0.632600, TNR=0.677700, MSE=0.344850\n",
      "\n",
      "Running # Neg: 75000\n",
      "# total trainging data: 265000, # Neg: 75000\n",
      "Training: acc=0.927257, TPR=0.991058, TNR=0.765627, MSE=0.072743\n",
      "Validataion: acc=0.666450, TPR=0.620900, TNR=0.712000, MSE=0.333550\n",
      "\n",
      "Running # Neg: 80000\n",
      "# total trainging data: 270000, # Neg: 80000\n",
      "Training: acc=0.926444, TPR=0.990089, TNR=0.775288, MSE=0.073556\n",
      "Validataion: acc=0.667500, TPR=0.609900, TNR=0.725100, MSE=0.332500\n",
      "\n",
      "Running # Neg: 85000\n",
      "# total trainging data: 275000, # Neg: 85000\n",
      "Training: acc=0.925687, TPR=0.988879, TNR=0.784435, MSE=0.074313\n",
      "Validataion: acc=0.671400, TPR=0.600300, TNR=0.742500, MSE=0.328600\n",
      "\n",
      "Running # Neg: 90000\n",
      "# total trainging data: 280000, # Neg: 90000\n",
      "Training: acc=0.924893, TPR=0.987753, TNR=0.792189, MSE=0.075107\n",
      "Validataion: acc=0.666450, TPR=0.590400, TNR=0.742500, MSE=0.333550\n",
      "\n",
      "Running # Neg: 95000\n",
      "# total trainging data: 285000, # Neg: 95000\n",
      "Training: acc=0.923491, TPR=0.986400, TNR=0.797674, MSE=0.076509\n",
      "Validataion: acc=0.673450, TPR=0.578400, TNR=0.768500, MSE=0.326550\n",
      "\n",
      "Running # Neg: 100000\n",
      "# total trainging data: 290000, # Neg: 100000\n",
      "Training: acc=0.923459, TPR=0.984921, TNR=0.806680, MSE=0.076541\n",
      "Validataion: acc=0.675750, TPR=0.568700, TNR=0.782800, MSE=0.324250\n",
      "\n",
      "Running # Neg: 105000\n",
      "# total trainging data: 295000, # Neg: 105000\n",
      "Training: acc=0.922166, TPR=0.983258, TNR=0.811619, MSE=0.077834\n",
      "Validataion: acc=0.670000, TPR=0.557200, TNR=0.782800, MSE=0.330000\n",
      "\n",
      "Running # Neg: 110000\n",
      "# total trainging data: 300000, # Neg: 110000\n",
      "Training: acc=0.921990, TPR=0.981353, TNR=0.819455, MSE=0.078010\n",
      "Validataion: acc=0.673850, TPR=0.548300, TNR=0.799400, MSE=0.326150\n",
      "\n",
      "Running # Neg: 115000\n",
      "# total trainging data: 305000, # Neg: 115000\n",
      "Training: acc=0.921643, TPR=0.979389, TNR=0.826235, MSE=0.078357\n",
      "Validataion: acc=0.669100, TPR=0.538800, TNR=0.799400, MSE=0.330900\n",
      "\n",
      "Running # Neg: 120000\n",
      "# total trainging data: 310000, # Neg: 120000\n",
      "Training: acc=0.921245, TPR=0.977316, TNR=0.832467, MSE=0.078755\n",
      "Validataion: acc=0.674200, TPR=0.529100, TNR=0.819300, MSE=0.325800\n",
      "\n",
      "Running # Neg: 125000\n",
      "# total trainging data: 315000, # Neg: 125000\n",
      "Training: acc=0.920806, TPR=0.975089, TNR=0.838296, MSE=0.079194\n",
      "Validataion: acc=0.671950, TPR=0.518300, TNR=0.825600, MSE=0.328050\n",
      "\n",
      "Running # Neg: 130000\n",
      "# total trainging data: 320000, # Neg: 130000\n",
      "Training: acc=0.920066, TPR=0.972658, TNR=0.843200, MSE=0.079934\n",
      "Validataion: acc=0.667800, TPR=0.510000, TNR=0.825600, MSE=0.332200\n",
      "\n",
      "Running # Neg: 135000\n",
      "# total trainging data: 325000, # Neg: 135000\n",
      "Training: acc=0.919745, TPR=0.970216, TNR=0.848711, MSE=0.080255\n",
      "Validataion: acc=0.677250, TPR=0.501100, TNR=0.853400, MSE=0.322750\n",
      "\n",
      "Running # Neg: 140000\n",
      "# total trainging data: 330000, # Neg: 140000\n",
      "Training: acc=0.918879, TPR=0.967221, TNR=0.853271, MSE=0.081121\n",
      "Validataion: acc=0.672900, TPR=0.492400, TNR=0.853400, MSE=0.327100\n",
      "\n",
      "Running # Neg: 145000\n",
      "# total trainging data: 335000, # Neg: 145000\n",
      "Training: acc=0.918931, TPR=0.964332, TNR=0.859441, MSE=0.081069\n",
      "Validataion: acc=0.668950, TPR=0.484500, TNR=0.853400, MSE=0.331050\n",
      "\n",
      "Running # Neg: 150000\n",
      "# total trainging data: 340000, # Neg: 150000\n",
      "Training: acc=0.917200, TPR=0.959958, TNR=0.863040, MSE=0.082800\n",
      "Validataion: acc=0.669900, TPR=0.473200, TNR=0.866600, MSE=0.330100\n",
      "\n",
      "Running # Neg: 155000\n",
      "# total trainging data: 345000, # Neg: 155000\n",
      "Training: acc=0.916670, TPR=0.957447, TNR=0.866684, MSE=0.083330\n",
      "Validataion: acc=0.667500, TPR=0.468400, TNR=0.866600, MSE=0.332500\n",
      "\n",
      "Running # Neg: 160000\n",
      "# total trainging data: 350000, # Neg: 160000\n",
      "Training: acc=0.915114, TPR=0.953068, TNR=0.870044, MSE=0.084886\n",
      "Validataion: acc=0.662800, TPR=0.459000, TNR=0.866600, MSE=0.337200\n",
      "\n",
      "Running # Neg: 165000\n",
      "# total trainging data: 355000, # Neg: 165000\n",
      "Training: acc=0.914741, TPR=0.949995, TNR=0.874145, MSE=0.085259\n",
      "Validataion: acc=0.659500, TPR=0.452400, TNR=0.866600, MSE=0.340500\n",
      "\n",
      "Running # Neg: 170000\n",
      "# total trainging data: 360000, # Neg: 170000\n",
      "Training: acc=0.914500, TPR=0.947311, TNR=0.877829, MSE=0.085500\n",
      "Validataion: acc=0.662900, TPR=0.447500, TNR=0.878300, MSE=0.337100\n",
      "\n",
      "Running # Neg: 175000\n",
      "# total trainging data: 365000, # Neg: 175000\n",
      "Training: acc=0.913170, TPR=0.943468, TNR=0.880274, MSE=0.086830\n",
      "Validataion: acc=0.659950, TPR=0.441600, TNR=0.878300, MSE=0.340050\n",
      "\n",
      "Running # Neg: 180000\n",
      "# total trainging data: 370000, # Neg: 180000\n",
      "Training: acc=0.911062, TPR=0.939705, TNR=0.880828, MSE=0.088938\n",
      "Validataion: acc=0.656550, TPR=0.434800, TNR=0.878300, MSE=0.343450\n",
      "\n",
      "Running # Neg: 185000\n",
      "# total trainging data: 375000, # Neg: 185000\n",
      "Training: acc=0.910896, TPR=0.937289, TNR=0.883789, MSE=0.089104\n",
      "Validataion: acc=0.655450, TPR=0.432600, TNR=0.878300, MSE=0.344550\n",
      "\n",
      "Running # Neg: 190000\n",
      "# total trainging data: 380000, # Neg: 190000\n",
      "Training: acc=0.909945, TPR=0.934063, TNR=0.885826, MSE=0.090055\n",
      "Validataion: acc=0.662400, TPR=0.428700, TNR=0.896100, MSE=0.337600\n",
      "\n",
      "Running # Neg: 195000\n",
      "# total trainging data: 385000, # Neg: 195000\n",
      "Training: acc=0.909257, TPR=0.931537, TNR=0.887549, MSE=0.090743\n",
      "Validataion: acc=0.660500, TPR=0.424900, TNR=0.896100, MSE=0.339500\n",
      "\n",
      "Running # Neg: 200000\n",
      "# total trainging data: 390000, # Neg: 200000\n",
      "Training: acc=0.908567, TPR=0.928611, TNR=0.889525, MSE=0.091433\n",
      "Validataion: acc=0.658400, TPR=0.420700, TNR=0.896100, MSE=0.341600\n",
      "\n",
      "Running # Neg: 205000\n",
      "# total trainging data: 395000, # Neg: 205000\n",
      "Training: acc=0.907681, TPR=0.925516, TNR=0.891151, MSE=0.092319\n",
      "Validataion: acc=0.658050, TPR=0.415300, TNR=0.900800, MSE=0.341950\n",
      "\n",
      "Running # Neg: 210000\n",
      "# total trainging data: 400000, # Neg: 210000\n",
      "Training: acc=0.907183, TPR=0.922821, TNR=0.893033, MSE=0.092817\n",
      "Validataion: acc=0.656350, TPR=0.411800, TNR=0.900900, MSE=0.343650\n",
      "\n",
      "Running # Neg: 215000\n",
      "# total trainging data: 405000, # Neg: 215000\n",
      "Training: acc=0.906672, TPR=0.920495, TNR=0.894456, MSE=0.093328\n",
      "Validataion: acc=0.655050, TPR=0.409200, TNR=0.900900, MSE=0.344950\n",
      "\n",
      "Running # Neg: 220000\n",
      "# total trainging data: 410000, # Neg: 220000\n",
      "Training: acc=0.905515, TPR=0.916989, TNR=0.895605, MSE=0.094485\n",
      "Validataion: acc=0.655950, TPR=0.405300, TNR=0.906600, MSE=0.344050\n",
      "\n",
      "Running # Neg: 225000\n",
      "# total trainging data: 415000, # Neg: 225000\n",
      "Training: acc=0.905325, TPR=0.914589, TNR=0.897502, MSE=0.094675\n",
      "Validataion: acc=0.653750, TPR=0.400900, TNR=0.906600, MSE=0.346250\n",
      "\n",
      "Running # Neg: 230000\n",
      "# total trainging data: 420000, # Neg: 230000\n",
      "Training: acc=0.904638, TPR=0.912189, TNR=0.898400, MSE=0.095362\n",
      "Validataion: acc=0.652450, TPR=0.398300, TNR=0.906600, MSE=0.347550\n",
      "\n",
      "Running # Neg: 235000\n",
      "# total trainging data: 425000, # Neg: 235000\n",
      "Training: acc=0.903628, TPR=0.909068, TNR=0.899230, MSE=0.096372\n",
      "Validataion: acc=0.653300, TPR=0.395400, TNR=0.911200, MSE=0.346700\n",
      "\n",
      "Running # Neg: 240000\n",
      "# total trainging data: 430000, # Neg: 240000\n",
      "Training: acc=0.904409, TPR=0.907311, TNR=0.902112, MSE=0.095591\n",
      "Validataion: acc=0.652000, TPR=0.392800, TNR=0.911200, MSE=0.348000\n",
      "\n",
      "Running # Neg: 245000\n",
      "# total trainging data: 435000, # Neg: 245000\n",
      "Training: acc=0.903434, TPR=0.904563, TNR=0.902559, MSE=0.096566\n",
      "Validataion: acc=0.649900, TPR=0.388600, TNR=0.911200, MSE=0.350100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.67725, 0.5011, 0.8534, 0.32275),\n",
       " (0.67575, 0.5687, 0.7828, 0.32425),\n",
       " (0.6742, 0.5291, 0.8193, 0.3258),\n",
       " (0.67385, 0.5483, 0.7994, 0.32615),\n",
       " (0.67345, 0.5784, 0.7685, 0.32655),\n",
       " (0.6729, 0.4924, 0.8534, 0.3271),\n",
       " (0.67195, 0.5183, 0.8256, 0.32805),\n",
       " (0.6714, 0.6003, 0.7425, 0.3286),\n",
       " (0.67, 0.5572, 0.7828, 0.33),\n",
       " (0.6699, 0.4732, 0.8666, 0.3301)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bookDataValid = bookDataValidPos + bookDataValidNeg\n",
    "#bookDataYValid = bookDataYValidPos + bookDataYValidNeg\n",
    "numNegativeExamples = range(5000, 250000, 5000)\n",
    "predBookResult = []\n",
    "\n",
    "for numNeg in numNegativeExamples:\n",
    "    print(\"\\nRunning # Neg: %d\" % (numNeg) )\n",
    "    bookDataNeg, bookDataYNeg = getNegativeEntries(numNeg)\n",
    "    bookDataArt = bookDataTrain + bookDataNeg\n",
    "    bookDataYArt = bookDataYTrain + bookDataYNeg\n",
    "    print(\"# total trainging data: %d, # Neg: %d\" % (len(bookDataArt), len(bookDataNeg)) )\n",
    "    \n",
    "    # Data to Features\n",
    "    bookFeaturesArt = getClassificationData(bookDataArt)\n",
    "    \n",
    "    model = linear_model.LogisticRegression(solver=\"liblinear\")\n",
    "    model.fit(bookFeaturesArt, bookDataYArt)\n",
    "\n",
    "    predBookDataYArt = model.predict(bookFeaturesArt)\n",
    "    mseTrain = MSE(predBookDataYArt, bookDataYArt)\n",
    "    predBookDataYValid = model.predict(bookFeaturesValid)\n",
    "    mseValid = MSE(predBookDataYValid, bookDataYValid)\n",
    "\n",
    "    writeOutClassificationPred(model, \"numNeg_\"+str(numNeg))\n",
    "\n",
    "    acc, TPR, TNR = getMetrics(predBookDataYArt, bookDataYArt)\n",
    "    print(\"Training: acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (acc, TPR, TNR, mseTrain) )\n",
    "    acc, TPR, TNR = getMetrics(predBookDataYValid, bookDataYValid)\n",
    "    print(\"Validataion: acc=%f, TPR=%f, TNR=%f, MSE=%f\" % (acc, TPR, TNR, mseValid) )\n",
    "    predBookResult.append((acc, TPR, TNR, mseValid, numNeg))\n",
    "    \n",
    "predBookResult.sort(reverse = True)\n",
    "predBookResult[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutClassificationPred(model, nameTag):\n",
    "    fileName = \"predictions_Read_classification_\" + nameTag + \".txt\"\n",
    "    predOutFile = open(fileName, 'w')\n",
    "    bookDataTest = []\n",
    "    \n",
    "    # Read Testing set\n",
    "    for l in open(\"pairs_Read.txt\", 'r'):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predOutFile.write(l)\n",
    "            continue\n",
    "        uId, bId = l.strip().split('-')\n",
    "        bookDataTest.append([uId, bId, -1])\n",
    "    \n",
    "    bookFeaturesTest = getClassificationData(bookDataTest)\n",
    "    bookFeaturesYTest = model.predict(bookFeaturesTest)\n",
    "    \n",
    "    # Write out prediction result\n",
    "    for data, y in zip(bookDataTest, bookFeaturesYTest):\n",
    "        predOutFile.write(data[0] + '-' + data[1] + \",\" + str(y) + \"\\n\")\n",
    "\n",
    "    predOutFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutClassificationPred2(model, nameTag):\n",
    "    fileName = \"predictions_Read_classification_\" + nameTag + \".txt\"\n",
    "    predOutFile = open(fileName, 'w')\n",
    "    bookDataTest = []\n",
    "    \n",
    "    # Read Testing set\n",
    "    for l in open(\"pairs_Read.txt\", 'r'):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predOutFile.write(l)\n",
    "            continue\n",
    "        uId, bId = l.strip().split('-')\n",
    "        bookDataTest.append([uId, bId, -1])\n",
    "    \n",
    "    bookFeaturesTest = getClassificationData2(bookDataTest)\n",
    "    bookFeaturesYTest = model.predict(bookFeaturesTest)\n",
    "    \n",
    "    # Write out prediction result\n",
    "    for data, y in zip(bookDataTest, bookFeaturesYTest):\n",
    "        predOutFile.write(data[0] + '-' + data[1] + \",\" + str(y) + \"\\n\")\n",
    "\n",
    "    predOutFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutClassificationPredWithFunction(model, nameTag, featureFunction):\n",
    "    fileName = \"predictions_Read_classification_\" + nameTag + \".txt\"\n",
    "    predOutFile = open(fileName, 'w')\n",
    "    bookDataTest = []\n",
    "    \n",
    "    # Read Testing set\n",
    "    for l in open(\"pairs_Read.txt\", 'r'):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predOutFile.write(l)\n",
    "            continue\n",
    "        uId, bId = l.strip().split('-')\n",
    "        bookDataTest.append([uId, bId, -1])\n",
    "    \n",
    "    bookFeaturesTest = featureFunction(bookDataTest)\n",
    "    bookFeaturesYTest = model.predict(bookFeaturesTest)\n",
    "    \n",
    "    # Write out prediction result\n",
    "    for data, y in zip(bookDataTest, bookFeaturesYTest):\n",
    "        predOutFile.write(data[0] + '-' + data[1] + \",\" + str(y) + \"\\n\")\n",
    "\n",
    "    predOutFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutClassificationPredWithFunction(model, nameTag, featureFunction, topK):\n",
    "    fileName = \"predictions_Read_classification_\" + nameTag + \".txt\"\n",
    "    predOutFile = open(fileName, 'w')\n",
    "    bookDataTest = []\n",
    "    \n",
    "    # Read Testing set\n",
    "    for l in open(\"pairs_Read.txt\", 'r'):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predOutFile.write(l)\n",
    "            continue\n",
    "        uId, bId = l.strip().split('-')\n",
    "        bookDataTest.append([uId, bId, -1])\n",
    "    \n",
    "    bookFeaturesTest = featureFunction(bookDataTest, topK)\n",
    "    bookFeaturesYTest = model.predict(bookFeaturesTest)\n",
    "    \n",
    "    # Write out prediction result\n",
    "    for data, y in zip(bookDataTest, bookFeaturesYTest):\n",
    "        predOutFile.write(data[0] + '-' + data[1] + \",\" + str(y) + \"\\n\")\n",
    "\n",
    "    predOutFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeOutClassificationPredWithFunction(model, nameTag, featureFunction, topK, scaler):\n",
    "    fileName = \"predictions_Read_classification_\" + nameTag + \".txt\"\n",
    "    predOutFile = open(fileName, 'w')\n",
    "    bookDataTest = []\n",
    "    \n",
    "    # Read Testing set\n",
    "    for l in open(\"pairs_Read.txt\", 'r'):\n",
    "        if l.startswith(\"userID\"):\n",
    "            #header\n",
    "            predOutFile.write(l)\n",
    "            continue\n",
    "        uId, bId = l.strip().split('-')\n",
    "        bookDataTest.append([uId, bId, -1])\n",
    "    \n",
    "    bookFeaturesTest = featureFunction(bookDataTest, topK)\n",
    "    bookFeaturesTest = scaler.transform(bookFeaturesTest)\n",
    "    bookFeaturesYTest = model.predict(bookFeaturesTest)\n",
    "    \n",
    "    # Write out prediction result\n",
    "    for data, y in zip(bookDataTest, bookFeaturesYTest):\n",
    "        predOutFile.write(data[0] + '-' + data[1] + \",\" + str(y) + \"\\n\")\n",
    "\n",
    "    predOutFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
